{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "uqySxgS6nvYn",
        "uJxYwqA6wZek",
        "EhOn-CZGn9OW",
        "MQ4Fu_0uW5bc",
        "8VlZfSw3v72W",
        "FXssIkqpM6Yy",
        "82nxFIqqWQJ-",
        "yD4BT6uWxRte",
        "szkAMQ7OO218"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "88ebab3dafd346ba81ee8cca95e9c70a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8cb07b5dffba4952b57e9bb6cafcf6b2",
              "IPY_MODEL_f20d9210f0c845c3b459a4d3b4077ae3",
              "IPY_MODEL_fb5e57e9a4de4b61a610ed9c191f027a"
            ],
            "layout": "IPY_MODEL_4100eeac093f423da4de70d493c6cd86"
          }
        },
        "8cb07b5dffba4952b57e9bb6cafcf6b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc8269bde4774a7e9f46ea632f2eb465",
            "placeholder": "​",
            "style": "IPY_MODEL_a65c317e32f24676b38f37f773c07715",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "f20d9210f0c845c3b459a4d3b4077ae3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b78e2bd75a754f9283f22e0e5169a211",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e31bdec1675b4f1f9711673033f80b48",
            "value": 25
          }
        },
        "fb5e57e9a4de4b61a610ed9c191f027a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e401eb2133134c2eb0d09a5bded829b0",
            "placeholder": "​",
            "style": "IPY_MODEL_c514240f51074dd392c7c7021d80dfe1",
            "value": " 25.0/25.0 [00:00&lt;00:00, 874B/s]"
          }
        },
        "4100eeac093f423da4de70d493c6cd86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc8269bde4774a7e9f46ea632f2eb465": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a65c317e32f24676b38f37f773c07715": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b78e2bd75a754f9283f22e0e5169a211": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e31bdec1675b4f1f9711673033f80b48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e401eb2133134c2eb0d09a5bded829b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c514240f51074dd392c7c7021d80dfe1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c8315ba4a1c4b56be298dbaecf62d72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_389d6b2af49c43e3b177ab8aa74c1df3",
              "IPY_MODEL_eed839996ef84bb7a9f1dbfe5acf2b0f",
              "IPY_MODEL_735fd50741454a368a37fa7e0d5e706a"
            ],
            "layout": "IPY_MODEL_1a7cafcc25374e2b8dfa54cbc41ff1d7"
          }
        },
        "389d6b2af49c43e3b177ab8aa74c1df3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f96dad34303f4341acbee3a5aa5c4199",
            "placeholder": "​",
            "style": "IPY_MODEL_e314a94eac9049bcbca9c3b106b674a8",
            "value": "config.json: 100%"
          }
        },
        "eed839996ef84bb7a9f1dbfe5acf2b0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14e513c2df3a480f803cede6538f5b68",
            "max": 615,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ea972cc8f62e46f388c0ba00e1e42c89",
            "value": 615
          }
        },
        "735fd50741454a368a37fa7e0d5e706a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6c8129991024da0b371505078627ec6",
            "placeholder": "​",
            "style": "IPY_MODEL_d805e887f37c42e3afba3d57a2ddcb8f",
            "value": " 615/615 [00:00&lt;00:00, 16.8kB/s]"
          }
        },
        "1a7cafcc25374e2b8dfa54cbc41ff1d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f96dad34303f4341acbee3a5aa5c4199": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e314a94eac9049bcbca9c3b106b674a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "14e513c2df3a480f803cede6538f5b68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea972cc8f62e46f388c0ba00e1e42c89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d6c8129991024da0b371505078627ec6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d805e887f37c42e3afba3d57a2ddcb8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b649c17acc524e5e97646c0fb3023169": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_047835f9df1d48b78465d20ee5bcc24d",
              "IPY_MODEL_4a41ae358f89484d960f4890187d333d",
              "IPY_MODEL_9788d24b092345bb886bf29298b6d037"
            ],
            "layout": "IPY_MODEL_2335b7b6955941368e925b4c27b2b0ac"
          }
        },
        "047835f9df1d48b78465d20ee5bcc24d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_295091330b5745369b55c1e4b6a292eb",
            "placeholder": "​",
            "style": "IPY_MODEL_da7d9b0fb27b4df6994958ba321048b9",
            "value": "sentencepiece.bpe.model: 100%"
          }
        },
        "4a41ae358f89484d960f4890187d333d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36967ad41e454d469a40dac3a0a860ff",
            "max": 5069051,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0ab699b3731d43cea7f0a9dbbe21eac7",
            "value": 5069051
          }
        },
        "9788d24b092345bb886bf29298b6d037": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91309475b46c478986375ce92bb7c43a",
            "placeholder": "​",
            "style": "IPY_MODEL_7f1025917ba44aeb8012de73872eb2f8",
            "value": " 5.07M/5.07M [00:00&lt;00:00, 18.2MB/s]"
          }
        },
        "2335b7b6955941368e925b4c27b2b0ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "295091330b5745369b55c1e4b6a292eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da7d9b0fb27b4df6994958ba321048b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "36967ad41e454d469a40dac3a0a860ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ab699b3731d43cea7f0a9dbbe21eac7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "91309475b46c478986375ce92bb7c43a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f1025917ba44aeb8012de73872eb2f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c64e02aeb5cc4f818dac6b35d72e27b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0abfd58afb604a87b1ae9bf9500fcff3",
              "IPY_MODEL_a96597fc42a143d09f18178c1ac35fc1",
              "IPY_MODEL_016db0aac74e47c0a28501a75a11cb59"
            ],
            "layout": "IPY_MODEL_583815c970b14dd8bc3072d2bb3fffe3"
          }
        },
        "0abfd58afb604a87b1ae9bf9500fcff3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3838b7f52f244be7b354cbd80df667c5",
            "placeholder": "​",
            "style": "IPY_MODEL_2434023ce9c947cf98afb7a78c5a53a9",
            "value": "tokenizer.json: 100%"
          }
        },
        "a96597fc42a143d09f18178c1ac35fc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eaf7f5e1750d4b4899500a618b63a2ad",
            "max": 9096718,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0f2fdbb387364ee5af499ac36359d3f4",
            "value": 9096718
          }
        },
        "016db0aac74e47c0a28501a75a11cb59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_febbbcd45a8b49d88282cb83f483e3ff",
            "placeholder": "​",
            "style": "IPY_MODEL_144bc50753b1496cb6b910578be45c4c",
            "value": " 9.10M/9.10M [00:00&lt;00:00, 21.5MB/s]"
          }
        },
        "583815c970b14dd8bc3072d2bb3fffe3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3838b7f52f244be7b354cbd80df667c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2434023ce9c947cf98afb7a78c5a53a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eaf7f5e1750d4b4899500a618b63a2ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f2fdbb387364ee5af499ac36359d3f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "febbbcd45a8b49d88282cb83f483e3ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "144bc50753b1496cb6b910578be45c4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c32779ac8ca4525b1d0d4296c6280d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c20168273f624ab798de0f433c6419ef",
              "IPY_MODEL_ac668af6963b4bbf9ce966832599e238",
              "IPY_MODEL_1a00837c21ed46cbb03094f4ce133ed1"
            ],
            "layout": "IPY_MODEL_f9401f44743f4c3e84febc259a891a27"
          }
        },
        "c20168273f624ab798de0f433c6419ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fdf62382884e42ca938cea4b2695c164",
            "placeholder": "​",
            "style": "IPY_MODEL_a7d9fedfe9fc41bfa6a33fd59b0bd725",
            "value": "model.safetensors: 100%"
          }
        },
        "ac668af6963b4bbf9ce966832599e238": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1790e5ad10d04c4faac96938fd367e7e",
            "max": 1115567652,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c703a09050dc41e58b8a5a519eb6c513",
            "value": 1115567652
          }
        },
        "1a00837c21ed46cbb03094f4ce133ed1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_095a321e93504be6b0bd7da42747171f",
            "placeholder": "​",
            "style": "IPY_MODEL_5be14af4c2af4aee8b3a30a5f9faec5a",
            "value": " 1.12G/1.12G [00:06&lt;00:00, 212MB/s]"
          }
        },
        "f9401f44743f4c3e84febc259a891a27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdf62382884e42ca938cea4b2695c164": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7d9fedfe9fc41bfa6a33fd59b0bd725": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1790e5ad10d04c4faac96938fd367e7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c703a09050dc41e58b8a5a519eb6c513": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "095a321e93504be6b0bd7da42747171f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5be14af4c2af4aee8b3a30a5f9faec5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xfo-03/Hierarchical_Classification_of_Articles/blob/main/English_XLM_R.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZQND3LPnf39"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n"
      ],
      "metadata": {
        "id": "kNZX2mQrvf0L",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "outputId": "50bef5a0-ce7f-4c08-cea0-1a4951f4b58d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-1f759c1655bd>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthenticate_user\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/auth.py\u001b[0m in \u001b[0;36mauthenticate_user\u001b[0;34m(clear_output, project_id)\u001b[0m\n\u001b[1;32m    258\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_check_adc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_CredentialType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUSER\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muse_auth_ephem\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m       _message.blocking_request(\n\u001b[0m\u001b[1;32m    261\u001b[0m           \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m           \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'auth_user_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJZQpBntz8Xb",
        "outputId": "e45b204c-054c-4eaf-a1b5-cbcd7399ff23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing:\n",
        "\n",
        "Preprocessing articles\n",
        "Preprocessing the annotations and merging with the article.\n",
        "Taxonomies Classification\n",
        "One Hot embedding\n",
        "Encode Multi Class Labels"
      ],
      "metadata": {
        "id": "HRtL7oipno7K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing"
      ],
      "metadata": {
        "id": "uqySxgS6nvYn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "def preprocess_articles(article_dir):\n",
        "    \"\"\"\n",
        "    Preprocess the article files by extracting filenames and text content into a DataFrame.\n",
        "\n",
        "    Args:\n",
        "    - article_dir (str): Directory path containing article `.txt` files.\n",
        "\n",
        "    Returns:\n",
        "    - pandas.DataFrame: DataFrame with columns ['article_id', 'text'].\n",
        "    \"\"\"\n",
        "    # List to store article data\n",
        "    articles = []\n",
        "\n",
        "    # Loop through each file in the directory\n",
        "    for filename in os.listdir(article_dir):\n",
        "        if filename.endswith(\".txt\"):\n",
        "            file_path = os.path.join(article_dir, filename)\n",
        "\n",
        "            # Read the file content\n",
        "            with open(file_path, 'r', encoding='utf-8') as file:\n",
        "                lines = file.readlines()\n",
        "\n",
        "                # Extract the text: skip title (first row) and empty line (second row)\n",
        "                title = lines[0].strip() if len(lines) > 0 else \"\"\n",
        "                content = \" \".join(line.strip() for line in lines[2:])\n",
        "\n",
        "                # Append the extracted data\n",
        "                articles.append({'article_id': filename, 'text': title + \"\\n\" + content})\n",
        "\n",
        "    # Create a DataFrame\n",
        "    article_df = pd.DataFrame(articles)\n",
        "\n",
        "    return article_df\n",
        "\n",
        "# Preprocessing the annotations and merging with the article.\n",
        "def preprocess_annotations(annotation_file, article_df):\n",
        "    \"\"\"\n",
        "    Preprocess the annotation file and merge annotations with the article DataFrame.\n",
        "\n",
        "    Args:\n",
        "    - annotation_file (str): Path to the annotation file (tab-separated).\n",
        "    - article_df (pandas.DataFrame): DataFrame with article IDs and texts.\n",
        "\n",
        "    Returns:\n",
        "    - pandas.DataFrame: Merged DataFrame with columns ['article_id', 'text', 'narratives', 'subnarratives'].\n",
        "    \"\"\"\n",
        "    # Read the annotation file\n",
        "    annotations = pd.read_csv(annotation_file, sep='\\t', header=None,\n",
        "                               names=['article_id', 'narratives', 'subnarratives'])\n",
        "\n",
        "    # Merge the annotation data with the article DataFrame\n",
        "    merged_df = pd.merge(article_df, annotations, on='article_id', how='left')\n",
        "\n",
        "    # Fill missing values for narratives and subnarratives with 'Other'\n",
        "    merged_df['narratives'] = merged_df['narratives'].fillna('Other')\n",
        "    merged_df['subnarratives'] = merged_df['subnarratives'].fillna('Other')\n",
        "\n",
        "    return merged_df\n",
        "\n",
        "# Taxonomies Processing\n",
        "def parse_taxonomy(taxonomy_str):\n",
        "    \"\"\"\n",
        "    Parse a taxonomy string into a hierarchical dictionary.\n",
        "\n",
        "    Args:\n",
        "    - taxonomy_str (str): Taxonomy string, e.g., 'x:y; x:z; x:y:a'\n",
        "\n",
        "    Returns:\n",
        "    - dict: Hierarchical representation of the taxonomy.\n",
        "    \"\"\"\n",
        "    taxonomy_dict = {}\n",
        "    if taxonomy_str == \"Other\" or not taxonomy_str:\n",
        "        return {\"Other\": {\"level_1\": [], \"level_2\": {}}}\n",
        "\n",
        "    entries = taxonomy_str.split(\";\")\n",
        "    for entry in entries:\n",
        "        levels = entry.split(\":\")\n",
        "        x = levels[0]  # Top-level narrative\n",
        "        y = levels[1] if len(levels) > 1 else \"Other\"\n",
        "        a = levels[2] if len(levels) > 2 else None\n",
        "\n",
        "        if x not in taxonomy_dict:\n",
        "            taxonomy_dict[x] = {\"level_1\": [], \"level_2\": {}}\n",
        "\n",
        "        if y != \"Other\" and y not in taxonomy_dict[x][\"level_1\"]:\n",
        "            taxonomy_dict[x][\"level_1\"].append(y)\n",
        "\n",
        "        if a and y != \"Other\":\n",
        "            if y not in taxonomy_dict[x][\"level_2\"]:\n",
        "                taxonomy_dict[x][\"level_2\"][y] = []\n",
        "            if a not in taxonomy_dict[x][\"level_2\"][y]:\n",
        "                taxonomy_dict[x][\"level_2\"][y].append(a)\n",
        "\n",
        "    return taxonomy_dict\n",
        "\n",
        "\n",
        "def expand_taxonomies(df, narrative_col, subnarrative_col):\n",
        "    \"\"\"\n",
        "    Expand taxonomies into hierarchical format.\n",
        "\n",
        "    Args:\n",
        "    - df (pd.DataFrame): DataFrame with taxonomy columns.\n",
        "    - narrative_col (str): Column name for narrative-level taxonomies.\n",
        "    - subnarrative_col (str): Column name for sub-narrative-level taxonomies.\n",
        "\n",
        "    Returns:\n",
        "    - pd.DataFrame: Expanded DataFrame with hierarchical taxonomy extraction.\n",
        "    \"\"\"\n",
        "    expanded_data = []\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        article_id = row['article_id']\n",
        "        narratives = parse_taxonomy(row[narrative_col])\n",
        "        subnarratives = parse_taxonomy(row[subnarrative_col])\n",
        "\n",
        "        for narrative, details in narratives.items():\n",
        "            for level_1 in details['level_1']:\n",
        "                if level_1 in subnarratives[narrative][\"level_2\"]:\n",
        "                    for level_2 in subnarratives[narrative][\"level_2\"][level_1]:\n",
        "                        expanded_data.append({\n",
        "                            \"article_id\": article_id,\n",
        "                            \"narrative\": narrative,\n",
        "                            \"level_1\": level_1,\n",
        "                            \"level_2\": level_2\n",
        "                        })\n",
        "                else:\n",
        "                    expanded_data.append({\n",
        "                        \"article_id\": article_id,\n",
        "                        \"narrative\": narrative,\n",
        "                        \"level_1\": level_1,\n",
        "                        \"level_2\": \"Other\"\n",
        "                    })\n",
        "            if not details['level_1']:  # If no level 1 for a narrative\n",
        "                expanded_data.append({\n",
        "                    \"article_id\": article_id,\n",
        "                    \"narrative\": narrative,\n",
        "                    \"level_1\": \"Other\",\n",
        "                    \"level_2\": \"Other\"\n",
        "                })\n",
        "\n",
        "    return pd.DataFrame(expanded_data)\n",
        "\n",
        "\n",
        "def load_annotations(file_path):\n",
        "    \"\"\"\n",
        "    Load and process annotations from a file into a DataFrame.\n",
        "\n",
        "    Args:\n",
        "    - file_path (str): Path to the annotations file.\n",
        "\n",
        "    Returns:\n",
        "    - pandas.DataFrame: DataFrame with columns ['article_id', 'narratives', 'subnarratives'].\n",
        "    \"\"\"\n",
        "    # Load the file into a DataFrame\n",
        "    annotations = pd.read_csv(file_path, sep='\\t', header=None,\n",
        "                               names=['article_id', 'narratives', 'subnarratives'])\n",
        "\n",
        "    # Fill missing values with 'Other'\n",
        "    annotations['narratives'] = annotations['narratives'].fillna('Other')\n",
        "    annotations['subnarratives'] = annotations['subnarratives'].fillna('Other')\n",
        "\n",
        "    return annotations\n",
        "\n",
        "\n",
        "# Training data = train_articles, Development data = dev_articles\n",
        "train_articles_path = '/content/drive/MyDrive/NLP_Proj/target_4_December_release/EN/raw-documents'\n",
        "train_articles = preprocess_articles(train_articles_path)\n",
        "dev_articles_path = '/content/drive/MyDrive/NLP_Proj/cleaned_dev_10_january_2025/EN/subtask-2-documents'\n",
        "dev_articles = preprocess_articles(dev_articles_path)\n",
        "#print(article_df.head())\n",
        "\n",
        "\n",
        "\n",
        "# Annotations for training and dev\n",
        "annotations_train_path = '/content/drive/MyDrive/NLP_Proj/target_4_December_release/EN/subtask-2-annotations.txt'\n",
        "annotations_train_df = load_annotations(annotations_train_path)\n",
        "expanded_train_annotations = expand_taxonomies(annotations_train_df, 'narratives', 'subnarratives')\n",
        "'/content/drive/MyDrive/NLP_Proj/cleaned_dev_10_january_2025/EN/subtask-2-annotations.txt'\n",
        "annotations_dev_path = '/content/drive/MyDrive/NLP_Proj/cleaned_dev_10_january_2025/EN/subtask-2-annotations.txt'\n",
        "annotations_dev_df = load_annotations(annotations_dev_path)\n",
        "expanded_dev_annotations = expand_taxonomies(annotations_dev_df, 'narratives', 'subnarratives')\n",
        "\n",
        "# View the processed annotations\n",
        "print(expanded_train_annotations.head())\n",
        "print(expanded_dev_annotations.head())\n",
        "\n"
      ],
      "metadata": {
        "id": "BP2NTbJank9C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a25a0392-756c-4a1d-eae0-5fd07f6bba63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         article_id narrative                         level_1  \\\n",
            "0  EN_CC_100013.txt        CC   Criticism of climate movement   \n",
            "1  EN_UA_300009.txt     Other                           Other   \n",
            "2  EN_UA_300017.txt     Other                           Other   \n",
            "3  EN_CC_100021.txt     Other                           Other   \n",
            "4  EN_UA_300041.txt     Other                           Other   \n",
            "\n",
            "                                level_2  \n",
            "0   Ad hominem attacks on key activists  \n",
            "1                                 Other  \n",
            "2                                 Other  \n",
            "3                                 Other  \n",
            "4                                 Other  \n",
            "             article_id narrative                            level_1  \\\n",
            "0  EN_UA_DEV_100012.txt       URW   Discrediting the West, Diplomacy   \n",
            "1  EN_UA_DEV_100012.txt       URW               Discrediting Ukraine   \n",
            "2      EN_CC_200053.txt     Other                              Other   \n",
            "3      EN_CC_200040.txt        CC      Criticism of climate movement   \n",
            "4      EN_CC_200040.txt        CC      Criticism of climate movement   \n",
            "\n",
            "                                             level_2  \n",
            "0   The West does not care about Ukraine, only ab...  \n",
            "1                  Ukraine is associated with nazism  \n",
            "2                                              Other  \n",
            "3                                              Other  \n",
            "4                       Climate movement is alarmist  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(expanded_train_annotations)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8eK6tD8ugNd",
        "outputId": "11159bcf-10f9-471b-99d6-bd7c08ae3b6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "875"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(expanded_dev_annotations)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9L99RoXWui0c",
        "outputId": "0c824797-9cd3-4985-8d00-27e8c8d3de45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "114"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Unique Classes"
      ],
      "metadata": {
        "id": "uJxYwqA6wZek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Level_1_unique = sorted(set(expanded_train_annotations['level_1']))\n",
        "Level_2_unique = sorted(set(expanded_train_annotations['level_2']))\n",
        "\n",
        "print(len(Level_1_unique), Level_1_unique)\n",
        "print(len(Level_2_unique), Level_2_unique)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QokDXSY7wck8",
        "outputId": "bc43381f-5835-4e7f-d53b-cd61fb42312a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20 [' Amplifying war-related fears', ' Blaming the war on others rather than the invader', ' Climate change is beneficial', ' Controversy about green technologies', ' Criticism of climate movement', ' Criticism of climate policies', ' Criticism of institutions and authorities', ' Discrediting Ukraine', ' Discrediting the West, Diplomacy', ' Distrust towards Media', ' Downplaying climate change', ' Green policies are geopolitical instruments', ' Hidden plots by secret schemes of powerful groups', ' Negative Consequences for the West', ' Overpraising the West', ' Praise of Russia', ' Questioning the measurements and science', ' Russia is the Victim', ' Speculating war outcomes', 'Other']\n",
            "44 [' Ad hominem attacks on key activists', ' Blaming global elites', ' By continuing the war we risk WWIII', ' CO2 is beneficial', ' Climate agenda has hidden motives', ' Climate movement is alarmist', ' Climate movement is corrupt', ' Climate policies are only for profit', ' Climate policies have negative impact on the economy', ' Climate-related international relations are abusive/exploitative', ' Criticism of international entities', ' Criticism of national governments', ' Criticism of political organizations and figures', ' Data shows no temperature increase', ' Diplomacy does/will not work', ' Discrediting Ukrainian government and officials and policies', ' Discrediting Ukrainian military', ' Discrediting Ukrainian nation and society', ' Human activities do not impact climate change', ' Methodologies/metrics used are unreliable/faulty', ' Other', ' Praise of Russian President Vladimir Putin', ' Praise of Russian military might', ' Renewable energy is costly', ' Renewable energy is dangerous', ' Russia is a guarantor of peace and prosperity', ' Russian army is collapsing', ' Sanctions imposed by Western countries will backfire', ' Scientific community is unreliable', ' Situation in Ukraine is hopeless', ' The EU is divided', ' The West are the aggressors', ' The West belongs in the right side of history', ' The West does not care about Ukraine, only about its interests', ' The West is russophobic', ' The West is weak', ' There is a real possibility that nuclear weapons will be employed', ' Ukraine is a hub for criminal activities', ' Ukraine is a puppet of the West', ' Ukraine is associated with nazism', ' Ukraine is the aggressor', ' Ukrainian army is collapsing', ' Western media is an instrument of propaganda', 'Other']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Level_1_unique = sorted(set(expanded_dev_annotations['level_1']))\n",
        "Level_2_unique = sorted(set(expanded_dev_annotations['level_2']))\n",
        "\n",
        "print(len(Level_1_unique), Level_1_unique)\n",
        "print(len(Level_2_unique), Level_2_unique)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQMglk0YM68O",
        "outputId": "0748e74a-4d29-4d2f-ec40-d85e4aee778f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20 [' Amplifying war-related fears', ' Blaming the war on others rather than the invader', ' Climate change is beneficial', ' Controversy about green technologies', ' Criticism of climate movement', ' Criticism of climate policies', ' Criticism of institutions and authorities', ' Discrediting Ukraine', ' Discrediting the West, Diplomacy', ' Distrust towards Media', ' Downplaying climate change', ' Green policies are geopolitical instruments', ' Hidden plots by secret schemes of powerful groups', ' Negative Consequences for the West', ' Overpraising the West', ' Praise of Russia', ' Questioning the measurements and science', ' Russia is the Victim', ' Speculating war outcomes', 'Other']\n",
            "59 [' Ad hominem attacks on key activists', ' Blaming global elites', ' By continuing the war we risk WWIII', ' CO2 concentrations are too small to have an impact', ' CO2 is beneficial', ' Climate agenda has hidden motives', ' Climate cycles are natural', ' Climate movement is alarmist', ' Climate movement is corrupt', ' Climate policies are ineffective', ' Climate policies are only for profit', ' Climate policies have negative impact on the economy', ' Criticism of international entities', ' Criticism of national governments', ' Criticism of political organizations and figures', ' Criticism of the EU', ' Diplomacy does/will not work', ' Discrediting Ukrainian government and officials and policies', ' Discrediting Ukrainian military', ' Green activities are a form of neo-colonialism', ' Greenhouse effect/carbon dioxide do not drive climate change', ' Ice is not melting', ' Methodologies/metrics used are unreliable/faulty', ' NATO should/will directly intervene', ' Other', ' Praise of Russian President Vladimir Putin', ' Praise of Russian military might', ' Renewable energy is costly', ' Renewable energy is dangerous', ' Renewable energy is unreliable', ' Russia actions in Ukraine are only self-defence', ' Russia has international support from a number of countries and people', ' Russia is a guarantor of peace and prosperity', ' Russia will also attack other countries', ' Russian army is collapsing', ' Russian invasion has strong national support', ' Sanctions imposed by Western countries will backfire', ' Scientific community is unreliable', ' Situation in Ukraine is hopeless', ' The EU is divided', ' The West are the aggressors', ' The West belongs in the right side of history', ' The West does not care about Ukraine, only about its interests', ' The West has the strongest international support', ' The West is overreacting', ' The West is russophobic', ' The West is weak', ' The conflict will increase the Ukrainian refugee flows to Europe', ' There is a real possibility that nuclear weapons will be employed', ' UA is anti-RU extremists', ' Ukraine is a hub for criminal activities', ' Ukraine is a puppet of the West', ' Ukraine is associated with nazism', ' Ukraine is the aggressor', ' Ukrainian army is collapsing', ' Ukrainian media cannot be trusted', ' West is tired of Ukraine', ' Western media is an instrument of propaganda', 'Other']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Group Level 1 classes by Narrative classes\n",
        "narrative_to_level_1_mapping = (\n",
        "    expanded_train_annotations.groupby('narrative')['level_1']\n",
        "    .apply(lambda x: sorted(x.unique()))  # Get unique Level 1 classes for each Narrative\n",
        "    .to_dict()  # Convert to dictionary\n",
        ")\n",
        "\n",
        "print(\"Narrative to Level 1 Mapping:\", narrative_to_level_1_mapping)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNGRNwGpxPh5",
        "outputId": "90de31b4-3f7d-488e-bd5e-4e1f08bc2a8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Narrative to Level 1 Mapping: {'CC': [' Amplifying Climate Fears', ' Climate change is beneficial', ' Controversy about green technologies', ' Criticism of climate movement', ' Criticism of climate policies', ' Criticism of institutions and authorities', ' Downplaying climate change', ' Green policies are geopolitical instruments', ' Hidden plots by secret schemes of powerful groups', ' Questioning the measurements and science'], 'Other': ['Other'], 'URW': [' Amplifying war-related fears', ' Blaming the war on others rather than the invader', ' Discrediting Ukraine', ' Discrediting the West, Diplomacy', ' Distrust towards Media', ' Hidden plots by secret schemes of powerful groups', ' Negative Consequences for the West', ' Overpraising the West', ' Praise of Russia', ' Russia is the Victim', ' Speculating war outcomes']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Group Level 2 classes by Level 1 Taxonomy\n",
        "narrative_to_level_2_mapping = (\n",
        "    expanded_annotations.groupby('level_1')['level_2']\n",
        "    .apply(lambda x: sorted(x.unique()))  # Get unique Level 2 classes for each Level 1\n",
        "    .to_dict()  # Convert to dictionary\n",
        ")\n",
        "\n",
        "print(\"Narrative to Level 2 Mapping:\", narrative_to_level_2_mapping)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRUg4wMVxeKL",
        "outputId": "c353030c-5d4f-41a4-8739-8417cc1df193"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Narrative to Level 2 Mapping: {' Amplifying war-related fears': [' By continuing the war we risk WWIII', ' NATO should/will directly intervene', ' Other', ' Russia will also attack other countries', ' There is a real possibility that nuclear weapons will be employed'], ' Blaming the war on others rather than the invader': [' The West are the aggressors', ' Ukraine is the aggressor'], ' Climate change is beneficial': [' CO2 is beneficial'], ' Controversy about green technologies': [' Other', ' Renewable energy is costly', ' Renewable energy is dangerous', ' Renewable energy is unreliable'], ' Criticism of climate movement': [' Ad hominem attacks on key activists', ' Climate movement is alarmist', ' Climate movement is corrupt', ' Other'], ' Criticism of climate policies': [' Climate policies are ineffective', ' Climate policies are only for profit', ' Climate policies have negative impact on the economy', ' Other'], ' Criticism of institutions and authorities': [' Criticism of international entities', ' Criticism of national governments', ' Criticism of political organizations and figures', ' Criticism of the EU', ' Other'], ' Discrediting Ukraine': [' Discrediting Ukrainian government and officials and policies', ' Discrediting Ukrainian military', ' Situation in Ukraine is hopeless', ' Ukraine is a hub for criminal activities', ' Ukraine is a puppet of the West', ' Ukraine is associated with nazism'], ' Discrediting the West, Diplomacy': [' Diplomacy does/will not work', ' Other', ' The EU is divided', ' The West does not care about Ukraine, only about its interests', ' The West is overreacting', ' The West is weak', ' West is tired of Ukraine'], ' Distrust towards Media': [' Ukrainian media cannot be trusted', ' Western media is an instrument of propaganda'], ' Downplaying climate change': [' CO2 concentrations are too small to have an impact', ' Climate cycles are natural', ' Ice is not melting'], ' Green policies are geopolitical instruments': [' Green activities are a form of neo-colonialism'], ' Hidden plots by secret schemes of powerful groups': [' Blaming global elites', ' Climate agenda has hidden motives', ' Other'], ' Negative Consequences for the West': [' Other', ' Sanctions imposed by Western countries will backfire', ' The conflict will increase the Ukrainian refugee flows to Europe'], ' Overpraising the West': [' The West belongs in the right side of history', ' The West has the strongest international support'], ' Praise of Russia': [' Other', ' Praise of Russian President Vladimir Putin', ' Praise of Russian military might', ' Russia has international support from a number of countries and people', ' Russia is a guarantor of peace and prosperity', ' Russian invasion has strong national support'], ' Questioning the measurements and science': [' Greenhouse effect/carbon dioxide do not drive climate change', ' Methodologies/metrics used are unreliable/faulty', ' Other', ' Scientific community is unreliable'], ' Russia is the Victim': [' Other', ' Russia actions in Ukraine are only self-defence', ' The West is russophobic', ' UA is anti-RU extremists'], ' Speculating war outcomes': [' Other', ' Russian army is collapsing', ' Ukrainian army is collapsing'], 'Other': ['Other']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### One-hot the article names."
      ],
      "metadata": {
        "id": "EhOn-CZGn9OW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to encode article IDs for train and dev datasets\n",
        "def encode_article_ids_sequentially(train_annotations, train_articles, dev_annotations, dev_articles):\n",
        "    # Get unique article IDs for train and dev\n",
        "    train_article_ids = sorted(set(train_annotations['article_id']).union(set(train_articles['article_id'])))\n",
        "    dev_article_ids = sorted(set(dev_annotations['article_id']).union(set(dev_articles['article_id'])))\n",
        "\n",
        "    # Create encoding maps\n",
        "    # Train article IDs start from 1\n",
        "    train_encode_map = {article: idx + 1 for idx, article in enumerate(train_article_ids)}\n",
        "    # Dev article IDs continue from the last train ID\n",
        "    dev_encode_map = {article: idx + 1 + len(train_article_ids) for idx, article in enumerate(dev_article_ids)}\n",
        "\n",
        "    # Combine the maps for decoding purposes\n",
        "    decode_map = {**{idx: article for article, idx in train_encode_map.items()},\n",
        "                  **{idx: article for article, idx in dev_encode_map.items()}}\n",
        "\n",
        "    # Apply encoding\n",
        "    train_annotations['article_id'] = train_annotations['article_id'].map(train_encode_map)\n",
        "    train_articles['article_id'] = train_articles['article_id'].map(train_encode_map)\n",
        "    dev_annotations['article_id'] = dev_annotations['article_id'].map(dev_encode_map)\n",
        "    dev_articles['article_id'] = dev_articles['article_id'].map(dev_encode_map)\n",
        "\n",
        "    return dev_annotations, train_annotations, dev_articles, train_articles, train_encode_map, dev_encode_map, decode_map\n",
        "\n",
        "\n",
        "# Encode article IDs sequentially for train and dev datasets\n",
        "expanded_dev_annotations, expanded_train_annotations, dev_articles, train_articles, train_encode_map, dev_encode_map, decode_map = encode_article_ids_sequentially(\n",
        "    expanded_train_annotations, train_articles, expanded_dev_annotations, dev_articles\n",
        ")\n",
        "\n",
        "# Print encode maps for reference\n",
        "print(\"Train Encode Map:\", train_encode_map)\n",
        "print(\"Dev Encode Map:\", dev_encode_map)\n",
        "print(\"Decode Map:\", decode_map)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTzrAGGcOZVm",
        "outputId": "97b8e878-dd7b-4ddc-9a06-ce5bc8dea247"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Encode Map: {'EN_CC_100000.txt': 1, 'EN_CC_100002.txt': 2, 'EN_CC_100003.txt': 3, 'EN_CC_100004.txt': 4, 'EN_CC_100005.txt': 5, 'EN_CC_100007.txt': 6, 'EN_CC_100008.txt': 7, 'EN_CC_100009.txt': 8, 'EN_CC_100010.txt': 9, 'EN_CC_100011.txt': 10, 'EN_CC_100012.txt': 11, 'EN_CC_100013.txt': 12, 'EN_CC_100014.txt': 13, 'EN_CC_100015.txt': 14, 'EN_CC_100016.txt': 15, 'EN_CC_100021.txt': 16, 'EN_CC_100023.txt': 17, 'EN_CC_100024.txt': 18, 'EN_CC_100028.txt': 19, 'EN_CC_100030.txt': 20, 'EN_CC_100034.txt': 21, 'EN_CC_100035.txt': 22, 'EN_CC_100036.txt': 23, 'EN_CC_100037.txt': 24, 'EN_CC_100038.txt': 25, 'EN_CC_100040.txt': 26, 'EN_CC_100042.txt': 27, 'EN_CC_100044.txt': 28, 'EN_CC_100046.txt': 29, 'EN_CC_100047.txt': 30, 'EN_CC_100050.txt': 31, 'EN_CC_100054.txt': 32, 'EN_CC_100065.txt': 33, 'EN_CC_100066.txt': 34, 'EN_CC_100067.txt': 35, 'EN_CC_100069.txt': 36, 'EN_CC_100070.txt': 37, 'EN_CC_100076.txt': 38, 'EN_CC_100083.txt': 39, 'EN_CC_100091.txt': 40, 'EN_CC_100093.txt': 41, 'EN_CC_100095.txt': 42, 'EN_CC_100098.txt': 43, 'EN_CC_100106.txt': 44, 'EN_CC_100122.txt': 45, 'EN_CC_100123.txt': 46, 'EN_CC_100124.txt': 47, 'EN_CC_100136.txt': 48, 'EN_CC_100137.txt': 49, 'EN_CC_100139.txt': 50, 'EN_CC_100145.txt': 51, 'EN_CC_100146.txt': 52, 'EN_CC_100147.txt': 53, 'EN_CC_100150.txt': 54, 'EN_CC_100156.txt': 55, 'EN_CC_100159.txt': 56, 'EN_CC_100169.txt': 57, 'EN_CC_100172.txt': 58, 'EN_CC_100197.txt': 59, 'EN_CC_100198.txt': 60, 'EN_CC_100203.txt': 61, 'EN_CC_100211.txt': 62, 'EN_CC_100213.txt': 63, 'EN_CC_100223.txt': 64, 'EN_CC_100232.txt': 65, 'EN_CC_100235.txt': 66, 'EN_CC_100243.txt': 67, 'EN_CC_200001.txt': 68, 'EN_CC_200007.txt': 69, 'EN_CC_200009.txt': 70, 'EN_CC_200012.txt': 71, 'EN_CC_200013.txt': 72, 'EN_CC_200015.txt': 73, 'EN_CC_200016.txt': 74, 'EN_CC_200018.txt': 75, 'EN_CC_200021.txt': 76, 'EN_CC_200022.txt': 77, 'EN_CC_200024.txt': 78, 'EN_CC_200025.txt': 79, 'EN_CC_200029.txt': 80, 'EN_CC_200041.txt': 81, 'EN_CC_200044.txt': 82, 'EN_CC_200048.txt': 83, 'EN_CC_200052.txt': 84, 'EN_CC_200055.txt': 85, 'EN_CC_200056.txt': 86, 'EN_CC_200058.txt': 87, 'EN_CC_200073.txt': 88, 'EN_CC_200083.txt': 89, 'EN_CC_200086.txt': 90, 'EN_CC_200092.txt': 91, 'EN_CC_200093.txt': 92, 'EN_CC_200097.txt': 93, 'EN_CC_200098.txt': 94, 'EN_CC_200101.txt': 95, 'EN_CC_200104.txt': 96, 'EN_CC_200105.txt': 97, 'EN_CC_200107.txt': 98, 'EN_CC_200110.txt': 99, 'EN_CC_200113.txt': 100, 'EN_CC_200116.txt': 101, 'EN_CC_200132.txt': 102, 'EN_CC_200134.txt': 103, 'EN_CC_200137.txt': 104, 'EN_CC_200139.txt': 105, 'EN_CC_200141.txt': 106, 'EN_CC_200144.txt': 107, 'EN_CC_200145.txt': 108, 'EN_CC_200150.txt': 109, 'EN_CC_200152.txt': 110, 'EN_CC_200154.txt': 111, 'EN_CC_200159.txt': 112, 'EN_CC_200165.txt': 113, 'EN_CC_200166.txt': 114, 'EN_CC_200168.txt': 115, 'EN_CC_200181.txt': 116, 'EN_CC_200188.txt': 117, 'EN_CC_200191.txt': 118, 'EN_CC_200211.txt': 119, 'EN_CC_200218.txt': 120, 'EN_CC_200221.txt': 121, 'EN_CC_200227.txt': 122, 'EN_CC_200234.txt': 123, 'EN_CC_200242.txt': 124, 'EN_CC_200245.txt': 125, 'EN_CC_200246.txt': 126, 'EN_CC_200254.txt': 127, 'EN_CC_200262.txt': 128, 'EN_CC_200270.txt': 129, 'EN_CC_200278.txt': 130, 'EN_CC_200279.txt': 131, 'EN_CC_200285.txt': 132, 'EN_CC_200289.txt': 133, 'EN_CC_200292.txt': 134, 'EN_CC_200294.txt': 135, 'EN_CC_200318.txt': 136, 'EN_CC_200321.txt': 137, 'EN_CC_200324.txt': 138, 'EN_CC_200326.txt': 139, 'EN_CC_200327.txt': 140, 'EN_CC_200337.txt': 141, 'EN_CC_200342.txt': 142, 'EN_CC_200343.txt': 143, 'EN_CC_200344.txt': 144, 'EN_CC_200349.txt': 145, 'EN_CC_300001.txt': 146, 'EN_CC_300003.txt': 147, 'EN_CC_300004.txt': 148, 'EN_CC_300005.txt': 149, 'EN_CC_300006.txt': 150, 'EN_CC_300008.txt': 151, 'EN_CC_300010.txt': 152, 'EN_CC_300017.txt': 153, 'EN_CC_300018.txt': 154, 'EN_CC_300022.txt': 155, 'EN_CC_300023.txt': 156, 'EN_CC_300028.txt': 157, 'EN_CC_300030.txt': 158, 'EN_CC_300031.txt': 159, 'EN_CC_300037.txt': 160, 'EN_CC_300038.txt': 161, 'EN_CC_300040.txt': 162, 'EN_CC_300052.txt': 163, 'EN_CC_300054.txt': 164, 'EN_CC_300057.txt': 165, 'EN_CC_300064.txt': 166, 'EN_CC_300074.txt': 167, 'EN_CC_300088.txt': 168, 'EN_CC_300112.txt': 169, 'EN_CC_300114.txt': 170, 'EN_CC_300124.txt': 171, 'EN_CC_300125.txt': 172, 'EN_CC_300134.txt': 173, 'EN_CC_300151.txt': 174, 'EN_CC_300158.txt': 175, 'EN_CC_300179.txt': 176, 'EN_UA_000104.txt': 177, 'EN_UA_000543.txt': 178, 'EN_UA_000568.txt': 179, 'EN_UA_000923.txt': 180, 'EN_UA_001032.txt': 181, 'EN_UA_001052.txt': 182, 'EN_UA_002416.txt': 183, 'EN_UA_002531.txt': 184, 'EN_UA_002668.txt': 185, 'EN_UA_002991.txt': 186, 'EN_UA_003579.txt': 187, 'EN_UA_004209.txt': 188, 'EN_UA_004343.txt': 189, 'EN_UA_004616.txt': 190, 'EN_UA_008072.txt': 191, 'EN_UA_008586.txt': 192, 'EN_UA_010091.txt': 193, 'EN_UA_010095.txt': 194, 'EN_UA_010735.txt': 195, 'EN_UA_010901.txt': 196, 'EN_UA_010909.txt': 197, 'EN_UA_011260.txt': 198, 'EN_UA_012234.txt': 199, 'EN_UA_012611.txt': 200, 'EN_UA_012803.txt': 201, 'EN_UA_013257.txt': 202, 'EN_UA_013344.txt': 203, 'EN_UA_013617.txt': 204, 'EN_UA_013710.txt': 205, 'EN_UA_013727.txt': 206, 'EN_UA_014014.txt': 207, 'EN_UA_014413.txt': 208, 'EN_UA_014637.txt': 209, 'EN_UA_014829.txt': 210, 'EN_UA_015443.txt': 211, 'EN_UA_015880.txt': 212, 'EN_UA_015962.txt': 213, 'EN_UA_016012.txt': 214, 'EN_UA_016466.txt': 215, 'EN_UA_017310.txt': 216, 'EN_UA_017831.txt': 217, 'EN_UA_018789.txt': 218, 'EN_UA_019640.txt': 219, 'EN_UA_020543.txt': 220, 'EN_UA_021123.txt': 221, 'EN_UA_021263.txt': 222, 'EN_UA_021270.txt': 223, 'EN_UA_021310.txt': 224, 'EN_UA_021377.txt': 225, 'EN_UA_021872.txt': 226, 'EN_UA_021918.txt': 227, 'EN_UA_022016.txt': 228, 'EN_UA_022051.txt': 229, 'EN_UA_022319.txt': 230, 'EN_UA_022339.txt': 231, 'EN_UA_023008.txt': 232, 'EN_UA_023211.txt': 233, 'EN_UA_023816.txt': 234, 'EN_UA_024050.txt': 235, 'EN_UA_024321.txt': 236, 'EN_UA_024628.txt': 237, 'EN_UA_024847.txt': 238, 'EN_UA_025165.txt': 239, 'EN_UA_025652.txt': 240, 'EN_UA_025764.txt': 241, 'EN_UA_026036.txt': 242, 'EN_UA_026142.txt': 243, 'EN_UA_026697.txt': 244, 'EN_UA_026740.txt': 245, 'EN_UA_027676.txt': 246, 'EN_UA_027787.txt': 247, 'EN_UA_027816.txt': 248, 'EN_UA_027879.txt': 249, 'EN_UA_028103.txt': 250, 'EN_UA_028520.txt': 251, 'EN_UA_029053.txt': 252, 'EN_UA_029155.txt': 253, 'EN_UA_100106.txt': 254, 'EN_UA_100210.txt': 255, 'EN_UA_100411.txt': 256, 'EN_UA_100587.txt': 257, 'EN_UA_100601.txt': 258, 'EN_UA_100688.txt': 259, 'EN_UA_100840.txt': 260, 'EN_UA_100864.txt': 261, 'EN_UA_100868.txt': 262, 'EN_UA_101067.txt': 263, 'EN_UA_101079.txt': 264, 'EN_UA_101189.txt': 265, 'EN_UA_101251.txt': 266, 'EN_UA_101805.txt': 267, 'EN_UA_101954.txt': 268, 'EN_UA_101996.txt': 269, 'EN_UA_102034.txt': 270, 'EN_UA_102054.txt': 271, 'EN_UA_102084.txt': 272, 'EN_UA_102415.txt': 273, 'EN_UA_102655.txt': 274, 'EN_UA_102703.txt': 275, 'EN_UA_102754.txt': 276, 'EN_UA_102892.txt': 277, 'EN_UA_102953.txt': 278, 'EN_UA_102958.txt': 279, 'EN_UA_102963.txt': 280, 'EN_UA_102990.txt': 281, 'EN_UA_103011.txt': 282, 'EN_UA_103025.txt': 283, 'EN_UA_103168.txt': 284, 'EN_UA_103251.txt': 285, 'EN_UA_103372.txt': 286, 'EN_UA_103403.txt': 287, 'EN_UA_103445.txt': 288, 'EN_UA_103517.txt': 289, 'EN_UA_103667.txt': 290, 'EN_UA_103732.txt': 291, 'EN_UA_103861.txt': 292, 'EN_UA_103941.txt': 293, 'EN_UA_103995.txt': 294, 'EN_UA_104152.txt': 295, 'EN_UA_104224.txt': 296, 'EN_UA_104434.txt': 297, 'EN_UA_104523.txt': 298, 'EN_UA_104569.txt': 299, 'EN_UA_104604.txt': 300, 'EN_UA_104775.txt': 301, 'EN_UA_104791.txt': 302, 'EN_UA_104859.txt': 303, 'EN_UA_104876.txt': 304, 'EN_UA_300000.txt': 305, 'EN_UA_300001.txt': 306, 'EN_UA_300005.txt': 307, 'EN_UA_300006.txt': 308, 'EN_UA_300007.txt': 309, 'EN_UA_300009.txt': 310, 'EN_UA_300010.txt': 311, 'EN_UA_300011.txt': 312, 'EN_UA_300012.txt': 313, 'EN_UA_300013.txt': 314, 'EN_UA_300015.txt': 315, 'EN_UA_300016.txt': 316, 'EN_UA_300017.txt': 317, 'EN_UA_300018.txt': 318, 'EN_UA_300019.txt': 319, 'EN_UA_300020.txt': 320, 'EN_UA_300022.txt': 321, 'EN_UA_300023.txt': 322, 'EN_UA_300025.txt': 323, 'EN_UA_300028.txt': 324, 'EN_UA_300029.txt': 325, 'EN_UA_300030.txt': 326, 'EN_UA_300031.txt': 327, 'EN_UA_300032.txt': 328, 'EN_UA_300034.txt': 329, 'EN_UA_300035.txt': 330, 'EN_UA_300036.txt': 331, 'EN_UA_300037.txt': 332, 'EN_UA_300038.txt': 333, 'EN_UA_300039.txt': 334, 'EN_UA_300040.txt': 335, 'EN_UA_300041.txt': 336, 'EN_UA_300043.txt': 337, 'EN_UA_300044.txt': 338, 'EN_UA_300045.txt': 339, 'EN_UA_300046.txt': 340, 'EN_UA_300048.txt': 341, 'EN_UA_300049.txt': 342, 'EN_UA_300050.txt': 343, 'EN_UA_300051.txt': 344, 'EN_UA_300052.txt': 345, 'EN_UA_300053.txt': 346, 'EN_UA_300058.txt': 347, 'EN_UA_300059.txt': 348, 'EN_UA_300060.txt': 349, 'EN_UA_300063.txt': 350, 'EN_UA_300065.txt': 351, 'EN_UA_300066.txt': 352, 'EN_UA_300067.txt': 353, 'EN_UA_300069.txt': 354, 'EN_UA_300070.txt': 355, 'EN_UA_300071.txt': 356, 'EN_UA_300073.txt': 357, 'EN_UA_300074.txt': 358, 'EN_UA_300075.txt': 359, 'EN_UA_300076.txt': 360, 'EN_UA_300077.txt': 361, 'EN_UA_300079.txt': 362, 'EN_UA_300080.txt': 363, 'EN_UA_300082.txt': 364, 'EN_UA_300084.txt': 365, 'EN_UA_300085.txt': 366, 'EN_UA_300086.txt': 367, 'EN_UA_300089.txt': 368, 'EN_UA_300090.txt': 369, 'EN_UA_300092.txt': 370, 'EN_UA_300099.txt': 371, 'EN_UA_300100.txt': 372, 'EN_UA_300102.txt': 373, 'EN_UA_300103.txt': 374, 'EN_UA_300104.txt': 375, 'EN_UA_300108.txt': 376, 'EN_UA_300115.txt': 377, 'EN_UA_300117.txt': 378, 'EN_UA_300120.txt': 379, 'EN_UA_300127.txt': 380, 'EN_UA_300129.txt': 381, 'EN_UA_300132.txt': 382, 'EN_UA_300133.txt': 383, 'EN_UA_300134.txt': 384, 'EN_UA_300135.txt': 385, 'EN_UA_300139.txt': 386, 'EN_UA_300141.txt': 387, 'EN_UA_300142.txt': 388, 'EN_UA_300144.txt': 389, 'EN_UA_300145.txt': 390, 'EN_UA_300150.txt': 391, 'EN_UA_300153.txt': 392, 'EN_UA_300154.txt': 393, 'EN_UA_300156.txt': 394, 'EN_UA_DEV_100028.txt': 395, 'EN_UA_DEV_216.txt': 396, 'EN_UA_DEV_23.txt': 397, 'EN_UA_DEV_24.txt': 398, 'EN_UA_DEV_26.txt': 399}\n",
            "Dev Encode Map: {'EN_CC_200030.txt': 400, 'EN_CC_200033.txt': 401, 'EN_CC_200034.txt': 402, 'EN_CC_200035.txt': 403, 'EN_CC_200036.txt': 404, 'EN_CC_200040.txt': 405, 'EN_CC_200046.txt': 406, 'EN_CC_200047.txt': 407, 'EN_CC_200049.txt': 408, 'EN_CC_200050.txt': 409, 'EN_CC_200053.txt': 410, 'EN_CC_200054.txt': 411, 'EN_CC_200060.txt': 412, 'EN_CC_200063.txt': 413, 'EN_CC_200064.txt': 414, 'EN_CC_200065.txt': 415, 'EN_CC_200069.txt': 416, 'EN_CC_200070.txt': 417, 'EN_CC_200071.txt': 418, 'EN_CC_200077.txt': 419, 'EN_CC_200078.txt': 420, 'EN_CC_200079.txt': 421, 'EN_CC_200081.txt': 422, 'EN_CC_200085.txt': 423, 'EN_UA_DEV_100002.txt': 424, 'EN_UA_DEV_100003.txt': 425, 'EN_UA_DEV_100004.txt': 426, 'EN_UA_DEV_100005.txt': 427, 'EN_UA_DEV_100012.txt': 428, 'EN_UA_DEV_100013.txt': 429, 'EN_UA_DEV_100019.txt': 430, 'EN_UA_DEV_100026.txt': 431, 'EN_UA_DEV_100029.txt': 432, 'EN_UA_DEV_100033.txt': 433, 'EN_UA_DEV_100034.txt': 434, 'EN_UA_DEV_100036.txt': 435, 'EN_UA_DEV_20.txt': 436, 'EN_UA_DEV_213.txt': 437, 'EN_UA_DEV_214.txt': 438, 'EN_UA_DEV_215.txt': 439, 'EN_UA_DEV_22.txt': 440}\n",
            "Decode Map: {1: 'EN_CC_100000.txt', 2: 'EN_CC_100002.txt', 3: 'EN_CC_100003.txt', 4: 'EN_CC_100004.txt', 5: 'EN_CC_100005.txt', 6: 'EN_CC_100007.txt', 7: 'EN_CC_100008.txt', 8: 'EN_CC_100009.txt', 9: 'EN_CC_100010.txt', 10: 'EN_CC_100011.txt', 11: 'EN_CC_100012.txt', 12: 'EN_CC_100013.txt', 13: 'EN_CC_100014.txt', 14: 'EN_CC_100015.txt', 15: 'EN_CC_100016.txt', 16: 'EN_CC_100021.txt', 17: 'EN_CC_100023.txt', 18: 'EN_CC_100024.txt', 19: 'EN_CC_100028.txt', 20: 'EN_CC_100030.txt', 21: 'EN_CC_100034.txt', 22: 'EN_CC_100035.txt', 23: 'EN_CC_100036.txt', 24: 'EN_CC_100037.txt', 25: 'EN_CC_100038.txt', 26: 'EN_CC_100040.txt', 27: 'EN_CC_100042.txt', 28: 'EN_CC_100044.txt', 29: 'EN_CC_100046.txt', 30: 'EN_CC_100047.txt', 31: 'EN_CC_100050.txt', 32: 'EN_CC_100054.txt', 33: 'EN_CC_100065.txt', 34: 'EN_CC_100066.txt', 35: 'EN_CC_100067.txt', 36: 'EN_CC_100069.txt', 37: 'EN_CC_100070.txt', 38: 'EN_CC_100076.txt', 39: 'EN_CC_100083.txt', 40: 'EN_CC_100091.txt', 41: 'EN_CC_100093.txt', 42: 'EN_CC_100095.txt', 43: 'EN_CC_100098.txt', 44: 'EN_CC_100106.txt', 45: 'EN_CC_100122.txt', 46: 'EN_CC_100123.txt', 47: 'EN_CC_100124.txt', 48: 'EN_CC_100136.txt', 49: 'EN_CC_100137.txt', 50: 'EN_CC_100139.txt', 51: 'EN_CC_100145.txt', 52: 'EN_CC_100146.txt', 53: 'EN_CC_100147.txt', 54: 'EN_CC_100150.txt', 55: 'EN_CC_100156.txt', 56: 'EN_CC_100159.txt', 57: 'EN_CC_100169.txt', 58: 'EN_CC_100172.txt', 59: 'EN_CC_100197.txt', 60: 'EN_CC_100198.txt', 61: 'EN_CC_100203.txt', 62: 'EN_CC_100211.txt', 63: 'EN_CC_100213.txt', 64: 'EN_CC_100223.txt', 65: 'EN_CC_100232.txt', 66: 'EN_CC_100235.txt', 67: 'EN_CC_100243.txt', 68: 'EN_CC_200001.txt', 69: 'EN_CC_200007.txt', 70: 'EN_CC_200009.txt', 71: 'EN_CC_200012.txt', 72: 'EN_CC_200013.txt', 73: 'EN_CC_200015.txt', 74: 'EN_CC_200016.txt', 75: 'EN_CC_200018.txt', 76: 'EN_CC_200021.txt', 77: 'EN_CC_200022.txt', 78: 'EN_CC_200024.txt', 79: 'EN_CC_200025.txt', 80: 'EN_CC_200029.txt', 81: 'EN_CC_200041.txt', 82: 'EN_CC_200044.txt', 83: 'EN_CC_200048.txt', 84: 'EN_CC_200052.txt', 85: 'EN_CC_200055.txt', 86: 'EN_CC_200056.txt', 87: 'EN_CC_200058.txt', 88: 'EN_CC_200073.txt', 89: 'EN_CC_200083.txt', 90: 'EN_CC_200086.txt', 91: 'EN_CC_200092.txt', 92: 'EN_CC_200093.txt', 93: 'EN_CC_200097.txt', 94: 'EN_CC_200098.txt', 95: 'EN_CC_200101.txt', 96: 'EN_CC_200104.txt', 97: 'EN_CC_200105.txt', 98: 'EN_CC_200107.txt', 99: 'EN_CC_200110.txt', 100: 'EN_CC_200113.txt', 101: 'EN_CC_200116.txt', 102: 'EN_CC_200132.txt', 103: 'EN_CC_200134.txt', 104: 'EN_CC_200137.txt', 105: 'EN_CC_200139.txt', 106: 'EN_CC_200141.txt', 107: 'EN_CC_200144.txt', 108: 'EN_CC_200145.txt', 109: 'EN_CC_200150.txt', 110: 'EN_CC_200152.txt', 111: 'EN_CC_200154.txt', 112: 'EN_CC_200159.txt', 113: 'EN_CC_200165.txt', 114: 'EN_CC_200166.txt', 115: 'EN_CC_200168.txt', 116: 'EN_CC_200181.txt', 117: 'EN_CC_200188.txt', 118: 'EN_CC_200191.txt', 119: 'EN_CC_200211.txt', 120: 'EN_CC_200218.txt', 121: 'EN_CC_200221.txt', 122: 'EN_CC_200227.txt', 123: 'EN_CC_200234.txt', 124: 'EN_CC_200242.txt', 125: 'EN_CC_200245.txt', 126: 'EN_CC_200246.txt', 127: 'EN_CC_200254.txt', 128: 'EN_CC_200262.txt', 129: 'EN_CC_200270.txt', 130: 'EN_CC_200278.txt', 131: 'EN_CC_200279.txt', 132: 'EN_CC_200285.txt', 133: 'EN_CC_200289.txt', 134: 'EN_CC_200292.txt', 135: 'EN_CC_200294.txt', 136: 'EN_CC_200318.txt', 137: 'EN_CC_200321.txt', 138: 'EN_CC_200324.txt', 139: 'EN_CC_200326.txt', 140: 'EN_CC_200327.txt', 141: 'EN_CC_200337.txt', 142: 'EN_CC_200342.txt', 143: 'EN_CC_200343.txt', 144: 'EN_CC_200344.txt', 145: 'EN_CC_200349.txt', 146: 'EN_CC_300001.txt', 147: 'EN_CC_300003.txt', 148: 'EN_CC_300004.txt', 149: 'EN_CC_300005.txt', 150: 'EN_CC_300006.txt', 151: 'EN_CC_300008.txt', 152: 'EN_CC_300010.txt', 153: 'EN_CC_300017.txt', 154: 'EN_CC_300018.txt', 155: 'EN_CC_300022.txt', 156: 'EN_CC_300023.txt', 157: 'EN_CC_300028.txt', 158: 'EN_CC_300030.txt', 159: 'EN_CC_300031.txt', 160: 'EN_CC_300037.txt', 161: 'EN_CC_300038.txt', 162: 'EN_CC_300040.txt', 163: 'EN_CC_300052.txt', 164: 'EN_CC_300054.txt', 165: 'EN_CC_300057.txt', 166: 'EN_CC_300064.txt', 167: 'EN_CC_300074.txt', 168: 'EN_CC_300088.txt', 169: 'EN_CC_300112.txt', 170: 'EN_CC_300114.txt', 171: 'EN_CC_300124.txt', 172: 'EN_CC_300125.txt', 173: 'EN_CC_300134.txt', 174: 'EN_CC_300151.txt', 175: 'EN_CC_300158.txt', 176: 'EN_CC_300179.txt', 177: 'EN_UA_000104.txt', 178: 'EN_UA_000543.txt', 179: 'EN_UA_000568.txt', 180: 'EN_UA_000923.txt', 181: 'EN_UA_001032.txt', 182: 'EN_UA_001052.txt', 183: 'EN_UA_002416.txt', 184: 'EN_UA_002531.txt', 185: 'EN_UA_002668.txt', 186: 'EN_UA_002991.txt', 187: 'EN_UA_003579.txt', 188: 'EN_UA_004209.txt', 189: 'EN_UA_004343.txt', 190: 'EN_UA_004616.txt', 191: 'EN_UA_008072.txt', 192: 'EN_UA_008586.txt', 193: 'EN_UA_010091.txt', 194: 'EN_UA_010095.txt', 195: 'EN_UA_010735.txt', 196: 'EN_UA_010901.txt', 197: 'EN_UA_010909.txt', 198: 'EN_UA_011260.txt', 199: 'EN_UA_012234.txt', 200: 'EN_UA_012611.txt', 201: 'EN_UA_012803.txt', 202: 'EN_UA_013257.txt', 203: 'EN_UA_013344.txt', 204: 'EN_UA_013617.txt', 205: 'EN_UA_013710.txt', 206: 'EN_UA_013727.txt', 207: 'EN_UA_014014.txt', 208: 'EN_UA_014413.txt', 209: 'EN_UA_014637.txt', 210: 'EN_UA_014829.txt', 211: 'EN_UA_015443.txt', 212: 'EN_UA_015880.txt', 213: 'EN_UA_015962.txt', 214: 'EN_UA_016012.txt', 215: 'EN_UA_016466.txt', 216: 'EN_UA_017310.txt', 217: 'EN_UA_017831.txt', 218: 'EN_UA_018789.txt', 219: 'EN_UA_019640.txt', 220: 'EN_UA_020543.txt', 221: 'EN_UA_021123.txt', 222: 'EN_UA_021263.txt', 223: 'EN_UA_021270.txt', 224: 'EN_UA_021310.txt', 225: 'EN_UA_021377.txt', 226: 'EN_UA_021872.txt', 227: 'EN_UA_021918.txt', 228: 'EN_UA_022016.txt', 229: 'EN_UA_022051.txt', 230: 'EN_UA_022319.txt', 231: 'EN_UA_022339.txt', 232: 'EN_UA_023008.txt', 233: 'EN_UA_023211.txt', 234: 'EN_UA_023816.txt', 235: 'EN_UA_024050.txt', 236: 'EN_UA_024321.txt', 237: 'EN_UA_024628.txt', 238: 'EN_UA_024847.txt', 239: 'EN_UA_025165.txt', 240: 'EN_UA_025652.txt', 241: 'EN_UA_025764.txt', 242: 'EN_UA_026036.txt', 243: 'EN_UA_026142.txt', 244: 'EN_UA_026697.txt', 245: 'EN_UA_026740.txt', 246: 'EN_UA_027676.txt', 247: 'EN_UA_027787.txt', 248: 'EN_UA_027816.txt', 249: 'EN_UA_027879.txt', 250: 'EN_UA_028103.txt', 251: 'EN_UA_028520.txt', 252: 'EN_UA_029053.txt', 253: 'EN_UA_029155.txt', 254: 'EN_UA_100106.txt', 255: 'EN_UA_100210.txt', 256: 'EN_UA_100411.txt', 257: 'EN_UA_100587.txt', 258: 'EN_UA_100601.txt', 259: 'EN_UA_100688.txt', 260: 'EN_UA_100840.txt', 261: 'EN_UA_100864.txt', 262: 'EN_UA_100868.txt', 263: 'EN_UA_101067.txt', 264: 'EN_UA_101079.txt', 265: 'EN_UA_101189.txt', 266: 'EN_UA_101251.txt', 267: 'EN_UA_101805.txt', 268: 'EN_UA_101954.txt', 269: 'EN_UA_101996.txt', 270: 'EN_UA_102034.txt', 271: 'EN_UA_102054.txt', 272: 'EN_UA_102084.txt', 273: 'EN_UA_102415.txt', 274: 'EN_UA_102655.txt', 275: 'EN_UA_102703.txt', 276: 'EN_UA_102754.txt', 277: 'EN_UA_102892.txt', 278: 'EN_UA_102953.txt', 279: 'EN_UA_102958.txt', 280: 'EN_UA_102963.txt', 281: 'EN_UA_102990.txt', 282: 'EN_UA_103011.txt', 283: 'EN_UA_103025.txt', 284: 'EN_UA_103168.txt', 285: 'EN_UA_103251.txt', 286: 'EN_UA_103372.txt', 287: 'EN_UA_103403.txt', 288: 'EN_UA_103445.txt', 289: 'EN_UA_103517.txt', 290: 'EN_UA_103667.txt', 291: 'EN_UA_103732.txt', 292: 'EN_UA_103861.txt', 293: 'EN_UA_103941.txt', 294: 'EN_UA_103995.txt', 295: 'EN_UA_104152.txt', 296: 'EN_UA_104224.txt', 297: 'EN_UA_104434.txt', 298: 'EN_UA_104523.txt', 299: 'EN_UA_104569.txt', 300: 'EN_UA_104604.txt', 301: 'EN_UA_104775.txt', 302: 'EN_UA_104791.txt', 303: 'EN_UA_104859.txt', 304: 'EN_UA_104876.txt', 305: 'EN_UA_300000.txt', 306: 'EN_UA_300001.txt', 307: 'EN_UA_300005.txt', 308: 'EN_UA_300006.txt', 309: 'EN_UA_300007.txt', 310: 'EN_UA_300009.txt', 311: 'EN_UA_300010.txt', 312: 'EN_UA_300011.txt', 313: 'EN_UA_300012.txt', 314: 'EN_UA_300013.txt', 315: 'EN_UA_300015.txt', 316: 'EN_UA_300016.txt', 317: 'EN_UA_300017.txt', 318: 'EN_UA_300018.txt', 319: 'EN_UA_300019.txt', 320: 'EN_UA_300020.txt', 321: 'EN_UA_300022.txt', 322: 'EN_UA_300023.txt', 323: 'EN_UA_300025.txt', 324: 'EN_UA_300028.txt', 325: 'EN_UA_300029.txt', 326: 'EN_UA_300030.txt', 327: 'EN_UA_300031.txt', 328: 'EN_UA_300032.txt', 329: 'EN_UA_300034.txt', 330: 'EN_UA_300035.txt', 331: 'EN_UA_300036.txt', 332: 'EN_UA_300037.txt', 333: 'EN_UA_300038.txt', 334: 'EN_UA_300039.txt', 335: 'EN_UA_300040.txt', 336: 'EN_UA_300041.txt', 337: 'EN_UA_300043.txt', 338: 'EN_UA_300044.txt', 339: 'EN_UA_300045.txt', 340: 'EN_UA_300046.txt', 341: 'EN_UA_300048.txt', 342: 'EN_UA_300049.txt', 343: 'EN_UA_300050.txt', 344: 'EN_UA_300051.txt', 345: 'EN_UA_300052.txt', 346: 'EN_UA_300053.txt', 347: 'EN_UA_300058.txt', 348: 'EN_UA_300059.txt', 349: 'EN_UA_300060.txt', 350: 'EN_UA_300063.txt', 351: 'EN_UA_300065.txt', 352: 'EN_UA_300066.txt', 353: 'EN_UA_300067.txt', 354: 'EN_UA_300069.txt', 355: 'EN_UA_300070.txt', 356: 'EN_UA_300071.txt', 357: 'EN_UA_300073.txt', 358: 'EN_UA_300074.txt', 359: 'EN_UA_300075.txt', 360: 'EN_UA_300076.txt', 361: 'EN_UA_300077.txt', 362: 'EN_UA_300079.txt', 363: 'EN_UA_300080.txt', 364: 'EN_UA_300082.txt', 365: 'EN_UA_300084.txt', 366: 'EN_UA_300085.txt', 367: 'EN_UA_300086.txt', 368: 'EN_UA_300089.txt', 369: 'EN_UA_300090.txt', 370: 'EN_UA_300092.txt', 371: 'EN_UA_300099.txt', 372: 'EN_UA_300100.txt', 373: 'EN_UA_300102.txt', 374: 'EN_UA_300103.txt', 375: 'EN_UA_300104.txt', 376: 'EN_UA_300108.txt', 377: 'EN_UA_300115.txt', 378: 'EN_UA_300117.txt', 379: 'EN_UA_300120.txt', 380: 'EN_UA_300127.txt', 381: 'EN_UA_300129.txt', 382: 'EN_UA_300132.txt', 383: 'EN_UA_300133.txt', 384: 'EN_UA_300134.txt', 385: 'EN_UA_300135.txt', 386: 'EN_UA_300139.txt', 387: 'EN_UA_300141.txt', 388: 'EN_UA_300142.txt', 389: 'EN_UA_300144.txt', 390: 'EN_UA_300145.txt', 391: 'EN_UA_300150.txt', 392: 'EN_UA_300153.txt', 393: 'EN_UA_300154.txt', 394: 'EN_UA_300156.txt', 395: 'EN_UA_DEV_100028.txt', 396: 'EN_UA_DEV_216.txt', 397: 'EN_UA_DEV_23.txt', 398: 'EN_UA_DEV_24.txt', 399: 'EN_UA_DEV_26.txt', 400: 'EN_CC_200030.txt', 401: 'EN_CC_200033.txt', 402: 'EN_CC_200034.txt', 403: 'EN_CC_200035.txt', 404: 'EN_CC_200036.txt', 405: 'EN_CC_200040.txt', 406: 'EN_CC_200046.txt', 407: 'EN_CC_200047.txt', 408: 'EN_CC_200049.txt', 409: 'EN_CC_200050.txt', 410: 'EN_CC_200053.txt', 411: 'EN_CC_200054.txt', 412: 'EN_CC_200060.txt', 413: 'EN_CC_200063.txt', 414: 'EN_CC_200064.txt', 415: 'EN_CC_200065.txt', 416: 'EN_CC_200069.txt', 417: 'EN_CC_200070.txt', 418: 'EN_CC_200071.txt', 419: 'EN_CC_200077.txt', 420: 'EN_CC_200078.txt', 421: 'EN_CC_200079.txt', 422: 'EN_CC_200081.txt', 423: 'EN_CC_200085.txt', 424: 'EN_UA_DEV_100002.txt', 425: 'EN_UA_DEV_100003.txt', 426: 'EN_UA_DEV_100004.txt', 427: 'EN_UA_DEV_100005.txt', 428: 'EN_UA_DEV_100012.txt', 429: 'EN_UA_DEV_100013.txt', 430: 'EN_UA_DEV_100019.txt', 431: 'EN_UA_DEV_100026.txt', 432: 'EN_UA_DEV_100029.txt', 433: 'EN_UA_DEV_100033.txt', 434: 'EN_UA_DEV_100034.txt', 435: 'EN_UA_DEV_100036.txt', 436: 'EN_UA_DEV_20.txt', 437: 'EN_UA_DEV_213.txt', 438: 'EN_UA_DEV_214.txt', 439: 'EN_UA_DEV_215.txt', 440: 'EN_UA_DEV_22.txt'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "common_ids = expanded_dev_annotations['article_id'][expanded_dev_annotations['article_id'].isin(dev_articles['article_id'])]\n",
        "print(f\"Number of common article IDs: {len(common_ids)}\")\n",
        "print(\"Common article IDs:\", len(common_ids.unique()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBDWvG4bPjGi",
        "outputId": "b1b6eaa9-6519-4e36-9566-711a87934adb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of common article IDs: 114\n",
            "Common article IDs: 41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "common_ids = expanded_train_annotations['article_id'][expanded_train_annotations['article_id'].isin(train_articles['article_id'])]\n",
        "print(f\"Number of common article IDs: {len(common_ids)}\")\n",
        "print(\"Common article IDs:\", len(common_ids.unique()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3X8em0jiizHg",
        "outputId": "28e02be2-5475-4a1b-9083-a5fa1cddb98e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of common article IDs: 875\n",
            "Common article IDs: 399\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(np.unique(train_articles['article_id']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6dI3dhZiNDf",
        "outputId": "8b810c79-e6a8-47ac-e4bf-d69aa1b22c76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "399"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualization and stuff"
      ],
      "metadata": {
        "id": "8VlZfSw3v72W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fuzzywuzzy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbheWEUae4RI",
        "outputId": "6bb24fea-7306-44f2-e478-a9c047e6e66c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fuzzywuzzy in /usr/local/lib/python3.11/dist-packages (0.18.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('vader_lexicon')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('wordnet')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1165Z8-zEuC",
        "outputId": "7413fec9-32e4-4a15-eb31-5785e7cc10c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Group Level 1 classes by Narrative classes\n",
        "narrative_to_level_1_mapping = (\n",
        "    expanded_train_annotations.groupby('narrative')['level_1']\n",
        "    .apply(lambda x: sorted(x.unique()))  # Get unique Level 1 classes for each Narrative\n",
        "    .to_dict()  # Convert to dictionary\n",
        ")\n",
        "\n",
        "print(\"Narrative to Level 1 Mapping:\", narrative_to_level_1_mapping)\n",
        "\n",
        "\n",
        "# Group Level 2 classes by Level 1 Taxonomy\n",
        "narrative_to_level_2_mapping = (\n",
        "    expanded_train_annotations.groupby('level_1')['level_2']\n",
        "    .apply(lambda x: sorted(x.unique()))  # Get unique Level 2 classes for each Level 1\n",
        "    .to_dict()  # Convert to dictionary\n",
        ")\n",
        "\n",
        "print(\"Level 1 to Level 2 Mapping:\", narrative_to_level_2_mapping)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvGTfdYrccIO",
        "outputId": "9b0b0b2b-d875-4471-c00b-5c17ca387fbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Narrative to Level 1 Mapping: {'CC': [' Amplifying Climate Fears', ' Climate change is beneficial', ' Controversy about green technologies', ' Criticism of climate movement', ' Criticism of climate policies', ' Criticism of institutions and authorities', ' Downplaying climate change', ' Green policies are geopolitical instruments', ' Hidden plots by secret schemes of powerful groups', ' Questioning the measurements and science'], 'Other': ['Other'], 'URW': [' Amplifying war-related fears', ' Blaming the war on others rather than the invader', ' Discrediting Ukraine', ' Discrediting the West, Diplomacy', ' Distrust towards Media', ' Hidden plots by secret schemes of powerful groups', ' Negative Consequences for the West', ' Overpraising the West', ' Praise of Russia', ' Russia is the Victim', ' Speculating war outcomes']}\n",
            "Level 1 to Level 2 Mapping: {' Amplifying Climate Fears': [' Amplifying existing fears of global warming', ' Doomsday scenarios for humans', ' Other'], ' Amplifying war-related fears': [' By continuing the war we risk WWIII', ' NATO should/will directly intervene', ' Other', ' Russia will also attack other countries', ' There is a real possibility that nuclear weapons will be employed'], ' Blaming the war on others rather than the invader': [' The West are the aggressors', ' Ukraine is the aggressor'], ' Climate change is beneficial': [' CO2 is beneficial', ' Temperature increase is beneficial'], ' Controversy about green technologies': [' Other', ' Renewable energy is costly', ' Renewable energy is dangerous', ' Renewable energy is unreliable'], ' Criticism of climate movement': [' Ad hominem attacks on key activists', ' Climate movement is alarmist', ' Climate movement is corrupt', ' Other'], ' Criticism of climate policies': [' Climate policies are ineffective', ' Climate policies are only for profit', ' Climate policies have negative impact on the economy', ' Other'], ' Criticism of institutions and authorities': [' Criticism of international entities', ' Criticism of national governments', ' Criticism of political organizations and figures', ' Criticism of the EU', ' Other'], ' Discrediting Ukraine': [' Discrediting Ukrainian government and officials and policies', ' Discrediting Ukrainian military', ' Rewriting Ukraine’s history', ' Situation in Ukraine is hopeless', ' Ukraine is a hub for criminal activities', ' Ukraine is a puppet of the West', ' Ukraine is associated with nazism'], ' Discrediting the West, Diplomacy': [' Diplomacy does/will not work', ' Other', ' The EU is divided', ' The West does not care about Ukraine, only about its interests', ' The West is overreacting', ' The West is weak', ' West is tired of Ukraine'], ' Distrust towards Media': [' Ukrainian media cannot be trusted', ' Western media is an instrument of propaganda'], ' Downplaying climate change': [' CO2 concentrations are too small to have an impact', ' Climate cycles are natural', ' Human activities do not impact climate change', ' Humans and nature will adapt to the changes', ' Ice is not melting', ' Other', ' Sea levels are not rising', ' Temperature increase does not have significant impact', ' Weather suggests the trend is global cooling'], ' Green policies are geopolitical instruments': [' Climate-related international relations are abusive/exploitative', ' Green activities are a form of neo-colonialism'], ' Hidden plots by secret schemes of powerful groups': [' Blaming global elites', ' Climate agenda has hidden motives', ' Other'], ' Negative Consequences for the West': [' Other', ' Sanctions imposed by Western countries will backfire', ' The conflict will increase the Ukrainian refugee flows to Europe'], ' Overpraising the West': [' The West belongs in the right side of history', ' The West has the strongest international support'], ' Praise of Russia': [' Other', ' Praise of Russian President Vladimir Putin', ' Praise of Russian military might', ' Russia has international support from a number of countries and people', ' Russia is a guarantor of peace and prosperity', ' Russian invasion has strong national support'], ' Questioning the measurements and science': [' Data shows no temperature increase', ' Greenhouse effect/carbon dioxide do not drive climate change', ' Methodologies/metrics used are unreliable/faulty', ' Other', ' Scientific community is unreliable'], ' Russia is the Victim': [' Other', ' Russia actions in Ukraine are only self-defence', ' The West is russophobic', ' UA is anti-RU extremists'], ' Speculating war outcomes': [' Other', ' Russian army is collapsing', ' Ukrainian army is collapsing'], 'Other': ['Other']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import Counter\n",
        "\n",
        "# Tokenize and process to extract top keywords by class or overall\n",
        "def extract_keywords_by_class_or_overall(narrative_dict, num_keywords=10, overall=False):\n",
        "    \"\"\"\n",
        "    Extracts top keywords from a narrative dictionary.\n",
        "\n",
        "    Args:\n",
        "    - narrative_dict (dict): A dictionary where keys are class labels and values are lists of narratives.\n",
        "    - num_keywords (int): Number of keywords to extract.\n",
        "    - overall (bool): If True, extracts top keywords across all classes combined.\n",
        "\n",
        "    Returns:\n",
        "    - dict or list: If `overall` is False, returns a dictionary where each class maps to its top keywords.\n",
        "                    If `overall` is True, returns a single list of top keywords across all narratives.\n",
        "    \"\"\"\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "\n",
        "    if overall:\n",
        "        # Combine all narratives across classes\n",
        "        all_words = []\n",
        "        for narratives in narrative_dict.values():\n",
        "            for narrative in narratives:\n",
        "                tokens = word_tokenize(narrative.lower())\n",
        "                filtered_tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
        "                all_words.extend(filtered_tokens)\n",
        "\n",
        "        # Count frequencies and extract top keywords\n",
        "        word_counts = Counter(all_words)\n",
        "        return [word for word, count in word_counts.most_common(num_keywords)]\n",
        "\n",
        "    else:\n",
        "        # Extract keywords per class\n",
        "        class_keywords = {}\n",
        "        for level, narratives in narrative_dict.items():\n",
        "            all_words = []\n",
        "            for narrative in narratives:\n",
        "                tokens = word_tokenize(narrative.lower())\n",
        "                filtered_tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
        "                all_words.extend(filtered_tokens)\n",
        "\n",
        "            # Count frequencies and extract top keywords\n",
        "            word_counts = Counter(all_words)\n",
        "            class_keywords[level] = [word for word, count in word_counts.most_common(num_keywords)]\n",
        "\n",
        "        return class_keywords\n",
        "\n",
        "\n",
        "# Extract keywords\n",
        "top_keywords_by_level1 = extract_keywords_by_class_or_overall(narrative_to_level_1_mapping, num_keywords=10, overall=False)\n",
        "top_keywords_by_level2 = extract_keywords_by_class_or_overall(narrative_to_level_2_mapping, num_keywords=20, overall=True)\n",
        "\n",
        "# Display the results\n",
        "print(\"Top Keywords Level 1:\")\n",
        "for class_name, keywords in top_keywords_by_level1.items():\n",
        "    print(f\"{class_name}: {keywords}\")\n",
        "\n",
        "print(\"\\nTop Keywords Level 2 (Overall):\")\n",
        "print(top_keywords_by_level2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFQHJCY8jS-0",
        "outputId": "19c5d5d1-9e45-407a-9eb8-d22f279df207"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top Keywords Level 1:\n",
            "CC: ['climate', 'criticism', 'change', 'green', 'policies', 'amplifying', 'fears', 'beneficial', 'controversy', 'technologies']\n",
            "Other: []\n",
            "URW: ['west', 'war', 'discrediting', 'russia', 'amplifying', 'fears', 'blaming', 'others', 'rather', 'invader']\n",
            "\n",
            "Top Keywords Level 2 (Overall):\n",
            "['west', 'ukraine', 'climate', 'ukrainian', 'russia', 'increase', 'policies', 'impact', 'criticism', 'international', 'russian', 'global', 'countries', 'temperature', 'renewable', 'energy', 'activities', 'support', 'humans', 'co2']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "from fuzzywuzzy import fuzz, process\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "# Download NLTK resources\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "# Initialize Sentiment Analyzer\n",
        "sentiment_analyzer = SentimentIntensityAnalyzer()\n",
        "article_df = train_articles\n",
        "# Load pre-trained XLM-R model and tokenizer\n",
        "model_name = \"xlm-roberta-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "def get_keyword_variations(keyword):\n",
        "    \"\"\"Generate variations for a keyword using synonyms and stemming.\"\"\"\n",
        "    variations = set()\n",
        "    for syn in wordnet.synsets(keyword):\n",
        "        for lemma in syn.lemmas():\n",
        "            variations.add(lemma.name().lower())  # Add synonyms\n",
        "    return variations\n",
        "\n",
        "def calculate_word_sentiment_scores(article, keywords, threshold=80):\n",
        "    \"\"\"\n",
        "    Calculate sentiment scores for keywords and their variations in an article.\n",
        "    :param article: The text to analyze.\n",
        "    :param keywords: List of keywords to find.\n",
        "    :param threshold: Fuzzy match threshold for keyword similarity.\n",
        "    :return: List of sentiment scores.\n",
        "    \"\"\"\n",
        "    sentiment_analyzer = SentimentIntensityAnalyzer()\n",
        "    sentiment_scores = []\n",
        "    article = article.lower()\n",
        "\n",
        "    for keyword in keywords:\n",
        "        variations = get_keyword_variations(keyword)\n",
        "        variations.add(keyword)  # Include the original keyword\n",
        "\n",
        "        # Check for matches in the article\n",
        "        matched_sentences = []\n",
        "        for variation in variations:\n",
        "            for sentence in nltk.sent_tokenize(article):\n",
        "                if fuzz.partial_ratio(variation, sentence) >= threshold:\n",
        "                    matched_sentences.append(sentence)\n",
        "\n",
        "        # Calculate sentiment for matched sentences\n",
        "        if matched_sentences:\n",
        "            combined_text = \" \".join(matched_sentences)\n",
        "            score = sentiment_analyzer.polarity_scores(combined_text)['compound']\n",
        "        else:\n",
        "            score = 0.0  # No match found\n",
        "\n",
        "        sentiment_scores.append(score)\n",
        "\n",
        "    return sentiment_scores\n",
        "'''\n",
        "\n",
        "# Function to calculate sentiment scores for all words in a class\n",
        "def calculate_word_sentiment_scores(article, keywords):\n",
        "    sentiment_scores = []\n",
        "    for keyword in keywords:\n",
        "        if keyword in article.lower():\n",
        "            score = sentiment_analyzer.polarity_scores(keyword)['compound']\n",
        "        else:\n",
        "            score = 0.0  # Assign zero if the word is not present\n",
        "        sentiment_scores.append(score)\n",
        "    return sentiment_scores\n",
        "'''\n",
        "# Apply word-level sentiment scores\n",
        "train_articles['cc_sentiment_scores'] = train_articles['text'].apply(lambda x: calculate_word_sentiment_scores(x, top_keywords_by_level1['CC']))\n",
        "train_articles['urw_sentiment_scores'] = train_articles['text'].apply(lambda x: calculate_word_sentiment_scores(x, top_keywords_by_level1['URW']))\n",
        "train_articles['level2_sentiment_scores'] = train_articles['text'].apply(lambda x: calculate_word_sentiment_scores(x, top_keywords_by_level2))\n",
        "\n",
        "\n",
        "# Function to compute sentence-level embedding for an article\n",
        "def compute_sentence_embedding(text):\n",
        "    # Tokenize input text\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512, padding=\"max_length\")\n",
        "\n",
        "    # Extract input IDs and attention masks\n",
        "    input_ids = inputs['input_ids']\n",
        "    attention_mask = inputs['attention_mask']\n",
        "\n",
        "    # Generate embeddings\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "    # Use the [CLS] token embedding for the sentence-level representation\n",
        "    sentence_embedding = outputs.last_hidden_state[:, 0, :].squeeze().numpy()  # Shape: (hidden_size,)\n",
        "    return sentence_embedding\n",
        "\n",
        "\n",
        "train_articles['sentiment_scores'] = train_articles.apply(\n",
        "    lambda row: row['cc_sentiment_scores'] + row['urw_sentiment_scores'] + row['level2_sentiment_scores'], axis=1\n",
        ")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2KZkfoBPzvPn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "88ebab3dafd346ba81ee8cca95e9c70a",
            "8cb07b5dffba4952b57e9bb6cafcf6b2",
            "f20d9210f0c845c3b459a4d3b4077ae3",
            "fb5e57e9a4de4b61a610ed9c191f027a",
            "4100eeac093f423da4de70d493c6cd86",
            "cc8269bde4774a7e9f46ea632f2eb465",
            "a65c317e32f24676b38f37f773c07715",
            "b78e2bd75a754f9283f22e0e5169a211",
            "e31bdec1675b4f1f9711673033f80b48",
            "e401eb2133134c2eb0d09a5bded829b0",
            "c514240f51074dd392c7c7021d80dfe1",
            "3c8315ba4a1c4b56be298dbaecf62d72",
            "389d6b2af49c43e3b177ab8aa74c1df3",
            "eed839996ef84bb7a9f1dbfe5acf2b0f",
            "735fd50741454a368a37fa7e0d5e706a",
            "1a7cafcc25374e2b8dfa54cbc41ff1d7",
            "f96dad34303f4341acbee3a5aa5c4199",
            "e314a94eac9049bcbca9c3b106b674a8",
            "14e513c2df3a480f803cede6538f5b68",
            "ea972cc8f62e46f388c0ba00e1e42c89",
            "d6c8129991024da0b371505078627ec6",
            "d805e887f37c42e3afba3d57a2ddcb8f",
            "b649c17acc524e5e97646c0fb3023169",
            "047835f9df1d48b78465d20ee5bcc24d",
            "4a41ae358f89484d960f4890187d333d",
            "9788d24b092345bb886bf29298b6d037",
            "2335b7b6955941368e925b4c27b2b0ac",
            "295091330b5745369b55c1e4b6a292eb",
            "da7d9b0fb27b4df6994958ba321048b9",
            "36967ad41e454d469a40dac3a0a860ff",
            "0ab699b3731d43cea7f0a9dbbe21eac7",
            "91309475b46c478986375ce92bb7c43a",
            "7f1025917ba44aeb8012de73872eb2f8",
            "c64e02aeb5cc4f818dac6b35d72e27b0",
            "0abfd58afb604a87b1ae9bf9500fcff3",
            "a96597fc42a143d09f18178c1ac35fc1",
            "016db0aac74e47c0a28501a75a11cb59",
            "583815c970b14dd8bc3072d2bb3fffe3",
            "3838b7f52f244be7b354cbd80df667c5",
            "2434023ce9c947cf98afb7a78c5a53a9",
            "eaf7f5e1750d4b4899500a618b63a2ad",
            "0f2fdbb387364ee5af499ac36359d3f4",
            "febbbcd45a8b49d88282cb83f483e3ff",
            "144bc50753b1496cb6b910578be45c4c",
            "2c32779ac8ca4525b1d0d4296c6280d3",
            "c20168273f624ab798de0f433c6419ef",
            "ac668af6963b4bbf9ce966832599e238",
            "1a00837c21ed46cbb03094f4ce133ed1",
            "f9401f44743f4c3e84febc259a891a27",
            "fdf62382884e42ca938cea4b2695c164",
            "a7d9fedfe9fc41bfa6a33fd59b0bd725",
            "1790e5ad10d04c4faac96938fd367e7e",
            "c703a09050dc41e58b8a5a519eb6c513",
            "095a321e93504be6b0bd7da42747171f",
            "5be14af4c2af4aee8b3a30a5f9faec5a"
          ]
        },
        "outputId": "aa4b74ea-0ace-4a1d-c38b-5830475e2663"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
            "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "88ebab3dafd346ba81ee8cca95e9c70a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3c8315ba4a1c4b56be298dbaecf62d72"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b649c17acc524e5e97646c0fb3023169"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c64e02aeb5cc4f818dac6b35d72e27b0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2c32779ac8ca4525b1d0d4296c6280d3"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply word-level sentiment scores\n",
        "dev_articles['cc_sentiment_scores'] = dev_articles['text'].apply(lambda x: calculate_word_sentiment_scores(x, top_keywords_by_level1['CC']))\n",
        "dev_articles['urw_sentiment_scores'] = dev_articles['text'].apply(lambda x: calculate_word_sentiment_scores(x, top_keywords_by_level1['URW']))\n",
        "dev_articles['level2_sentiment_scores'] = dev_articles['text'].apply(lambda x: calculate_word_sentiment_scores(x, top_keywords_by_level2))\n"
      ],
      "metadata": {
        "id": "n3occ_jkrs_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dev_articles['sentiment_scores'] = dev_articles.apply(\n",
        "    lambda row: row['cc_sentiment_scores'] + row['urw_sentiment_scores'] + row['level2_sentiment_scores'], axis=1\n",
        ")"
      ],
      "metadata": {
        "id": "iaFmYZ2VspPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_articles.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eO7PgvABdZE9",
        "outputId": "80b75cd4-ef57-411b-ba72-7cf06bb85e3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         article_id                                               text  \\\n",
              "0  EN_CC_100004.txt  A Tesla Owner Just Exposed A Sick Secret About...   \n",
              "1  EN_CC_100007.txt  ESG in action: Unity Foods partners with The G...   \n",
              "2  EN_CC_100010.txt  Leveraging Chinese expertise to help Pakistan ...   \n",
              "3  EN_CC_100013.txt  Bill Gates Says He Is ‘The Solution’ To Climat...   \n",
              "4  EN_CC_100011.txt  Met Office issues urgent warning as 70mph wind...   \n",
              "\n",
              "                                 cc_sentiment_scores  \\\n",
              "0  [0.0, 0.0, -0.4854, -0.977, 0.0, 0.0, -0.25, 0...   \n",
              "1  [0.0, 0.0, 0.4939, -0.8977, 0.0, 0.0, 0.296, 0...   \n",
              "2  [0.0, 0.0, 0.3818, 0.9851, 0.6249, 0.0, 0.3818...   \n",
              "3  [-0.5267, 0.0, -0.8397, -0.5329, 0.0, 0.34, 0....   \n",
              "4  [0.1531, 0.0, 0.7992, -0.7037, 0.0, 0.0, 0.778...   \n",
              "\n",
              "                                urw_sentiment_scores  \\\n",
              "0  [-0.9793, -0.7964, 0.0, 0.0, 0.0, -0.25, -0.39...   \n",
              "1  [0.7254, -0.4215, 0.0, 0.0, 0.0, 0.296, 0.0, 0...   \n",
              "2  [0.9883, 0.0, 0.0, 0.0, 0.0, 0.3818, 0.0, 0.0,...   \n",
              "3  [0.8807, 0.0, 0.0, 0.0, 0.34, 0.6249, -0.296, ...   \n",
              "4  [0.8994, 0.7105, 0.0, 0.0, 0.0, 0.7783, 0.1779...   \n",
              "\n",
              "                             level2_sentiment_scores  \\\n",
              "0  [-0.9793, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...   \n",
              "1  [0.7254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2732,...   \n",
              "2  [0.9883, 0.0, 0.0, 0.0, 0.0, 0.9744, 0.6249, 0...   \n",
              "3  [0.8807, 0.0, -0.5267, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
              "4  [0.8994, 0.0, 0.1531, 0.0, 0.0, 0.5499, 0.0, 0...   \n",
              "\n",
              "                                    sentiment_scores  \n",
              "0  [0.0, 0.0, -0.4854, -0.977, 0.0, 0.0, -0.25, 0...  \n",
              "1  [0.0, 0.0, 0.4939, -0.8977, 0.0, 0.0, 0.296, 0...  \n",
              "2  [0.0, 0.0, 0.3818, 0.9851, 0.6249, 0.0, 0.3818...  \n",
              "3  [-0.5267, 0.0, -0.8397, -0.5329, 0.0, 0.34, 0....  \n",
              "4  [0.1531, 0.0, 0.7992, -0.7037, 0.0, 0.0, 0.778...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cbc85bc2-cebd-43d5-acd3-9126ea54be45\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article_id</th>\n",
              "      <th>text</th>\n",
              "      <th>cc_sentiment_scores</th>\n",
              "      <th>urw_sentiment_scores</th>\n",
              "      <th>level2_sentiment_scores</th>\n",
              "      <th>sentiment_scores</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>EN_CC_100004.txt</td>\n",
              "      <td>A Tesla Owner Just Exposed A Sick Secret About...</td>\n",
              "      <td>[0.0, 0.0, -0.4854, -0.977, 0.0, 0.0, -0.25, 0...</td>\n",
              "      <td>[-0.9793, -0.7964, 0.0, 0.0, 0.0, -0.25, -0.39...</td>\n",
              "      <td>[-0.9793, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
              "      <td>[0.0, 0.0, -0.4854, -0.977, 0.0, 0.0, -0.25, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>EN_CC_100007.txt</td>\n",
              "      <td>ESG in action: Unity Foods partners with The G...</td>\n",
              "      <td>[0.0, 0.0, 0.4939, -0.8977, 0.0, 0.0, 0.296, 0...</td>\n",
              "      <td>[0.7254, -0.4215, 0.0, 0.0, 0.0, 0.296, 0.0, 0...</td>\n",
              "      <td>[0.7254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2732,...</td>\n",
              "      <td>[0.0, 0.0, 0.4939, -0.8977, 0.0, 0.0, 0.296, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>EN_CC_100010.txt</td>\n",
              "      <td>Leveraging Chinese expertise to help Pakistan ...</td>\n",
              "      <td>[0.0, 0.0, 0.3818, 0.9851, 0.6249, 0.0, 0.3818...</td>\n",
              "      <td>[0.9883, 0.0, 0.0, 0.0, 0.0, 0.3818, 0.0, 0.0,...</td>\n",
              "      <td>[0.9883, 0.0, 0.0, 0.0, 0.0, 0.9744, 0.6249, 0...</td>\n",
              "      <td>[0.0, 0.0, 0.3818, 0.9851, 0.6249, 0.0, 0.3818...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>EN_CC_100013.txt</td>\n",
              "      <td>Bill Gates Says He Is ‘The Solution’ To Climat...</td>\n",
              "      <td>[-0.5267, 0.0, -0.8397, -0.5329, 0.0, 0.34, 0....</td>\n",
              "      <td>[0.8807, 0.0, 0.0, 0.0, 0.34, 0.6249, -0.296, ...</td>\n",
              "      <td>[0.8807, 0.0, -0.5267, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
              "      <td>[-0.5267, 0.0, -0.8397, -0.5329, 0.0, 0.34, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>EN_CC_100011.txt</td>\n",
              "      <td>Met Office issues urgent warning as 70mph wind...</td>\n",
              "      <td>[0.1531, 0.0, 0.7992, -0.7037, 0.0, 0.0, 0.778...</td>\n",
              "      <td>[0.8994, 0.7105, 0.0, 0.0, 0.0, 0.7783, 0.1779...</td>\n",
              "      <td>[0.8994, 0.0, 0.1531, 0.0, 0.0, 0.5499, 0.0, 0...</td>\n",
              "      <td>[0.1531, 0.0, 0.7992, -0.7037, 0.0, 0.0, 0.778...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cbc85bc2-cebd-43d5-acd3-9126ea54be45')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cbc85bc2-cebd-43d5-acd3-9126ea54be45 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cbc85bc2-cebd-43d5-acd3-9126ea54be45');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-46b9b0f3-a197-4285-b3fd-8ab65d7e0d69\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-46b9b0f3-a197-4285-b3fd-8ab65d7e0d69')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-46b9b0f3-a197-4285-b3fd-8ab65d7e0d69 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_articles",
              "summary": "{\n  \"name\": \"train_articles\",\n  \"rows\": 399,\n  \"fields\": [\n    {\n      \"column\": \"article_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 399,\n        \"samples\": [\n          \"EN_UA_020543.txt\",\n          \"EN_UA_300077.txt\",\n          \"EN_CC_100035.txt\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 396,\n        \"samples\": [\n          \"WATCH: Arrests Made as Global Climate Protesters Demand End to Fossil Fuels\\nRoads will be blocked, cities shut down, airports targeted, marches begun and chanting, lots of chanting, will combine Friday as climate protesters around the world rally to demand an immediate end to fossil fuel use.  That\\u2019s the plan, anyway, with the so-called Global Climate Strike 2023 destined to last through the weekend and end late Sunday.  AP reports the mass public action \\u2014 driven by several mostly youth-led, local and global climate groups and organizations, including Greta Thunberg\\u2019s Fridays for Future movement \\u2014 will take place in dozens of countries and in at least 50 cities worldwide for 72-hours.  WATCH: Greta Thunberg Calls for \\u201cDrastic Emissions Cuts\\u201d to \\u201cFundamentally Change Our Society\\u201d  The protest demands include \\u2013 but are not restricted to \\u2013 \\u201cdivesting from new and current fossil fuel projects, sharing the burden equally among society, investing in community-owned renewable energy projects, and paying reparations to communities affected by the climate crisis,\\u201d Euronews reports.  Organisers said their climate protest would call on governments to end subsidies for oil and gas immediately and to cancel any plans for expanding fossil fuel production.  Financial institutions of all types around world will also face protests and a call for them to end funding fossil fuel development.  In one strike in Quezon City in the Philippines, AP reports activists lay in front of the Department of Environment and Natural Resources in protest, and held signs demanding fossil fuels \\u2014 from coal to natural gas \\u2014 be phased out.  Another major mass action is planned to take place Sunday in New York, to coincide with the city\\u2019s Climate Week and the U.N. climate summit.  Climate activists have organized similar worldwide strikes in recent years, where protesters from different nations join together on a single day.  The \\u201cclimate strike\\u201d comes two months before this year\\u2019s United Nations COP28 climate summit, where more than 80 countries plan to push for a global agreement to phase out coal, oil and gas.  COMMENTS  Please let us know if you're having issues with commenting.\",\n          \"Warning US could be \\u2018hit with most debilitating strike EVER\\u2019 in space war with Russia after chilling ISS threat\\nWarning US could be \\u2018hit with most debilitating strike EVER\\u2019 in space war with Russia after chilling ISS threat  THE US could be hit with the most debilitating and destructive strike ever in a potential space war with Russia, an expert warns.  Relations between Moscow and Washington have plunged to new lows amid the Ukrainian crisis, and Russia\\u2019s space agency warned that US sanctions could \\u201cdestroy\\u201d cooperation on the International Space Station.  Moscow claimed Washington needs its cooperation to prevent the ISS from falling on the US or Europe.  Geopolitical and space expert Brandon J Weichert told The Sun that Moscow has a decade to a 12-year advantage on the US in the galaxies.  He said US defenses are in \\u201cno way fit\\u201d to deal with the challenges posed by Russia.  Weichert warned: \\u201cWe are going to get hit very hard soon in space. It is going to be the most debilitating strike on America, possibly ever.  \\u201cAnd we may not recover from it in a timely fashion. This could be how we lose our first war on Earth is losing the war in space.\\u201d  Weichert slammed the \\\"arrogant\\\" DC political class, claiming they didn\\u2019t foresee any rival challenging Washington\\u2019s dominance in the post-Cold-War world.  Most read in The Sun  He said: \\u201cThey thought there would never be a need for any kind of preventative or security measure because we thought we would always be dominant, and we thought no one would be crazy enough to challenge us.  \\u201cWell here we are 30 years later, and you have Russia, China, North Korea, and even Iran showing us that it was the wrong assumption.\\u201d  The expert feared that the US has a 60 percent chance of being pushed out of space by its rivals completely.  President Biden unleashed a package of sanctions against Moscow on Thursday after Putin\\u2019s forces rolled into Ukraine.  And, an additional 7,000 troops will be sent to Eastern Europe to bolster Nato\\u2019s defenses.  Russia\\u2019s invasion of the besieged nation saw Europe plunged into its biggest crisis since World War II.  Experts claim the world has not seen a crisis since the Cuban Missile Crisis in the 1960s.  The flashpoint was the closest point the world came to a full-blown nuclear war.  US intelligence feared that Kyiv could fall within 96 hours and US Secretary of State Antony Blinken said it\\u2019s a \\u201cpossibility\\u201d that Putin could move beyond the borders of Ukraine.  The Russian strongman may feel emboldened and seek to move on to other nations if successful.  Troops have reportedly already been spotted in the Belarussian city of Brest \\u2013 10 miles east of the Polish border.  Biden told reporters Thursday: \\u201cHe has much larger ambitions. He wants to, in fact, re-establish the former Soviet Union. That\\u2019s what this is all about.\\u201d  Weichert said: \\u201cIf Putin suspects the West will prop up a formidable anti-Russian resistance in a post-invasion Ukraine, he will risk not only nuclear war but also will threaten to attack US assets in space and the ISS.  \\u201cPutin fully understands the concept of asymmetrical warfare.\\u201d  He speculated that Moscow will ramp up its threats in cyberspace and nuclear warfare.  PUTIN'S THREATS  In December, Weichert warned that Moscow is plotting to launch a Pearl Harbor attack on the US in the cosmos.  The Pearl Harbor attack of December 1941 left America reeling as Japanese forces bombed the US naval port.  In his book, Winning Space: How America Remains a Superpower, Weichert says that Russian co-orbital satellites, known as space stalkers, have been tailgating US satellites for years.  He predicts that the stalkers will eventually hit the satellites, sending them crashing into the ground.  Weichert believes Russia is preparing to launch a \\\"devastating\\\" attack on American satellites at the time of its own choice.  He warned that before launching an attack on Washington\\u2019s satellites, Moscow would \\\"engage in a series of escalations\\u201d with neighboring nations.  Russia conducted an anti-satellite weapon test (ASAT) in November where it destroyed one of its own satellites that had been in orbit since 1982.  READ MORE SUN STORIES  Blinken branded the test \\\"dangerous and irresponsible\\\" as it created a field of 1,500 pieces of debris, forcing the ISS crew to take shelter.  State Department spokesperson Ned Price said the test marked an increase in the risk to astronauts and cosmonauts on the ISS.  We pay for your stories!  Do you have a story for The US Sun team?  Email us at exclusive@the-sun.com or call 212 416 4552.  Like us on Facebook at www.facebook.com/TheSunUS and follow us from our main Twitter account at @TheSunUS\",\n          \"Israel to respond to genocide charges at UN\\u2019s top court06:35\\nIsrael to respond to genocide charges at UN\\u2019s top court  Israel will respond to charges of genocide at the United Nations\\u2019 top court on Friday after South Africa filed an urgent request with the court to order a ceasefire in Gaza.  It is the third time the International Court of Justice (ICJ) has held hearings on the Israel-Hamas war since South Africa filed proceedings at The Hague court in December.  On Thursday, South Africa told the court the situation in Gaza has reached \\u201ca new and horrific stage\\u201d, and urged the 15 judges to take urgent action.  Israel must \\u201ctotally and unconditionally withdraw\\u201d from the Gaza Strip, said Vusimuzi Madonsela, South Africa\\u2019s ambassador to the Netherlands.  South Africa has submitted four requests for the ICJ to investigate Israel. According to the latest request, the country says Israel\\u2019s military incursion in Rafah threatens the \\u201cvery survival of Palestinians in Gaza\\u201d.  During hearings earlier this year, Israel strongly denied committing genocide in Gaza, saying it does all it can to spare civilians and is only targeting Hamas militants. Israel says Rafah is the last stronghold of the militant group.  In January, judges ordered Israel to do all it can to prevent death, destruction and any acts of genocide in Gaza, but the panel stopped short of ordering an end to the military offensive.  The court has already found that there is a \\u201creal and imminent risk\\u201d to the Palestinian people in Gaza by Israel\\u2019s military operations.  \\u201cThis may well be the last chance for the court to act,\\u201d said Irish lawyer Blinne Ni Ghralaigh, who is part of South Africa\\u2019s legal team.  ICJ judges have broad powers to order a ceasefire and other measures, though the court does not have its own enforcement apparatus.  A 2022 order by the court demanding that Russia halt its full-scale invasion of Ukraine has so far gone unheeded.  Most of Gaza\\u2019s population of 2.3 million people have been displaced since fighting began.  The war began with a Hamas attack on southern Israel on October 7 in which Palestinian militants killed around 1,200 people and took about 250 hostages.  Gaza\\u2019s Health Ministry says more than 35,000 Palestinians have been killed in the war without distinguishing between civilians and combatants in its count.  South Africa initiated proceedings in December 2023 and sees the legal campaign as rooted in issues central to its identity. Its governing party, the African National Congress, has long compared Israel\\u2019s policies in Gaza and the occupied West Bank to its own history under the apartheid regime of white minority rule, which restricted most Blacks to \\u201chomelands\\u201d. Apartheid ended in 1994.  On Sunday, Egypt announced it plans to join the case. Several countries have also indicated they plan to intervene, but only Libya, Nicaragua and Colombia have filed formal requests to do so.  Join the Belfast Telegraph WhatsApp channel  Stay up to date with some of Northern Ireland's biggest stories\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cc_sentiment_scores\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"urw_sentiment_scores\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"level2_sentiment_scores\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment_scores\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "article_df['entity_labels'] = article_df['entities'].apply(lambda ents: [label for _, label in ents])\n",
        "all_labels = [label for labels in article_df['entity_labels'] for label in labels]\n",
        "label_counts = Counter(all_labels)\n",
        "\n",
        "# Plot\n",
        "import matplotlib.pyplot as plt\n",
        "plt.bar(label_counts.keys(), label_counts.values())\n",
        "plt.title(\"Entity Label Distribution\")\n",
        "plt.xlabel(\"Entity Type\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "cZeK7Y85Yiir",
        "outputId": "89093045-8c55-40c9-a070-4a793c5804b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Article Embedding"
      ],
      "metadata": {
        "id": "MQ4Fu_0uW5bc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "import spacy\n",
        "import nltk\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from collections import Counter\n",
        "\n",
        "# Check for CUDA availability\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load pre-trained XLM-R model and tokenizer\n",
        "model_name = \"xlm-roberta-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Ensure model is on the correct device\n",
        "\n",
        "# Load SpaCy's language model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "# Initialize sentiment analyzer\n",
        "sentiment_analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Function to extract entities from text\n",
        "def extract_entities(text):\n",
        "    doc = nlp(text)\n",
        "    return [(ent.text, ent.label_) for ent in doc.ents]\n",
        "\n",
        "# Function to map entities to actants\n",
        "def map_entities_to_actants(entities):\n",
        "    actants = {\"subject\": [], \"object\": [], \"helper\": [], \"opponent\": []}\n",
        "    for ent, label in entities:\n",
        "        if label == \"PERSON\":\n",
        "            actants[\"subject\"].append(ent)\n",
        "        elif label in {\"GPE\", \"ORG\"}:\n",
        "            actants[\"object\"].append(ent)\n",
        "        # Use sentiment to decide helper/opponent\n",
        "        sentiment = sentiment_analyzer.polarity_scores(ent)['compound']\n",
        "        if sentiment > 0.2:\n",
        "            actants[\"helper\"].append(ent)\n",
        "        elif sentiment < -0.2:\n",
        "            actants[\"opponent\"].append(ent)\n",
        "    return actants\n",
        "\n",
        "# Function to convert actants to text format\n",
        "def actants_to_text(actants):\n",
        "    actants_text = []\n",
        "    if actants[\"subject\"]:\n",
        "        actants_text.append(f\"Subject: {', '.join(actants['subject'])}.\")\n",
        "    if actants[\"object\"]:\n",
        "        actants_text.append(f\"Object: {', '.join(actants['object'])}.\")\n",
        "    if actants[\"helper\"]:\n",
        "        actants_text.append(f\"Helper: {', '.join(actants['helper'])}.\")\n",
        "    if actants[\"opponent\"]:\n",
        "        actants_text.append(f\"Opponent: {', '.join(actants['opponent'])}.\")\n",
        "    return \" \".join(actants_text)\n",
        "\n",
        "# Function to compute token-based embedding for an article\n",
        "def compute_token_based_embedding(text):\n",
        "    # Tokenize input text\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512, padding=\"max_length\").to(device)\n",
        "\n",
        "    # Generate embeddings\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    # Token embeddings (last hidden state)\n",
        "    token_embeddings = outputs.last_hidden_state  # Shape: (batch_size, seq_len, hidden_size)\n",
        "\n",
        "    # Apply mean pooling to aggregate token embeddings\n",
        "    attention_mask = inputs['attention_mask']\n",
        "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, dim=1)\n",
        "    sum_mask = torch.clamp(input_mask_expanded.sum(dim=1), min=1e-9)\n",
        "    token_based_embedding = sum_embeddings / sum_mask  # Mean pooling\n",
        "\n",
        "    # Move back to CPU and convert to NumPy\n",
        "    return token_based_embedding.squeeze().cpu().numpy()\n",
        "\n",
        "# Function to process articles\n",
        "def process_articles_with_token_embeddings(article_df):\n",
        "    # Extract entities and map them to actants\n",
        "    article_df['entities'] = article_df['text'].apply(extract_entities)\n",
        "    article_df['actants'] = article_df['entities'].apply(map_entities_to_actants)\n",
        "\n",
        "    # Convert actants to text\n",
        "    article_df['actants_text'] = article_df['actants'].apply(actants_to_text)\n",
        "\n",
        "    # Compute token-based embeddings for article text and actant text\n",
        "    article_df['token_based_embedding'] = article_df['text'].apply(compute_token_based_embedding)\n",
        "    article_df['actants_embedding'] = article_df['actants_text'].apply(compute_token_based_embedding)\n",
        "\n",
        "    # Combine text and actant embeddings\n",
        "    article_df['combined_embedding'] = article_df.apply(\n",
        "        lambda row: np.hstack([row['token_based_embedding'], row['actants_embedding']]),\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    return article_df\n",
        "\n",
        "# Assuming train_articles and dev_articles DataFrames are already loaded\n",
        "processed_train_df = process_articles_with_token_embeddings(train_articles)\n",
        "processed_dev_df = process_articles_with_token_embeddings(dev_articles)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVKG2WEvW8xH",
        "outputId": "3fc2d781-50bc-41bf-b882-7c44bdb97cfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save processed DataFrames\n",
        "processed_train_df.to_csv('/content/drive/MyDrive/NLP_Proj/embedded_article/processed_train_articles.csv', index=False)\n",
        "processed_dev_df.to_csv('/content/drive/MyDrive/NLP_Proj/embedded_article/processed_dev_articles.csv', index=False)\n",
        "\n",
        "# Print a sample of the processed data\n",
        "processed_train_df.head()\n",
        "#print(processed_dev_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 695
        },
        "collapsed": true,
        "id": "487X8xO9PqPo",
        "outputId": "cf525999-ef68-49dd-bc83-bc9255d7c7d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   article_id                                               text  \\\n",
              "0           4  A Tesla Owner Just Exposed A Sick Secret About...   \n",
              "1           6  ESG in action: Unity Foods partners with The G...   \n",
              "2           9  Leveraging Chinese expertise to help Pakistan ...   \n",
              "3          12  Bill Gates Says He Is ‘The Solution’ To Climat...   \n",
              "4          10  Met Office issues urgent warning as 70mph wind...   \n",
              "\n",
              "                                 cc_sentiment_scores  \\\n",
              "0  [0.0, 0.0, -0.4854, -0.977, 0.0, 0.0, -0.25, 0...   \n",
              "1  [0.0, 0.0, 0.4939, -0.8977, 0.0, 0.0, 0.296, 0...   \n",
              "2  [0.0, 0.0, 0.3818, 0.9851, 0.6249, 0.0, 0.3818...   \n",
              "3  [-0.5267, 0.0, -0.8397, -0.5329, 0.0, 0.34, 0....   \n",
              "4  [0.1531, 0.0, 0.7992, -0.7037, 0.0, 0.0, 0.778...   \n",
              "\n",
              "                                urw_sentiment_scores  \\\n",
              "0  [-0.9793, -0.7964, 0.0, 0.0, 0.0, -0.25, -0.39...   \n",
              "1  [0.7254, -0.4215, 0.0, 0.0, 0.0, 0.296, 0.0, 0...   \n",
              "2  [0.9883, 0.0, 0.0, 0.0, 0.0, 0.3818, 0.0, 0.0,...   \n",
              "3  [0.8807, 0.0, 0.0, 0.0, 0.34, 0.6249, -0.296, ...   \n",
              "4  [0.8994, 0.7105, 0.0, 0.0, 0.0, 0.7783, 0.1779...   \n",
              "\n",
              "                             level2_sentiment_scores  \\\n",
              "0  [-0.9793, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...   \n",
              "1  [0.7254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2732,...   \n",
              "2  [0.9883, 0.0, 0.0, 0.0, 0.0, 0.9744, 0.6249, 0...   \n",
              "3  [0.8807, 0.0, -0.5267, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
              "4  [0.8994, 0.0, 0.1531, 0.0, 0.0, 0.5499, 0.0, 0...   \n",
              "\n",
              "                                    sentiment_scores  \\\n",
              "0  [0.0, 0.0, -0.4854, -0.977, 0.0, 0.0, -0.25, 0...   \n",
              "1  [0.0, 0.0, 0.4939, -0.8977, 0.0, 0.0, 0.296, 0...   \n",
              "2  [0.0, 0.0, 0.3818, 0.9851, 0.6249, 0.0, 0.3818...   \n",
              "3  [-0.5267, 0.0, -0.8397, -0.5329, 0.0, 0.34, 0....   \n",
              "4  [0.1531, 0.0, 0.7992, -0.7037, 0.0, 0.0, 0.778...   \n",
              "\n",
              "                                            entities  \\\n",
              "0  [(Tesla, ORG), (Tesla, ORG), (An Inconvenient ...   \n",
              "1  [(ESG, ORG), (Unity Foods, ORG), (The Green Ar...   \n",
              "2  [(Chinese, NORP), (Pakistan, GPE), (Pakistan, ...   \n",
              "3  [(Bill Gates, PERSON), (Jets, PERSON), (Bill G...   \n",
              "4  [(Met Office, ORG), (70mph, QUANTITY), (UK, GP...   \n",
              "\n",
              "                                             actants  \\\n",
              "0  {'subject': ['Al Gore', 'Teslas', 'Brad Temple...   \n",
              "1  {'subject': ['jerry cans', 'Habib Elahi'], 'ob...   \n",
              "2  {'subject': ['Liaqat Ali Shah'], 'object': ['P...   \n",
              "3  {'subject': ['Bill Gates', 'Jets', 'Bill Gates...   \n",
              "4  {'subject': ['Storm Jocelyn', 'Windy', 'Outloo...   \n",
              "\n",
              "                                        actants_text  \\\n",
              "0  Subject: Al Gore, Teslas, Brad Templeton, Temp...   \n",
              "1  Subject: jerry cans, Habib Elahi. Object: ESG,...   \n",
              "2  Subject: Liaqat Ali Shah. Object: Pakistan, Pa...   \n",
              "3  Subject: Bill Gates, Jets, Bill Gates, Bill Ga...   \n",
              "4  Subject: Storm Jocelyn, Windy, Outlook. Object...   \n",
              "\n",
              "                               token_based_embedding  \\\n",
              "0  [-0.0220115, -0.0074324175, 0.014859043, 0.003...   \n",
              "1  [-0.014961489, -0.011857742, -0.0007843474, -0...   \n",
              "2  [-0.013167953, 0.020093676, 0.010838951, 0.008...   \n",
              "3  [-0.015397585, 0.02165544, 0.003880438, -0.007...   \n",
              "4  [0.025963038, 0.020136321, -0.014449881, 0.026...   \n",
              "\n",
              "                                   actants_embedding  \\\n",
              "0  [-0.0022261546, 0.055587865, 0.026547622, 0.00...   \n",
              "1  [0.023054093, 0.058462076, 0.013864914, 0.0200...   \n",
              "2  [-0.012079347, 0.078377545, 0.0021905769, 0.03...   \n",
              "3  [-0.0127927875, 0.06957293, 0.015238972, -0.00...   \n",
              "4  [-0.002969738, 0.0668433, 0.020641668, 0.04076...   \n",
              "\n",
              "                                  combined_embedding  \n",
              "0  [-0.0220115, -0.0074324175, 0.014859043, 0.003...  \n",
              "1  [-0.014961489, -0.011857742, -0.0007843474, -0...  \n",
              "2  [-0.013167953, 0.020093676, 0.010838951, 0.008...  \n",
              "3  [-0.015397585, 0.02165544, 0.003880438, -0.007...  \n",
              "4  [0.025963038, 0.020136321, -0.014449881, 0.026...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-66636170-ca08-4629-9ced-2bd454a1bd6c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article_id</th>\n",
              "      <th>text</th>\n",
              "      <th>cc_sentiment_scores</th>\n",
              "      <th>urw_sentiment_scores</th>\n",
              "      <th>level2_sentiment_scores</th>\n",
              "      <th>sentiment_scores</th>\n",
              "      <th>entities</th>\n",
              "      <th>actants</th>\n",
              "      <th>actants_text</th>\n",
              "      <th>token_based_embedding</th>\n",
              "      <th>actants_embedding</th>\n",
              "      <th>combined_embedding</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>A Tesla Owner Just Exposed A Sick Secret About...</td>\n",
              "      <td>[0.0, 0.0, -0.4854, -0.977, 0.0, 0.0, -0.25, 0...</td>\n",
              "      <td>[-0.9793, -0.7964, 0.0, 0.0, 0.0, -0.25, -0.39...</td>\n",
              "      <td>[-0.9793, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
              "      <td>[0.0, 0.0, -0.4854, -0.977, 0.0, 0.0, -0.25, 0...</td>\n",
              "      <td>[(Tesla, ORG), (Tesla, ORG), (An Inconvenient ...</td>\n",
              "      <td>{'subject': ['Al Gore', 'Teslas', 'Brad Temple...</td>\n",
              "      <td>Subject: Al Gore, Teslas, Brad Templeton, Temp...</td>\n",
              "      <td>[-0.0220115, -0.0074324175, 0.014859043, 0.003...</td>\n",
              "      <td>[-0.0022261546, 0.055587865, 0.026547622, 0.00...</td>\n",
              "      <td>[-0.0220115, -0.0074324175, 0.014859043, 0.003...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6</td>\n",
              "      <td>ESG in action: Unity Foods partners with The G...</td>\n",
              "      <td>[0.0, 0.0, 0.4939, -0.8977, 0.0, 0.0, 0.296, 0...</td>\n",
              "      <td>[0.7254, -0.4215, 0.0, 0.0, 0.0, 0.296, 0.0, 0...</td>\n",
              "      <td>[0.7254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2732,...</td>\n",
              "      <td>[0.0, 0.0, 0.4939, -0.8977, 0.0, 0.0, 0.296, 0...</td>\n",
              "      <td>[(ESG, ORG), (Unity Foods, ORG), (The Green Ar...</td>\n",
              "      <td>{'subject': ['jerry cans', 'Habib Elahi'], 'ob...</td>\n",
              "      <td>Subject: jerry cans, Habib Elahi. Object: ESG,...</td>\n",
              "      <td>[-0.014961489, -0.011857742, -0.0007843474, -0...</td>\n",
              "      <td>[0.023054093, 0.058462076, 0.013864914, 0.0200...</td>\n",
              "      <td>[-0.014961489, -0.011857742, -0.0007843474, -0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9</td>\n",
              "      <td>Leveraging Chinese expertise to help Pakistan ...</td>\n",
              "      <td>[0.0, 0.0, 0.3818, 0.9851, 0.6249, 0.0, 0.3818...</td>\n",
              "      <td>[0.9883, 0.0, 0.0, 0.0, 0.0, 0.3818, 0.0, 0.0,...</td>\n",
              "      <td>[0.9883, 0.0, 0.0, 0.0, 0.0, 0.9744, 0.6249, 0...</td>\n",
              "      <td>[0.0, 0.0, 0.3818, 0.9851, 0.6249, 0.0, 0.3818...</td>\n",
              "      <td>[(Chinese, NORP), (Pakistan, GPE), (Pakistan, ...</td>\n",
              "      <td>{'subject': ['Liaqat Ali Shah'], 'object': ['P...</td>\n",
              "      <td>Subject: Liaqat Ali Shah. Object: Pakistan, Pa...</td>\n",
              "      <td>[-0.013167953, 0.020093676, 0.010838951, 0.008...</td>\n",
              "      <td>[-0.012079347, 0.078377545, 0.0021905769, 0.03...</td>\n",
              "      <td>[-0.013167953, 0.020093676, 0.010838951, 0.008...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>12</td>\n",
              "      <td>Bill Gates Says He Is ‘The Solution’ To Climat...</td>\n",
              "      <td>[-0.5267, 0.0, -0.8397, -0.5329, 0.0, 0.34, 0....</td>\n",
              "      <td>[0.8807, 0.0, 0.0, 0.0, 0.34, 0.6249, -0.296, ...</td>\n",
              "      <td>[0.8807, 0.0, -0.5267, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
              "      <td>[-0.5267, 0.0, -0.8397, -0.5329, 0.0, 0.34, 0....</td>\n",
              "      <td>[(Bill Gates, PERSON), (Jets, PERSON), (Bill G...</td>\n",
              "      <td>{'subject': ['Bill Gates', 'Jets', 'Bill Gates...</td>\n",
              "      <td>Subject: Bill Gates, Jets, Bill Gates, Bill Ga...</td>\n",
              "      <td>[-0.015397585, 0.02165544, 0.003880438, -0.007...</td>\n",
              "      <td>[-0.0127927875, 0.06957293, 0.015238972, -0.00...</td>\n",
              "      <td>[-0.015397585, 0.02165544, 0.003880438, -0.007...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10</td>\n",
              "      <td>Met Office issues urgent warning as 70mph wind...</td>\n",
              "      <td>[0.1531, 0.0, 0.7992, -0.7037, 0.0, 0.0, 0.778...</td>\n",
              "      <td>[0.8994, 0.7105, 0.0, 0.0, 0.0, 0.7783, 0.1779...</td>\n",
              "      <td>[0.8994, 0.0, 0.1531, 0.0, 0.0, 0.5499, 0.0, 0...</td>\n",
              "      <td>[0.1531, 0.0, 0.7992, -0.7037, 0.0, 0.0, 0.778...</td>\n",
              "      <td>[(Met Office, ORG), (70mph, QUANTITY), (UK, GP...</td>\n",
              "      <td>{'subject': ['Storm Jocelyn', 'Windy', 'Outloo...</td>\n",
              "      <td>Subject: Storm Jocelyn, Windy, Outlook. Object...</td>\n",
              "      <td>[0.025963038, 0.020136321, -0.014449881, 0.026...</td>\n",
              "      <td>[-0.002969738, 0.0668433, 0.020641668, 0.04076...</td>\n",
              "      <td>[0.025963038, 0.020136321, -0.014449881, 0.026...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-66636170-ca08-4629-9ced-2bd454a1bd6c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-66636170-ca08-4629-9ced-2bd454a1bd6c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-66636170-ca08-4629-9ced-2bd454a1bd6c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-857d5316-ef98-41ea-9cea-37cf104ac10b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-857d5316-ef98-41ea-9cea-37cf104ac10b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-857d5316-ef98-41ea-9cea-37cf104ac10b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"#print(processed_dev_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"article_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 4,\n        \"max\": 12,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          6,\n          10,\n          9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"ESG in action: Unity Foods partners with The Green Ark to recycle plastic waste\\nKarachi - Unity Foods continues to showcase a strong commitment to ESG principles through a partnership with The Green Ark (TGA). A MoU was signed to this effect between both companies whereby TGA will collect and transform scrap materials from Unity Foods to create a diverse array of recycled products intended for reuse. The initiative aims to facilitate the circular economy by mitigating the impact of single-use plastics that contribute significantly towards the deterioration of global ecosystems.  Unity Foods regularly undertakes lasting projects that align with its objectives to reduce the impact of conventional industrialisation on the environment. Under the current partnership with The Green Ark, a leading recycling solutions provider, Unity Foods will not only ensure the traceability of its packaging waste but also highlight a robust commitment to a greener environment by contributing to the circular economy. With an average of more than 13,000 kilogrammes of waste every month including items like garbage debris, oily pouches, plastic jerry cans, tin scraps, plastic bags, and cardboard cartons, a substantial amount of materials will be recycled which will not end up in landfills or incinerators that ultimately damage nature.  \\u201cGlobal warming is a present and potent threat, especially for Pakistan which despite producing a negligible level of greenhouse gases, faces the brunt of the consequences of this global phenomenon. At Unity Foods, we always aim to set a precedent, particularly with our ESG practices that underscore our commitment to ensuring our children can inherit a safe and healthy planet. This partnership with The Green Ark is another step in this direction and we aim to continue commencing similar initiatives in the future,\\u201d commented Ms Nageen Rizvi, Head of Corporate Communications and Sustainability, Unity Foods at the signing ceremony. At the occasion, Mr Habib Elahi, CEO, The Green Ark said, \\u201cWe are committed to reduce the carbon footprint through recycling waste into resin and building materials such as pavers and tiles made from end-of-cycle plastic waste. By this strategic partnership between Unity Foods and TGA, we can ensure that that waste generated is responsibly recycled and adds value in the circular economy.\\u201d\",\n          \"Met Office issues urgent warning as 70mph winds set to hammer UK - check your area The fierce winds are accompanied by a surprising change in temperature.\\nUK weather maps: Met Office issues yellow warnings over 70mph winds  The fierce winds are accompanied by a surprising change in temperature.  Met Office forecasts strong winds for the north  Crushing waves will slam the UK\\u2019s shores while power cuts and travel delays are likely as 70mph batter the country.  The Met Office has placed a yellow weather warning for wind as strong gales are predicted for much of the northeast of the UK. The weather warning covers Highlands & Eilean Siar and Orkney & Shetland in Scotland.  However, some experts predict heavy winds will also hit other coastlines along the UK. The \\u201cspell of very windy weather\\u201d is likely to lead to \\u201ctravel disruption\\u201d, the weather agency said.  This includes impacting coastal routes and sea fronts with large waves, as well as possible loss of power and other services.  Delays to road, air and ferry transport are also \\u201clikely\\u201d.  While the worst of the winds will hit along the coast, speeds could still reach a substantial 60mph inland.  The weather warning is in place until 11am, although winds will remain throughout the day for much of the country.  The weather agency said: \\u201cWinds will increase quickly towards dawn Saturday across the Northern Isles with gusts generally reaching 50-60mph but with a smaller chance of 70mph gusts. Winds will quickly ease from late morning.\\u201d  The winds will accompany slightly warmer temperatures than in recent days. The mercury is likely to reach 13C in Belfast and 12C in Glasgow, both typically in the colder regions of the UK.  However the country is still reeling from the impact of Storm Isha and Storm Jocelyn.  Don't miss...  Met Office verdict on horror snow deluge as maps show exact day it will hit [REVEAL]  UK's mega storm season explained as Met Office scientists say 'more may come' [INSIGHT]  New maps show exact date more storm chaos will wallop into Britain [ANALYSIS]  With the ground saturated in various regions, the flood risk remains high.  Nine flood warnings were last night in place across England alone, including an alert for River Ouse in York city centre. The river burst its banks this week.  The closely consecutive storms has been attributed to the recent positions of jetstreams influencing low-pressure systems from the Atlantic. However, weather experts have also explained to Express.co.uk that climate change is likely having an impact on the number and severity of storms.  Met Office 5 day weather forecast  Today:  Outbreaks of rain slowly sinking south across northern Scotland, and slowing over the mainland. Elsewhere, dry with sunny spells, although cloudier later in the west with patchy drizzle. Very strong winds in the north, but lighter in the south. Mild.  Tonight:  Rain slowly returns north through the evening. Cloudy with drizzle in the north and west, but drier elsewhere with clear spells. Windy, with gales in the north. Mild for most.  Sunday:  On Sunday, remaining wet and windy in northwest. Generally dry in southeast, but cloudy at times, although some brighter spells possible. Very mild.  Outlook for Monday to Wednesday:  Turning more unsettled into the new working week, with some drier interludes, but less wet and windy than seen recently.\",\n          \"Leveraging Chinese expertise to help Pakistan expedite real estate growth\\nPakistan\\u2019s collaboration with Chinese construction companies offers a unique opportunity to leverage their vast expertise to expedite its infrastructure and real estate development and adopt efficient construction techniques while ensuring high-quality standards and promoting sustainable practices.  Dr. Liaqat Ali Shah, Head of Policy CPEC in the Centre of Excellence for CPEC, said this while talking to WealthPK.  \\u201cThe Chinese investment under the CPEC is mainly focused on infrastructure. The largest part went into setting up power generation plants, railway tracks, and building highway infrastructure. The CPEC's western alignment was also the focus of new infrastructure projects, which connected Pakistan's most underdeveloped regions with Gwadar and major urban centres.\\u201d  \\u201cOwing to China\\u2019s rapid urbanization in the last two decades, Chinese construction companies have had a lot of exposure to efficient construction techniques, which has given them a lot of expertise in these fields,\\u201d he said.  \\u201cCollaborating with Chinese construction firms allows Pakistan to benefit from these high-quality standards, contributing to the construction of a durable and resilient infrastructure. This is particularly crucial in regions prone to natural disasters, as the expertise garnered from the Chinese practices can help in designing and constructing buildings that can withstand various environmental challenges,\\u201d he opined.  \\u201cAs the world collectively embraces the imperative of sustainable development, the Pak-China partnership aligns seamlessly with these global goals. Both nations recognize the importance of environment-friendly construction practices and adoption of green building materials.\\u201d  \\u201cThrough joint research initiatives and knowledge-sharing, the collaboration will be instrumental in achieving the targets related to climate action and responsible consumption and production.\\u201d  \\u201cImplementing focused training programs and knowledge-sharing initiatives is crucial for cultivating a skilled and competitive construction workforce in Pakistan,\\u201d he suggested.  He further informed WealthPK that more than 5,000 trained and experienced Chinese engineers and workers and more than 2,000 Pakistani engineers and workers were involved in different projects under the CPEC.  According to the SBP Annual Report 2023, the construction industry recorded a contraction of 5.5 percent in FY23, after registering a moderate growth in the previous two years. Increase in input prices and wages, higher borrowing costs, and slower growth in development spending are the main factors which constrained the construction activity during FY23.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cc_sentiment_scores\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"urw_sentiment_scores\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"level2_sentiment_scores\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment_scores\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"entities\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"actants\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"actants_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Subject: jerry cans, Habib Elahi. Object: ESG, Unity Foods, The Green Ark, Karachi - Unity Foods, The Green Ark, TGA, TGA, Unity Foods, Unity Foods, The Green Ark, Unity Foods, Pakistan, Unity Foods, ESG, The Green Ark, Corporate Communications, The Green Ark, Unity Foods, TGA.\",\n          \"Subject: Storm Jocelyn, Windy, Outlook. Object: Met Office, UK, UK, Met Office, UK, The Met Office, UK, Highlands & Eilean Siar, Orkney & Shetland, Scotland, UK, Belfast, Glasgow, UK, Storm Isha, Met Office, UK, Met Office, Britain, England, River Ouse, York city, Met Office, Scotland.\",\n          \"Subject: Liaqat Ali Shah. Object: Pakistan, Pakistan, CPEC, CPEC, CPEC, Pakistan, China, Pakistan, China, Pakistan, CPEC, the SBP Annual Report. Helper: the Centre of Excellence for.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"token_based_embedding\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"actants_embedding\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"combined_embedding\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Processed datasets\n",
        "processed_train_df = pd.read_csv('/content/drive/MyDrive/NLP_Proj/embedded_article/processed_train_articles.csv')\n",
        "processed_dev_df = pd.read_csv('/content/drive/MyDrive/NLP_Proj/embedded_article/processed_dev_articles.csv')\n",
        "\n",
        "\n",
        "sentiment_data_train = train_articles[['article_id', 'sentiment_scores', 'level2_sentiment_scores']]\n",
        "sentiment_data_dev = dev_articles[['article_id', 'sentiment_scores', 'level2_sentiment_scores']]\n",
        "\n",
        "# Merge sentiment data with the existing DataFrame\n",
        "processed_train_df = processed_train_df.merge(\n",
        "    sentiment_data_train,\n",
        "    on=\"article_id\",\n",
        "    how=\"left\"  # Use 'left' to keep all rows from processed_train_df\n",
        ")\n",
        "\n",
        "processed_dev_df = processed_dev_df.merge(\n",
        "    sentiment_data_dev,\n",
        "    on=\"article_id\",\n",
        "    how=\"left\"  # Use 'left' to keep all rows from processed_dev_df\n",
        ")\n",
        "\n",
        "processed_train_df.to_csv('/content/drive/MyDrive/NLP_Proj/embedded_article/processed_train_articles.csv', index=False)\n",
        "processed_dev_df.to_csv('/content/drive/MyDrive/NLP_Proj/embedded_article/processed_dev_articles.csv', index=False)\n"
      ],
      "metadata": {
        "id": "DGacuqknrCfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_train_df.head()"
      ],
      "metadata": {
        "id": "lqesIvHEpoyL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 695
        },
        "outputId": "888e16b7-3962-4ac2-955f-4fa8674f3934"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   article_id                                               text  \\\n",
              "0           4  A Tesla Owner Just Exposed A Sick Secret About...   \n",
              "1           6  ESG in action: Unity Foods partners with The G...   \n",
              "2           9  Leveraging Chinese expertise to help Pakistan ...   \n",
              "3          12  Bill Gates Says He Is ‘The Solution’ To Climat...   \n",
              "4          10  Met Office issues urgent warning as 70mph wind...   \n",
              "\n",
              "                                 cc_sentiment_scores  \\\n",
              "0  [0.0, 0.0, -0.4854, -0.977, 0.0, 0.0, -0.25, 0...   \n",
              "1  [0.0, 0.0, 0.4939, -0.8977, 0.0, 0.0, 0.296, 0...   \n",
              "2  [0.0, 0.0, 0.3818, 0.9851, 0.6249, 0.0, 0.3818...   \n",
              "3  [-0.5267, 0.0, -0.8397, -0.5329, 0.0, 0.34, 0....   \n",
              "4  [0.1531, 0.0, 0.7992, -0.7037, 0.0, 0.0, 0.778...   \n",
              "\n",
              "                                urw_sentiment_scores  \\\n",
              "0  [-0.9793, -0.7964, 0.0, 0.0, 0.0, -0.25, -0.39...   \n",
              "1  [0.7254, -0.4215, 0.0, 0.0, 0.0, 0.296, 0.0, 0...   \n",
              "2  [0.9883, 0.0, 0.0, 0.0, 0.0, 0.3818, 0.0, 0.0,...   \n",
              "3  [0.8807, 0.0, 0.0, 0.0, 0.34, 0.6249, -0.296, ...   \n",
              "4  [0.8994, 0.7105, 0.0, 0.0, 0.0, 0.7783, 0.1779...   \n",
              "\n",
              "                           level2_sentiment_scores_x  \\\n",
              "0  [-0.9793, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...   \n",
              "1  [0.7254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2732,...   \n",
              "2  [0.9883, 0.0, 0.0, 0.0, 0.0, 0.9744, 0.6249, 0...   \n",
              "3  [0.8807, 0.0, -0.5267, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
              "4  [0.8994, 0.0, 0.1531, 0.0, 0.0, 0.5499, 0.0, 0...   \n",
              "\n",
              "                                  sentiment_scores_x  \\\n",
              "0  [0.0, 0.0, -0.4854, -0.977, 0.0, 0.0, -0.25, 0...   \n",
              "1  [0.0, 0.0, 0.4939, -0.8977, 0.0, 0.0, 0.296, 0...   \n",
              "2  [0.0, 0.0, 0.3818, 0.9851, 0.6249, 0.0, 0.3818...   \n",
              "3  [-0.5267, 0.0, -0.8397, -0.5329, 0.0, 0.34, 0....   \n",
              "4  [0.1531, 0.0, 0.7992, -0.7037, 0.0, 0.0, 0.778...   \n",
              "\n",
              "                                            entities  \\\n",
              "0  [('Tesla', 'ORG'), ('Tesla', 'ORG'), ('An Inco...   \n",
              "1  [('ESG', 'ORG'), ('Unity Foods', 'ORG'), ('The...   \n",
              "2  [('Chinese', 'NORP'), ('Pakistan', 'GPE'), ('P...   \n",
              "3  [('Bill Gates', 'PERSON'), ('Jets', 'PERSON'),...   \n",
              "4  [('Met Office', 'ORG'), ('70mph', 'QUANTITY'),...   \n",
              "\n",
              "                                             actants  \\\n",
              "0  {'subject': ['Al Gore', 'Teslas', 'Brad Temple...   \n",
              "1  {'subject': ['jerry cans', 'Habib Elahi'], 'ob...   \n",
              "2  {'subject': ['Liaqat Ali Shah'], 'object': ['P...   \n",
              "3  {'subject': ['Bill Gates', 'Jets', 'Bill Gates...   \n",
              "4  {'subject': ['Storm Jocelyn', 'Windy', 'Outloo...   \n",
              "\n",
              "                                        actants_text  \\\n",
              "0  Subject: Al Gore, Teslas, Brad Templeton, Temp...   \n",
              "1  Subject: jerry cans, Habib Elahi. Object: ESG,...   \n",
              "2  Subject: Liaqat Ali Shah. Object: Pakistan, Pa...   \n",
              "3  Subject: Bill Gates, Jets, Bill Gates, Bill Ga...   \n",
              "4  Subject: Storm Jocelyn, Windy, Outlook. Object...   \n",
              "\n",
              "                               token_based_embedding  \\\n",
              "0  [-2.20114999e-02 -7.43241748e-03  1.48590431e-...   \n",
              "1  [-1.49614885e-02 -1.18577424e-02 -7.84347416e-...   \n",
              "2  [-1.31679531e-02  2.00936757e-02  1.08389510e-...   \n",
              "3  [-1.53975850e-02  2.16554403e-02  3.88043793e-...   \n",
              "4  [ 2.59630382e-02  2.01363210e-02 -1.44498814e-...   \n",
              "\n",
              "                                   actants_embedding  \\\n",
              "0  [-2.22615455e-03  5.55878654e-02  2.65476219e-...   \n",
              "1  [ 2.30540931e-02  5.84620759e-02  1.38649140e-...   \n",
              "2  [-1.20793469e-02  7.83775449e-02  2.19057687e-...   \n",
              "3  [-1.27927875e-02  6.95729330e-02  1.52389724e-...   \n",
              "4  [-2.96973810e-03  6.68433011e-02  2.06416678e-...   \n",
              "\n",
              "                                  combined_embedding  \\\n",
              "0  [-0.0220115  -0.00743242  0.01485904 ...  0.01...   \n",
              "1  [-0.01496149 -0.01185774 -0.00078435 ...  0.03...   \n",
              "2  [-0.01316795  0.02009368  0.01083895 ...  0.03...   \n",
              "3  [-0.01539758  0.02165544  0.00388044 ...  0.01...   \n",
              "4  [ 0.02596304  0.02013632 -0.01444988 ...  0.10...   \n",
              "\n",
              "                                  sentiment_scores_y  \\\n",
              "0  [0.0, 0.0, -0.4854, -0.977, 0.0, 0.0, -0.25, 0...   \n",
              "1  [0.0, 0.0, 0.4939, -0.8977, 0.0, 0.0, 0.296, 0...   \n",
              "2  [0.0, 0.0, 0.3818, 0.9851, 0.6249, 0.0, 0.3818...   \n",
              "3  [-0.5267, 0.0, -0.8397, -0.5329, 0.0, 0.34, 0....   \n",
              "4  [0.1531, 0.0, 0.7992, -0.7037, 0.0, 0.0, 0.778...   \n",
              "\n",
              "                           level2_sentiment_scores_y  \n",
              "0  [-0.9793, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...  \n",
              "1  [0.7254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2732,...  \n",
              "2  [0.9883, 0.0, 0.0, 0.0, 0.0, 0.9744, 0.6249, 0...  \n",
              "3  [0.8807, 0.0, -0.5267, 0.0, 0.0, 0.0, 0.0, 0.0...  \n",
              "4  [0.8994, 0.0, 0.1531, 0.0, 0.0, 0.5499, 0.0, 0...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1f2c22da-f513-42eb-8544-2de0bc428adb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article_id</th>\n",
              "      <th>text</th>\n",
              "      <th>cc_sentiment_scores</th>\n",
              "      <th>urw_sentiment_scores</th>\n",
              "      <th>level2_sentiment_scores_x</th>\n",
              "      <th>sentiment_scores_x</th>\n",
              "      <th>entities</th>\n",
              "      <th>actants</th>\n",
              "      <th>actants_text</th>\n",
              "      <th>token_based_embedding</th>\n",
              "      <th>actants_embedding</th>\n",
              "      <th>combined_embedding</th>\n",
              "      <th>sentiment_scores_y</th>\n",
              "      <th>level2_sentiment_scores_y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>A Tesla Owner Just Exposed A Sick Secret About...</td>\n",
              "      <td>[0.0, 0.0, -0.4854, -0.977, 0.0, 0.0, -0.25, 0...</td>\n",
              "      <td>[-0.9793, -0.7964, 0.0, 0.0, 0.0, -0.25, -0.39...</td>\n",
              "      <td>[-0.9793, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
              "      <td>[0.0, 0.0, -0.4854, -0.977, 0.0, 0.0, -0.25, 0...</td>\n",
              "      <td>[('Tesla', 'ORG'), ('Tesla', 'ORG'), ('An Inco...</td>\n",
              "      <td>{'subject': ['Al Gore', 'Teslas', 'Brad Temple...</td>\n",
              "      <td>Subject: Al Gore, Teslas, Brad Templeton, Temp...</td>\n",
              "      <td>[-2.20114999e-02 -7.43241748e-03  1.48590431e-...</td>\n",
              "      <td>[-2.22615455e-03  5.55878654e-02  2.65476219e-...</td>\n",
              "      <td>[-0.0220115  -0.00743242  0.01485904 ...  0.01...</td>\n",
              "      <td>[0.0, 0.0, -0.4854, -0.977, 0.0, 0.0, -0.25, 0...</td>\n",
              "      <td>[-0.9793, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6</td>\n",
              "      <td>ESG in action: Unity Foods partners with The G...</td>\n",
              "      <td>[0.0, 0.0, 0.4939, -0.8977, 0.0, 0.0, 0.296, 0...</td>\n",
              "      <td>[0.7254, -0.4215, 0.0, 0.0, 0.0, 0.296, 0.0, 0...</td>\n",
              "      <td>[0.7254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2732,...</td>\n",
              "      <td>[0.0, 0.0, 0.4939, -0.8977, 0.0, 0.0, 0.296, 0...</td>\n",
              "      <td>[('ESG', 'ORG'), ('Unity Foods', 'ORG'), ('The...</td>\n",
              "      <td>{'subject': ['jerry cans', 'Habib Elahi'], 'ob...</td>\n",
              "      <td>Subject: jerry cans, Habib Elahi. Object: ESG,...</td>\n",
              "      <td>[-1.49614885e-02 -1.18577424e-02 -7.84347416e-...</td>\n",
              "      <td>[ 2.30540931e-02  5.84620759e-02  1.38649140e-...</td>\n",
              "      <td>[-0.01496149 -0.01185774 -0.00078435 ...  0.03...</td>\n",
              "      <td>[0.0, 0.0, 0.4939, -0.8977, 0.0, 0.0, 0.296, 0...</td>\n",
              "      <td>[0.7254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2732,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9</td>\n",
              "      <td>Leveraging Chinese expertise to help Pakistan ...</td>\n",
              "      <td>[0.0, 0.0, 0.3818, 0.9851, 0.6249, 0.0, 0.3818...</td>\n",
              "      <td>[0.9883, 0.0, 0.0, 0.0, 0.0, 0.3818, 0.0, 0.0,...</td>\n",
              "      <td>[0.9883, 0.0, 0.0, 0.0, 0.0, 0.9744, 0.6249, 0...</td>\n",
              "      <td>[0.0, 0.0, 0.3818, 0.9851, 0.6249, 0.0, 0.3818...</td>\n",
              "      <td>[('Chinese', 'NORP'), ('Pakistan', 'GPE'), ('P...</td>\n",
              "      <td>{'subject': ['Liaqat Ali Shah'], 'object': ['P...</td>\n",
              "      <td>Subject: Liaqat Ali Shah. Object: Pakistan, Pa...</td>\n",
              "      <td>[-1.31679531e-02  2.00936757e-02  1.08389510e-...</td>\n",
              "      <td>[-1.20793469e-02  7.83775449e-02  2.19057687e-...</td>\n",
              "      <td>[-0.01316795  0.02009368  0.01083895 ...  0.03...</td>\n",
              "      <td>[0.0, 0.0, 0.3818, 0.9851, 0.6249, 0.0, 0.3818...</td>\n",
              "      <td>[0.9883, 0.0, 0.0, 0.0, 0.0, 0.9744, 0.6249, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>12</td>\n",
              "      <td>Bill Gates Says He Is ‘The Solution’ To Climat...</td>\n",
              "      <td>[-0.5267, 0.0, -0.8397, -0.5329, 0.0, 0.34, 0....</td>\n",
              "      <td>[0.8807, 0.0, 0.0, 0.0, 0.34, 0.6249, -0.296, ...</td>\n",
              "      <td>[0.8807, 0.0, -0.5267, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
              "      <td>[-0.5267, 0.0, -0.8397, -0.5329, 0.0, 0.34, 0....</td>\n",
              "      <td>[('Bill Gates', 'PERSON'), ('Jets', 'PERSON'),...</td>\n",
              "      <td>{'subject': ['Bill Gates', 'Jets', 'Bill Gates...</td>\n",
              "      <td>Subject: Bill Gates, Jets, Bill Gates, Bill Ga...</td>\n",
              "      <td>[-1.53975850e-02  2.16554403e-02  3.88043793e-...</td>\n",
              "      <td>[-1.27927875e-02  6.95729330e-02  1.52389724e-...</td>\n",
              "      <td>[-0.01539758  0.02165544  0.00388044 ...  0.01...</td>\n",
              "      <td>[-0.5267, 0.0, -0.8397, -0.5329, 0.0, 0.34, 0....</td>\n",
              "      <td>[0.8807, 0.0, -0.5267, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10</td>\n",
              "      <td>Met Office issues urgent warning as 70mph wind...</td>\n",
              "      <td>[0.1531, 0.0, 0.7992, -0.7037, 0.0, 0.0, 0.778...</td>\n",
              "      <td>[0.8994, 0.7105, 0.0, 0.0, 0.0, 0.7783, 0.1779...</td>\n",
              "      <td>[0.8994, 0.0, 0.1531, 0.0, 0.0, 0.5499, 0.0, 0...</td>\n",
              "      <td>[0.1531, 0.0, 0.7992, -0.7037, 0.0, 0.0, 0.778...</td>\n",
              "      <td>[('Met Office', 'ORG'), ('70mph', 'QUANTITY'),...</td>\n",
              "      <td>{'subject': ['Storm Jocelyn', 'Windy', 'Outloo...</td>\n",
              "      <td>Subject: Storm Jocelyn, Windy, Outlook. Object...</td>\n",
              "      <td>[ 2.59630382e-02  2.01363210e-02 -1.44498814e-...</td>\n",
              "      <td>[-2.96973810e-03  6.68433011e-02  2.06416678e-...</td>\n",
              "      <td>[ 0.02596304  0.02013632 -0.01444988 ...  0.10...</td>\n",
              "      <td>[0.1531, 0.0, 0.7992, -0.7037, 0.0, 0.0, 0.778...</td>\n",
              "      <td>[0.8994, 0.0, 0.1531, 0.0, 0.0, 0.5499, 0.0, 0...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1f2c22da-f513-42eb-8544-2de0bc428adb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1f2c22da-f513-42eb-8544-2de0bc428adb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1f2c22da-f513-42eb-8544-2de0bc428adb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d298fe83-f200-4642-a3d5-518930f94ae9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d298fe83-f200-4642-a3d5-518930f94ae9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d298fe83-f200-4642-a3d5-518930f94ae9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "processed_train_df",
              "summary": "{\n  \"name\": \"processed_train_df\",\n  \"rows\": 399,\n  \"fields\": [\n    {\n      \"column\": \"article_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 115,\n        \"min\": 1,\n        \"max\": 399,\n        \"num_unique_values\": 399,\n        \"samples\": [\n          220,\n          361,\n          22\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 396,\n        \"samples\": [\n          \"WATCH: Arrests Made as Global Climate Protesters Demand End to Fossil Fuels\\nRoads will be blocked, cities shut down, airports targeted, marches begun and chanting, lots of chanting, will combine Friday as climate protesters around the world rally to demand an immediate end to fossil fuel use.  That\\u2019s the plan, anyway, with the so-called Global Climate Strike 2023 destined to last through the weekend and end late Sunday.  AP reports the mass public action \\u2014 driven by several mostly youth-led, local and global climate groups and organizations, including Greta Thunberg\\u2019s Fridays for Future movement \\u2014 will take place in dozens of countries and in at least 50 cities worldwide for 72-hours.  WATCH: Greta Thunberg Calls for \\u201cDrastic Emissions Cuts\\u201d to \\u201cFundamentally Change Our Society\\u201d  The protest demands include \\u2013 but are not restricted to \\u2013 \\u201cdivesting from new and current fossil fuel projects, sharing the burden equally among society, investing in community-owned renewable energy projects, and paying reparations to communities affected by the climate crisis,\\u201d Euronews reports.  Organisers said their climate protest would call on governments to end subsidies for oil and gas immediately and to cancel any plans for expanding fossil fuel production.  Financial institutions of all types around world will also face protests and a call for them to end funding fossil fuel development.  In one strike in Quezon City in the Philippines, AP reports activists lay in front of the Department of Environment and Natural Resources in protest, and held signs demanding fossil fuels \\u2014 from coal to natural gas \\u2014 be phased out.  Another major mass action is planned to take place Sunday in New York, to coincide with the city\\u2019s Climate Week and the U.N. climate summit.  Climate activists have organized similar worldwide strikes in recent years, where protesters from different nations join together on a single day.  The \\u201cclimate strike\\u201d comes two months before this year\\u2019s United Nations COP28 climate summit, where more than 80 countries plan to push for a global agreement to phase out coal, oil and gas.  COMMENTS  Please let us know if you're having issues with commenting.\",\n          \"Warning US could be \\u2018hit with most debilitating strike EVER\\u2019 in space war with Russia after chilling ISS threat\\nWarning US could be \\u2018hit with most debilitating strike EVER\\u2019 in space war with Russia after chilling ISS threat  THE US could be hit with the most debilitating and destructive strike ever in a potential space war with Russia, an expert warns.  Relations between Moscow and Washington have plunged to new lows amid the Ukrainian crisis, and Russia\\u2019s space agency warned that US sanctions could \\u201cdestroy\\u201d cooperation on the International Space Station.  Moscow claimed Washington needs its cooperation to prevent the ISS from falling on the US or Europe.  Geopolitical and space expert Brandon J Weichert told The Sun that Moscow has a decade to a 12-year advantage on the US in the galaxies.  He said US defenses are in \\u201cno way fit\\u201d to deal with the challenges posed by Russia.  Weichert warned: \\u201cWe are going to get hit very hard soon in space. It is going to be the most debilitating strike on America, possibly ever.  \\u201cAnd we may not recover from it in a timely fashion. This could be how we lose our first war on Earth is losing the war in space.\\u201d  Weichert slammed the \\\"arrogant\\\" DC political class, claiming they didn\\u2019t foresee any rival challenging Washington\\u2019s dominance in the post-Cold-War world.  Most read in The Sun  He said: \\u201cThey thought there would never be a need for any kind of preventative or security measure because we thought we would always be dominant, and we thought no one would be crazy enough to challenge us.  \\u201cWell here we are 30 years later, and you have Russia, China, North Korea, and even Iran showing us that it was the wrong assumption.\\u201d  The expert feared that the US has a 60 percent chance of being pushed out of space by its rivals completely.  President Biden unleashed a package of sanctions against Moscow on Thursday after Putin\\u2019s forces rolled into Ukraine.  And, an additional 7,000 troops will be sent to Eastern Europe to bolster Nato\\u2019s defenses.  Russia\\u2019s invasion of the besieged nation saw Europe plunged into its biggest crisis since World War II.  Experts claim the world has not seen a crisis since the Cuban Missile Crisis in the 1960s.  The flashpoint was the closest point the world came to a full-blown nuclear war.  US intelligence feared that Kyiv could fall within 96 hours and US Secretary of State Antony Blinken said it\\u2019s a \\u201cpossibility\\u201d that Putin could move beyond the borders of Ukraine.  The Russian strongman may feel emboldened and seek to move on to other nations if successful.  Troops have reportedly already been spotted in the Belarussian city of Brest \\u2013 10 miles east of the Polish border.  Biden told reporters Thursday: \\u201cHe has much larger ambitions. He wants to, in fact, re-establish the former Soviet Union. That\\u2019s what this is all about.\\u201d  Weichert said: \\u201cIf Putin suspects the West will prop up a formidable anti-Russian resistance in a post-invasion Ukraine, he will risk not only nuclear war but also will threaten to attack US assets in space and the ISS.  \\u201cPutin fully understands the concept of asymmetrical warfare.\\u201d  He speculated that Moscow will ramp up its threats in cyberspace and nuclear warfare.  PUTIN'S THREATS  In December, Weichert warned that Moscow is plotting to launch a Pearl Harbor attack on the US in the cosmos.  The Pearl Harbor attack of December 1941 left America reeling as Japanese forces bombed the US naval port.  In his book, Winning Space: How America Remains a Superpower, Weichert says that Russian co-orbital satellites, known as space stalkers, have been tailgating US satellites for years.  He predicts that the stalkers will eventually hit the satellites, sending them crashing into the ground.  Weichert believes Russia is preparing to launch a \\\"devastating\\\" attack on American satellites at the time of its own choice.  He warned that before launching an attack on Washington\\u2019s satellites, Moscow would \\\"engage in a series of escalations\\u201d with neighboring nations.  Russia conducted an anti-satellite weapon test (ASAT) in November where it destroyed one of its own satellites that had been in orbit since 1982.  READ MORE SUN STORIES  Blinken branded the test \\\"dangerous and irresponsible\\\" as it created a field of 1,500 pieces of debris, forcing the ISS crew to take shelter.  State Department spokesperson Ned Price said the test marked an increase in the risk to astronauts and cosmonauts on the ISS.  We pay for your stories!  Do you have a story for The US Sun team?  Email us at exclusive@the-sun.com or call 212 416 4552.  Like us on Facebook at www.facebook.com/TheSunUS and follow us from our main Twitter account at @TheSunUS\",\n          \"Israel to respond to genocide charges at UN\\u2019s top court06:35\\nIsrael to respond to genocide charges at UN\\u2019s top court  Israel will respond to charges of genocide at the United Nations\\u2019 top court on Friday after South Africa filed an urgent request with the court to order a ceasefire in Gaza.  It is the third time the International Court of Justice (ICJ) has held hearings on the Israel-Hamas war since South Africa filed proceedings at The Hague court in December.  On Thursday, South Africa told the court the situation in Gaza has reached \\u201ca new and horrific stage\\u201d, and urged the 15 judges to take urgent action.  Israel must \\u201ctotally and unconditionally withdraw\\u201d from the Gaza Strip, said Vusimuzi Madonsela, South Africa\\u2019s ambassador to the Netherlands.  South Africa has submitted four requests for the ICJ to investigate Israel. According to the latest request, the country says Israel\\u2019s military incursion in Rafah threatens the \\u201cvery survival of Palestinians in Gaza\\u201d.  During hearings earlier this year, Israel strongly denied committing genocide in Gaza, saying it does all it can to spare civilians and is only targeting Hamas militants. Israel says Rafah is the last stronghold of the militant group.  In January, judges ordered Israel to do all it can to prevent death, destruction and any acts of genocide in Gaza, but the panel stopped short of ordering an end to the military offensive.  The court has already found that there is a \\u201creal and imminent risk\\u201d to the Palestinian people in Gaza by Israel\\u2019s military operations.  \\u201cThis may well be the last chance for the court to act,\\u201d said Irish lawyer Blinne Ni Ghralaigh, who is part of South Africa\\u2019s legal team.  ICJ judges have broad powers to order a ceasefire and other measures, though the court does not have its own enforcement apparatus.  A 2022 order by the court demanding that Russia halt its full-scale invasion of Ukraine has so far gone unheeded.  Most of Gaza\\u2019s population of 2.3 million people have been displaced since fighting began.  The war began with a Hamas attack on southern Israel on October 7 in which Palestinian militants killed around 1,200 people and took about 250 hostages.  Gaza\\u2019s Health Ministry says more than 35,000 Palestinians have been killed in the war without distinguishing between civilians and combatants in its count.  South Africa initiated proceedings in December 2023 and sees the legal campaign as rooted in issues central to its identity. Its governing party, the African National Congress, has long compared Israel\\u2019s policies in Gaza and the occupied West Bank to its own history under the apartheid regime of white minority rule, which restricted most Blacks to \\u201chomelands\\u201d. Apartheid ended in 1994.  On Sunday, Egypt announced it plans to join the case. Several countries have also indicated they plan to intervene, but only Libya, Nicaragua and Colombia have filed formal requests to do so.  Join the Belfast Telegraph WhatsApp channel  Stay up to date with some of Northern Ireland's biggest stories\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cc_sentiment_scores\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 395,\n        \"samples\": [\n          \"[0.1531, 0.0, 0.0, 0.5423, 0.0, -0.4588, 0.5859, 0.0, 0.0, 0.0]\",\n          \"[0.0, 0.0, -0.8225, -0.9896, -0.4588, 0.0, 0.0, 0.0, 0.0, 0.0]\",\n          \"[0.0, 0.0, -0.0387, -0.625, 0.0, -0.1546, -0.0258, 0.0, 0.0, 0.0]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"urw_sentiment_scores\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 395,\n        \"samples\": [\n          \"[0.1346, 0.0, 0.0, 0.0, -0.4588, 0.5859, 0.0, 0.0, 0.7184, 0.0]\",\n          \"[-0.9828, -0.9786, 0.0, -0.2263, 0.0, 0.0, -0.9136, -0.5574, 0.6124, 0.0]\",\n          \"[0.3662, 0.0, 0.1531, -0.2066, -0.1546, -0.0258, 0.0, -0.8519, -0.5106, 0.0]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"level2_sentiment_scores_x\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 395,\n        \"samples\": [\n          \"[0.1346, 0.0, 0.1531, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.6124, 0.9413, 0.0, 0.0, 0.7184, -0.1027, -0.4215, -0.7269, 0.0]\",\n          \"[-0.9828, -0.8957, 0.0, 0.0, -0.2263, -0.2263, -0.4588, 0.0, 0.0, 0.0, -0.2263, 0.0, -0.9726, 0.0, 0.0, 0.0, -0.8271, -0.872, 0.0, 0.0]\",\n          \"[0.3662, 0.3595, 0.0, 0.0, -0.2066, -0.34, 0.0, 0.0, 0.0, 0.0, -0.2066, 0.0, -0.7851, 0.0, 0.0, 0.0, -0.7783, -0.703, -0.6486, 0.0]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment_scores_x\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 395,\n        \"samples\": [\n          \"[0.1531, 0.0, 0.0, 0.5423, 0.0, -0.4588, 0.5859, 0.0, 0.0, 0.0, 0.1346, 0.0, 0.0, 0.0, -0.4588, 0.5859, 0.0, 0.0, 0.7184, 0.0, 0.1346, 0.0, 0.1531, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.6124, 0.9413, 0.0, 0.0, 0.7184, -0.1027, -0.4215, -0.7269, 0.0]\",\n          \"[0.0, 0.0, -0.8225, -0.9896, -0.4588, 0.0, 0.0, 0.0, 0.0, 0.0, -0.9828, -0.9786, 0.0, -0.2263, 0.0, 0.0, -0.9136, -0.5574, 0.6124, 0.0, -0.9828, -0.8957, 0.0, 0.0, -0.2263, -0.2263, -0.4588, 0.0, 0.0, 0.0, -0.2263, 0.0, -0.9726, 0.0, 0.0, 0.0, -0.8271, -0.872, 0.0, 0.0]\",\n          \"[0.0, 0.0, -0.0387, -0.625, 0.0, -0.1546, -0.0258, 0.0, 0.0, 0.0, 0.3662, 0.0, 0.1531, -0.2066, -0.1546, -0.0258, 0.0, -0.8519, -0.5106, 0.0, 0.3662, 0.3595, 0.0, 0.0, -0.2066, -0.34, 0.0, 0.0, 0.0, 0.0, -0.2066, 0.0, -0.7851, 0.0, 0.0, 0.0, -0.7783, -0.703, -0.6486, 0.0]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"entities\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 395,\n        \"samples\": [\n          \"[('Fossil Fuels', 'PERSON'), ('Friday', 'DATE'), ('Global Climate Strike 2023', 'ORG'), ('the weekend', 'DATE'), ('late Sunday', 'DATE'), ('AP', 'ORG'), ('Greta Thunberg\\u2019s', 'PERSON'), ('Fridays', 'DATE'), ('dozens', 'CARDINAL'), ('at least 50', 'CARDINAL'), ('72-hours', 'TIME'), ('Greta Thunberg', 'PERSON'), ('Fundamentally Change Our Society', 'WORK_OF_ART'), ('one', 'CARDINAL'), ('Quezon City', 'GPE'), ('Philippines', 'GPE'), ('AP', 'ORG'), ('the Department of Environment and Natural Resources', 'ORG'), ('Sunday', 'DATE'), ('New York', 'GPE'), ('U.N.', 'ORG'), ('recent years', 'DATE'), ('a single day', 'DATE'), ('two months before this year', 'DATE'), ('United Nations', 'ORG'), ('more than 80', 'CARDINAL')]\",\n          \"[('Biden', 'PERSON'), ('Israel', 'GPE'), ('Ukraine', 'GPE'), ('Biden', 'PERSON'), ('Israel', 'GPE'), ('Ukraine', 'GPE'), ('WASHINGTON', 'GPE'), ('NewsNation', 'ORG'), ('Joe Biden', 'PERSON'), ('fourth', 'ORDINAL'), ('Thursday', 'DATE'), ('evening', 'TIME'), ('American', 'NORP'), ('Israel', 'GPE'), ('Ukraine', 'GPE'), ('Israel', 'GPE'), ('the Gaza Strip', 'GPE'), ('Palestinians', 'NORP'), ('Palestinian', 'NORP'), ('Israel', 'GPE'), ('Thursday', 'DATE'), ('Gaza', 'GPE'), ('Lebanon', 'GPE'), ('Israeli', 'NORP'), ('West Financial', 'LOC'), ('Biden', 'PERSON'), ('$100 billion', 'MONEY'), ('the subsequent 12 months', 'DATE'), ('White Home', 'ORG'), ('The Related Press', 'ORG'), ('Biden', 'PERSON'), ('Thursday', 'DATE'), ('the week', 'DATE'), ('Israel', 'GPE'), ('3,785', 'CARDINAL'), ('Gaza', 'GPE'), ('12,500', 'CARDINAL'), ('one', 'CARDINAL'), ('1,300', 'CARDINAL'), ('1,400', 'CARDINAL'), ('Israel', 'GPE'), ('Hamas', 'ORG'), ('Oct. 7', 'DATE'), ('Roughly 200', 'CARDINAL'), ('Israeli', 'NORP'), ('Thursday', 'DATE'), ('203', 'CARDINAL'), ('the White Home', 'ORG'), ('Ukraine', 'GPE'), ('Russia', 'GPE'), ('Russian', 'NORP'), ('two', 'CARDINAL'), ('Ukraine', 'GPE'), ('Wednesday', 'DATE'), ('Vladimir Putin', 'PERSON'), ('U.S.-supplied', 'ORG'), ('Kyiv', 'PERSON'), ('Kremlin', 'ORG'), ('Putin', 'PERSON'), ('Russia', 'GPE'), ('the U.S.-made Military Tactical Missile System', 'ORG'), ('ATACMS', 'PRODUCT'), ('Biden', 'PERSON'), ('Biden', 'PERSON'), ('Home', 'ORG'), ('Republican', 'NORP'), ('Kevin McCarthy', 'PERSON'), ('greater than two weeks', 'DATE'), ('Patrick McHenry', 'PERSON'), ('Home', 'ORG'), ('Congress', 'ORG'), ('Biden', 'PERSON'), ('the Oval Workplace', 'FAC'), ('8:00 pm', 'TIME'), ('Biden', 'PERSON'), ('U.S.', 'GPE'), ('first', 'ORDINAL'), ('Minneapolis', 'GPE'), ('Derek Chauvin', 'PERSON'), ('George Floyd', 'PERSON')]\",\n          \"[('Ukraine', 'GPE'), ('Ukraine', 'GPE'), ('Citizen Soldier', 'PERSON'), ('Ukraine', 'GPE'), ('Last week', 'DATE'), ('the State Department', 'ORG'), ('Russian', 'NORP'), ('the United States', 'GPE'), ('the estimated $300 billion', 'MONEY'), ('Europe', 'LOC'), ('$500 billion', 'MONEY'), ('Putin', 'PERSON'), ('Russia', 'GPE'), ('State', 'ORG'), ('Antony Blinken', 'PERSON'), ('Blinken', 'PERSON'), ('Pottery Barn', 'WORK_OF_ART'), ('Colin Powell', 'PERSON'), ('the summer of 2002', 'DATE'), ('George W. Bush', 'PERSON'), ('Iraq', 'GPE'), ('American', 'NORP'), ('European', 'NORP'), ('billions of missing dollars', 'MONEY'), ('the Coalition Provisional Authority\\u2019s', 'ORG'), ('Iraq', 'GPE'), ('Russia', 'GPE'), ('Russia', 'GPE'), ('China', 'GPE'), ('American', 'NORP'), ('Libya', 'GPE'), ('Iraq', 'GPE'), ('the United States', 'GPE'), ('DC', 'GPE'), ('the Great Power Competition', 'ORG'), ('China', 'GPE'), ('Russia', 'GPE'), ('Europe', 'LOC'), ('the United States', 'GPE'), ('America', 'GPE'), ('World War II', 'EVENT'), ('Blinken', 'PERSON'), ('Ukraine', 'GPE'), ('America', 'GPE'), ('Russia', 'GPE'), ('America', 'GPE'), ('Citizen Soldier', 'PERSON'), ('Happiness', 'ORG')]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"actants\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 395,\n        \"samples\": [\n          \"{'subject': ['Fossil Fuels', 'Greta Thunberg\\u2019s', 'Greta Thunberg'], 'object': ['Global Climate Strike 2023', 'AP', 'Quezon City', 'Philippines', 'AP', 'the Department of Environment and Natural Resources', 'New York', 'U.N.', 'United Nations'], 'helper': ['the Department of Environment and Natural Resources', 'United Nations'], 'opponent': []}\",\n          \"{'subject': ['Biden', 'Biden', 'Joe Biden', 'Biden', 'Biden', 'Vladimir Putin', 'Kyiv', 'Putin', 'Biden', 'Biden', 'Kevin McCarthy', 'Patrick McHenry', 'Biden', 'Biden', 'Derek Chauvin', 'George Floyd'], 'object': ['Israel', 'Ukraine', 'Israel', 'Ukraine', 'WASHINGTON', 'NewsNation', 'Israel', 'Ukraine', 'Israel', 'the Gaza Strip', 'Israel', 'Gaza', 'Lebanon', 'White Home', 'The Related Press', 'Israel', 'Gaza', 'Israel', 'Hamas', 'the White Home', 'Ukraine', 'Russia', 'Ukraine', 'U.S.-supplied', 'Kremlin', 'Russia', 'the U.S.-made Military Tactical Missile System', 'Home', 'Home', 'Congress', 'U.S.', 'Minneapolis'], 'helper': ['greater than two weeks'], 'opponent': []}\",\n          \"{'subject': ['Citizen Soldier', 'Putin', 'Antony Blinken', 'Blinken', 'Colin Powell', 'George W. Bush', 'Blinken', 'Citizen Soldier'], 'object': ['Ukraine', 'Ukraine', 'Ukraine', 'the State Department', 'the United States', 'Russia', 'State', 'Iraq', 'the Coalition Provisional Authority\\u2019s', 'Iraq', 'Russia', 'Russia', 'China', 'Libya', 'Iraq', 'the United States', 'DC', 'the Great Power Competition', 'China', 'Russia', 'the United States', 'America', 'Ukraine', 'America', 'Russia', 'America', 'Happiness'], 'helper': ['the United States', 'the United States', 'the Great Power Competition', 'the United States', 'Happiness'], 'opponent': ['billions of missing dollars', 'World War II']}\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"actants_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 395,\n        \"samples\": [\n          \"Subject: Fossil Fuels, Greta Thunberg\\u2019s, Greta Thunberg. Object: Global Climate Strike 2023, AP, Quezon City, Philippines, AP, the Department of Environment and Natural Resources, New York, U.N., United Nations. Helper: the Department of Environment and Natural Resources, United Nations.\",\n          \"Subject: Biden, Biden, Joe Biden, Biden, Biden, Vladimir Putin, Kyiv, Putin, Biden, Biden, Kevin McCarthy, Patrick McHenry, Biden, Biden, Derek Chauvin, George Floyd. Object: Israel, Ukraine, Israel, Ukraine, WASHINGTON, NewsNation, Israel, Ukraine, Israel, the Gaza Strip, Israel, Gaza, Lebanon, White Home, The Related Press, Israel, Gaza, Israel, Hamas, the White Home, Ukraine, Russia, Ukraine, U.S.-supplied, Kremlin, Russia, the U.S.-made Military Tactical Missile System, Home, Home, Congress, U.S., Minneapolis. Helper: greater than two weeks.\",\n          \"Subject: Citizen Soldier, Putin, Antony Blinken, Blinken, Colin Powell, George W. Bush, Blinken, Citizen Soldier. Object: Ukraine, Ukraine, Ukraine, the State Department, the United States, Russia, State, Iraq, the Coalition Provisional Authority\\u2019s, Iraq, Russia, Russia, China, Libya, Iraq, the United States, DC, the Great Power Competition, China, Russia, the United States, America, Ukraine, America, Russia, America, Happiness. Helper: the United States, the United States, the Great Power Competition, the United States, Happiness. Opponent: billions of missing dollars, World War II.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"token_based_embedding\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 396,\n        \"samples\": [\n          \"[-1.01175644e-02  3.07316650e-02 -5.00748912e-03  1.73069797e-02\\n  1.42111018e-01 -4.76319008e-02  2.69255112e-03  9.98153239e-02\\n -1.58171747e-02 -2.80281454e-02  2.28548236e-02 -1.17820362e-02\\n  2.52116341e-02 -1.69247726e-03  3.18373516e-02  1.67185944e-02\\n  1.80841088e-02 -3.68161984e-02  6.12140298e-02  2.65990328e-02\\n  4.02402552e-03  1.15738884e-02  5.31964637e-02  2.40522364e-04\\n  6.00141883e-02  1.57966167e-02  1.00132218e-02 -3.19757015e-02\\n  2.50976495e-02  5.30137271e-02  1.51324160e-02 -2.22338997e-02\\n  1.18705938e-02  3.29616889e-02  2.80631762e-02  5.89898117e-02\\n -4.65590460e-03 -2.80619436e-03  3.79945040e-02  6.52916217e-03\\n  6.77111791e-04  3.51533331e-02 -2.48942971e-02  4.04730178e-02\\n  2.34110579e-02  6.06515631e-03  4.33116294e-02  2.83327810e-02\\n  1.96783002e-02 -4.15165015e-02  1.99982319e-02  7.85021558e-02\\n  2.76148338e-02  2.09877104e-01  4.15641852e-02  1.92004610e-02\\n  4.18335684e-02 -2.14592405e-02  3.76600102e-02  1.55188829e-01\\n  3.52267809e-02 -2.31893640e-02  1.42979147e-02  9.25911367e-02\\n  1.20691597e-01  1.07531222e-02  1.74807955e-03 -2.00922098e-02\\n -1.58613622e-02  7.39694713e-03  7.25145042e-02  5.95321245e-02\\n  7.87940547e-02 -9.59746465e-02 -2.06908453e-02 -2.58167088e-02\\n  4.68846895e-02  1.30411098e-02 -4.68763802e-03  2.09406205e-02\\n -1.87068363e-03  6.44982085e-02  3.84860933e-02 -3.75633314e-02\\n  8.80169496e-02  1.00792348e-02 -2.56354641e-02 -4.78701219e-02\\n -1.07882060e-02  1.05820462e-01  2.84024402e-02 -5.02049550e-02\\n  5.06067462e-02  1.87098309e-02  3.33132385e-03 -4.71285358e-03\\n -1.47168543e-02  2.60308795e-02  1.91249624e-02 -3.08926664e-02\\n -3.08076479e-03  1.46745639e-02  3.71179990e-02  9.38090086e-02\\n -1.43621892e-01 -1.56969205e-02 -1.15037314e-03  2.50664819e-02\\n  4.80805784e-02  1.09344915e-01  2.76395790e-02  2.87085231e-02\\n  7.86743015e-02  2.95166206e-02  3.00978702e-02 -3.00221127e-02\\n -1.15771797e-02  9.56759509e-03  9.87479556e-03  1.84682254e-02\\n  3.72784100e-02  3.33282016e-02 -1.90241262e-02  3.85438949e-02\\n -8.49440321e-03 -2.92595057e-03 -2.19449066e-02 -3.05206515e-02\\n  3.61607373e-02  3.96104492e-02  1.58695076e-02  7.42964726e-03\\n  4.35067294e-03 -9.95603949e-03  1.52704092e-02  9.20583233e-02\\n  3.84110259e-03  3.67477834e-02  3.50547805e-02  4.45803925e-02\\n  1.77414459e-03 -1.84498448e-02 -2.78447326e-02  5.33202030e-02\\n  1.40983388e-02 -5.19811809e-01  6.13226648e-03  2.30026245e-02\\n  2.44327378e-03  6.92027658e-02  9.97371320e-03 -8.01117346e-02\\n -1.12962091e+00  3.72196063e-02  2.68100724e-02  4.78199385e-02\\n -1.12960348e-02  2.17398144e-02  4.42540692e-03  6.75282180e-02\\n  7.90634975e-02  3.67827863e-02 -1.06066009e-02  3.36018763e-02\\n -6.70834780e-02 -5.09007834e-02  2.96009872e-02  3.99907604e-02\\n  3.68967041e-04 -8.07663484e-04  1.70722720e-03  1.90998625e-03\\n  6.87251538e-02  2.57807188e-02 -1.08855786e-02 -1.83036458e-02\\n  1.69337187e-02 -2.65543275e-02 -8.34154058e-03 -1.90750081e-02\\n -2.19423734e-02 -2.64565200e-02  8.24479759e-02  4.24873605e-02\\n -1.66745678e-01  5.33529383e-04  3.33071388e-02 -1.63449300e-03\\n  1.10668996e-02 -7.12456880e-03 -5.93649596e-03  2.48606056e-02\\n  6.56290725e-02  5.95616363e-02 -2.90214140e-02 -4.28013057e-02\\n -6.80848863e-03  4.72441688e-02  1.40015862e-03 -2.96148397e-02\\n  1.29573587e-02 -1.43810804e-03  1.13827419e-02  9.22427792e-03\\n -7.16058612e-02 -2.23379564e-02 -3.11335386e-03  2.07399353e-02\\n -1.87870078e-02  1.15296673e-02  1.32290255e-02  2.19965093e-02\\n  5.74905984e-02 -1.01765683e-02 -2.09896974e-02 -1.32783279e-02\\n  2.46857163e-02 -1.21181598e-02  6.55830503e-02  1.30508728e-02\\n -6.57124594e-02  1.31541130e-03 -5.01435203e-03  3.75962593e-02\\n -9.39519238e-03 -4.11156943e-04  2.96583064e-02 -1.10288737e-02\\n  5.63277304e-02 -6.76079914e-02  9.67705529e-03 -1.78321302e-02\\n  4.14312109e-02 -1.89307556e-02 -1.29677467e-02  1.41779343e-02\\n -2.20520291e-04 -1.93328522e-02  7.23862350e-02 -2.36139521e-01\\n -3.01566999e-02 -2.26461403e-02  1.78256333e-02  1.33963674e-02\\n  1.08194388e-01  9.27998743e-04 -3.58853787e-02  3.67652476e-02\\n -8.98525119e-03  8.24304670e-03  3.83083746e-02 -3.09437774e-02\\n -1.21685555e-02  5.03640287e-02  1.22438334e-02  2.19211262e-02\\n -5.74637614e-02  3.32862623e-02 -5.30968010e-02  5.52395701e-01\\n -3.48773226e-02  2.83024516e-02  5.00242822e-02  2.00333763e-02\\n  2.88651139e-02  4.53393161e-02  3.07842672e-01  1.36524037e-01\\n -6.33108839e-02  1.91917904e-02 -8.67354125e-03  6.58080634e-03\\n  1.12794731e-02  4.53149788e-02  2.04883330e-02 -5.16034327e-02\\n -3.86185423e-02 -2.94115134e-02 -2.94033084e-02  5.94244227e-02\\n  6.67944402e-02  1.50372326e-01 -3.36946212e-02  4.96931039e-02\\n  1.54517498e-02  3.87253389e-02  9.84177087e-03  5.63329551e-03\\n  5.77185377e-02  5.83151318e-02 -1.02428691e-02 -2.93158777e-02\\n  7.46595254e-03  7.58914053e-02  1.32052675e-01  1.12561025e-02\\n -9.65069141e-03  3.44859362e-02  1.29808988e-02 -2.33176909e-02\\n  1.15003930e-02 -9.56096873e-02  2.71991286e-02  1.97838782e-03\\n -1.14912270e-02  7.15575069e-02  2.28830993e-01 -1.08397682e-03\\n  3.36670433e-03  1.17134675e-01  2.68822443e-02  2.32079416e-04\\n -9.01288837e-02  6.16242643e-03 -3.96761708e-02 -1.23146689e-02\\n  4.83750924e-02  3.94258015e-02  5.44787496e-02  7.29022697e-02\\n  4.04339693e-02 -4.07103710e-02 -5.98796550e-03  7.08386526e-02\\n -4.67829593e-02  4.57532480e-02  2.81950372e-04  2.35258769e-02\\n  6.02403618e-02  3.91291529e-02  1.69091020e-03  1.78268179e-02\\n -1.18963129e-03  4.93202880e-02 -5.74263185e-02  1.48303583e-02\\n  5.86976111e-02  6.57510608e-02 -5.25476299e-02  7.94941261e-02\\n  1.74417812e-02  2.38809399e-02  7.79081956e-02 -2.45281942e-02\\n  6.19481467e-02  3.02872364e-03  2.45467536e-02  1.33302798e-02\\n  1.12355093e-03  2.12681722e-02  6.52786717e-02 -1.69137605e-02\\n  7.48158768e-02  5.56591414e-02 -2.10770480e-02  4.27785591e-04\\n -8.95718392e-03  3.37699763e-02  9.32478253e-03 -8.85410681e-02\\n -9.30090062e-03  3.94432917e-02  9.77508072e-03  8.08163881e-02\\n -1.02152200e-02 -1.53129436e-02 -1.99209601e-02 -7.92772602e-03\\n -3.06085531e-05  2.15984769e-02 -3.04188635e-02  1.07555194e-02\\n  7.09399162e-03 -1.46388467e-02  3.41263087e-03  2.70043928e-02\\n  6.30244017e-02 -1.21742249e-01 -5.57170389e-03  7.82705564e-03\\n  5.84751628e-02  4.73806262e-02  2.75755301e-02  1.36505822e-02\\n  2.09820010e-02  3.83226611e-02 -1.55190937e-02  2.58001685e-02\\n -7.73241185e-03  8.08711629e-03  4.94097034e-03 -7.41949379e-02\\n  1.08757010e-02 -2.58108135e-02  4.30916697e-02  2.07825936e-02\\n  4.49574180e-02 -2.22526360e-02  3.32189314e-02  5.07532395e-02\\n  7.93241858e-02  2.65753083e-03 -3.94605733e-02 -7.11780041e-03\\n  3.52027006e-02  3.43648121e-02  4.36907224e-02  3.20330169e-03\\n  1.52327102e-02  1.92063097e-02  1.13358773e-01  9.71168559e-03\\n  2.35518464e-03 -4.18361016e-02  7.60699064e-02  1.48268864e-02\\n  4.32905369e-02  3.13822143e-02  5.37483282e-02  5.13869263e-02\\n  4.14925292e-02  5.32312952e-02 -3.25292051e-02  6.44286675e-03\\n  2.11208351e-02 -7.74161145e-02 -3.23188938e-02 -2.68419855e-04\\n -4.56323521e-03  1.56882126e-03  4.33514789e-02  2.68974919e-02\\n  4.15535346e-02 -7.50914635e-03 -2.24886667e-02  1.06223794e-02\\n  1.90381315e-02  1.37353530e-02 -4.43571955e-02  4.00631949e-02\\n  2.51069162e-02  3.27747175e-03 -2.24249233e-02  7.85552114e-02\\n  2.06250045e-02  4.88427877e-02  1.82946697e-02 -1.00191729e-02\\n -1.05398949e-02  1.08143473e-02  3.82324844e-03  1.18276309e-02\\n  4.34675068e-02  1.00106597e-02 -8.75330414e-04  4.66786437e-02\\n  2.04672255e-02  6.60491958e-02  5.20914420e-02 -1.83679640e+00\\n  1.54087553e-02 -8.96823301e-04  7.60295466e-02  7.86563233e-02\\n  2.08053570e-02  5.30474782e-02  3.37787047e-02  1.97756477e-02\\n  1.40749123e-02 -3.06638777e-02  2.18942463e-02 -3.17390240e-03\\n  7.23037124e-02 -1.93765759e-02  4.62685004e-02 -1.32381814e-02\\n  1.14277396e-02 -8.40522256e-03  6.49195397e-04 -3.13564688e-02\\n  8.51910859e-02  1.08406572e-02 -1.53702376e-02 -3.26241851e-02\\n  2.13612951e-02  4.78711799e-02 -3.07639153e-03  1.56165302e-01\\n  2.75647221e-03 -6.86638802e-02  6.08828925e-02 -1.63384248e-02\\n  9.74660181e-03  1.36801926e-02 -1.81593653e-02  7.68056065e-02\\n -2.69088224e-02 -1.85541987e-01  2.42236014e-02  3.63765215e-03\\n -1.78443193e-02  1.47068584e-02  4.10510898e-02  1.55047197e-02\\n -1.55589019e-03  3.02898809e-02  9.07801185e-03  8.50553811e-02\\n  1.63362399e-02  1.94058230e-03  3.44286144e-01  2.30538212e-02\\n  3.26994099e-02 -3.91247161e-02  6.64231926e-02  5.11273406e-02\\n  1.00123622e-02  3.40724885e-02  3.70050222e-02 -1.07481731e-02\\n  5.81369996e-02  6.72984868e-02  3.17601524e-02  4.70455885e-02\\n  1.57688223e-02 -2.22802758e-02  2.42235921e-02 -3.80701758e-02\\n  9.26326495e-03 -8.71483013e-02  2.88097113e-02  4.50296560e-03\\n  8.61710012e-02 -3.35141659e-01 -5.80183268e-02  1.39716128e-02\\n  1.30466167e-02  1.14286747e-02 -2.80859116e-02  7.16603780e-03\\n  5.17761596e-02  4.00574170e-02  1.48035605e-02  4.53569144e-02\\n  1.38722584e-02  4.16393839e-02 -2.84851622e-02  1.31536927e-02\\n  5.20818345e-02  4.54264097e-02 -8.44165124e-03 -1.26176290e-02\\n -2.08496135e-02  1.21892188e-02 -8.42610374e-04 -2.96840095e-03\\n -4.62046330e-04  7.82447532e-02  2.36668307e-02 -2.18351036e-02\\n  5.86539432e-02  6.34552678e-03  2.36173626e-02  2.77032424e-02\\n -1.16267418e-02 -1.15903178e-02  9.57412366e-03  3.26392241e-02\\n -1.33318016e-02 -1.38388742e-02  2.33830768e-03  3.80252190e-02\\n -8.65741819e-03 -5.74816205e-02  4.58374955e-02  6.44028513e-03\\n  2.98909619e-02 -2.57060025e-03 -2.48400234e-02 -1.36462674e-01\\n  2.96264179e-02  4.32078205e-02  1.19637698e-02  2.41696555e-02\\n  4.09807935e-02 -2.71323696e-02  5.51009737e-02  8.54595304e-02\\n -6.25619030e+00 -1.05856340e-02  5.87541610e-02  4.00031125e-03\\n  3.96127719e-03 -4.16619470e-03  2.69799177e-02  2.42192578e-02\\n -2.75230110e-02 -2.28309613e-02 -2.32367383e-04  6.17039530e-03\\n  7.87663385e-02  3.58752012e-02  6.29029572e-02  3.35517712e-02\\n -9.04751476e-03  2.28252467e-02 -1.40842618e-02  3.00426465e-02\\n -1.58631075e-02  5.65993339e-02  5.39372861e-02  6.82661235e-02\\n  4.85536940e-02 -1.63706578e-02  7.10176751e-02 -6.00185692e-02\\n  1.12715568e-02  6.75310045e-02  9.91282053e-03  9.93938930e-03\\n -8.84175394e-03 -1.82736646e-02 -1.90212969e-02  1.78768560e-02\\n -5.58830611e-02 -1.39821805e-02  3.70474495e-02  4.13530208e-02\\n -2.43809540e-02  2.46927980e-02  5.73170837e-04  1.42622162e-02\\n -1.80136561e-02 -6.00690804e-02  4.97411489e-02 -5.05182706e-02\\n -2.39745378e-02  2.08655037e-02 -1.92162059e-02  6.25568861e-03\\n -3.55471112e-02  5.85290566e-02  1.20679857e-02  3.17830108e-02\\n -1.25385902e-03  2.25029830e-02 -3.87524962e-02 -5.08885421e-02\\n  3.16083580e-02 -1.29672354e-02  5.59658557e-02  2.53891367e-02\\n  3.27390283e-02  4.72432524e-02  6.62144423e-02  3.19355689e-02\\n  1.08938257e-03  5.45652211e-02 -3.19861807e-02  4.88984026e-02\\n -1.07569583e-01  1.89494848e-01 -2.91131362e-02  7.14059174e-02\\n  5.76334819e-02  1.73804089e-02  3.70935127e-02  3.17259207e-02\\n  4.01075045e-03  3.75329144e-02 -3.27520333e-02  2.36161929e-02\\n  2.46215705e-02 -7.34362453e-02  1.32254381e-02  6.69095712e-03\\n  3.45322676e-02 -2.16139983e-02 -1.01689026e-02 -3.84649523e-02\\n -1.41975814e-02  1.38704628e-02  3.98182347e-02  5.61979134e-03\\n -1.71721801e-02 -4.37742192e-03  1.91635117e-02  2.82879416e-02\\n  5.31779416e-02 -3.42916586e-02 -1.39195602e-02  2.91889645e-02\\n -2.58192606e-03  4.51326407e-02 -1.29275694e-01  4.06507999e-02\\n  1.72830168e-02  4.01902497e-02 -4.80957478e-02 -2.33178632e-03\\n -1.31842317e-02 -4.19217767e-03  3.64883281e-02  2.62597688e-02\\n  6.66086897e-02 -3.35248793e-03 -7.65986415e-03  3.48380320e-02\\n  3.34732495e-02  1.50510119e-02  1.95927657e-02 -2.07564551e-02\\n  4.93822135e-02  2.89561916e-02  4.46786284e-02 -5.68436552e-03\\n -2.78363768e-02  1.17896600e-02 -6.00862764e-02 -1.07370308e-02\\n  1.71090178e-02  3.99987772e-02 -5.01469076e-02 -6.10468611e-02\\n -4.40740027e-03 -6.57620258e-04  1.84899066e-02  3.10981981e-02\\n  1.59167275e-01  6.81742877e-02  1.68598872e-02  6.66985661e-02\\n  1.93375163e-02  5.98900355e-02 -3.41660604e-02 -1.94457937e-02\\n  2.62704492e-02  6.53835312e-02 -4.64002980e-04 -1.70224741e-01\\n  5.37200831e-04  1.77778492e+01  1.19578540e-02  3.06766406e-02\\n -3.12560238e-03  3.69602516e-02  2.25912314e-02  1.05799744e-02\\n  4.22411785e-02  3.37259434e-02  2.86768824e-02  6.25587329e-02\\n -9.21601709e-03 -7.90549368e-02 -3.10209636e-02  6.18068408e-03\\n  1.63943926e-03  2.70597022e-02 -9.55747347e-03  7.13660643e-02\\n  2.51233410e-02 -8.07026681e-03 -1.39987990e-02 -3.81891131e-02\\n  6.98717386e-02  8.11329857e-02  1.75713617e-02  8.69429186e-02]\",\n          \"[-5.35403437e-04  3.47549058e-02 -1.80311836e-02  3.15960757e-02\\n  1.12645820e-01 -9.32684243e-02 -1.29157156e-02  1.37929961e-01\\n -1.05335610e-02 -2.72319987e-02  3.75525914e-02  1.70062520e-02\\n -7.08225891e-02  6.24168105e-03  4.92981039e-02  2.28318237e-02\\n  9.57202539e-03 -3.84021625e-02  7.24485666e-02  1.91962533e-02\\n -2.34528966e-02  3.49881314e-02  3.61087499e-03  4.92638461e-02\\n  7.98773672e-03 -1.10962223e-02  9.56985168e-03 -5.19072860e-02\\n  4.62728925e-02  5.60163260e-02  2.64346022e-02 -5.43416105e-02\\n -1.46138705e-02  4.76671606e-02 -7.20016845e-03  3.53531241e-02\\n  1.48540307e-02 -5.75864688e-03  2.00972296e-02  3.25547047e-02\\n  5.05043603e-02  4.14467566e-02 -2.25588121e-02  4.18476164e-02\\n  3.39222103e-02  2.23192554e-02  2.47931182e-02  4.34331968e-02\\n  7.43232761e-03 -4.97015901e-02  3.74574065e-02  6.64021522e-02\\n  3.73715237e-02  1.98916987e-01  6.85098618e-02 -4.58811643e-03\\n  2.31266897e-02 -2.73768567e-02  6.40747696e-02  1.26558721e-01\\n  4.04021926e-02 -1.38148982e-02  2.75009815e-02  7.35365823e-02\\n  9.52246189e-02  7.70795159e-03 -3.55820432e-02 -1.14565752e-02\\n -5.16204461e-02  1.06392261e-02  1.11108348e-01  9.12246332e-02\\n -1.03723705e-02 -7.72098154e-02  5.30753881e-02 -2.63855234e-02\\n  5.42849377e-02  3.20609435e-02  3.11119249e-04  2.16550240e-03\\n  1.03882337e-02  8.35697949e-02  2.09288429e-02 -5.59248440e-02\\n  1.17537379e-01  3.52408364e-02 -2.12431122e-02 -6.58288272e-03\\n -8.53145961e-04  9.50349420e-02  3.05249970e-02 -2.14366205e-02\\n  4.38477620e-02  1.68346125e-03  3.75327421e-03 -1.74866691e-02\\n  4.17163298e-02  3.94462161e-02 -1.60541967e-04 -4.35632281e-02\\n -1.77756716e-02 -4.95084450e-02 -4.31211106e-03  1.39968008e-01\\n -9.51721296e-02 -1.15659405e-02  1.42755937e-02  9.02618654e-03\\n  4.43949401e-02  6.54568598e-02  3.41560841e-02 -5.56104630e-03\\n  5.38325869e-02  4.65288386e-02  1.21819414e-02 -4.40445617e-02\\n  2.87346728e-02 -1.95307087e-03  3.61054800e-02  3.31862494e-02\\n  2.89732590e-02  3.10586989e-02 -3.95250358e-02  1.85415410e-02\\n -1.63344741e-02 -1.03225149e-02 -2.36587748e-02 -3.70713621e-02\\n  5.14802411e-02  6.22785985e-02  3.00030559e-02  3.27230170e-02\\n  2.77871843e-02 -2.97450665e-02 -1.59179457e-02  6.59460574e-02\\n  1.31104300e-02  5.59322350e-02  1.13333128e-02  5.79080246e-02\\n  7.06007844e-03 -8.87461845e-03 -2.02167612e-02  1.78700611e-02\\n -4.72517801e-04 -5.29935598e-01  1.97565090e-02  8.47488567e-02\\n -2.72396859e-02  5.19065633e-02  5.11021633e-03 -1.18901163e-01\\n -1.07058287e+00  2.57522427e-02 -3.62289734e-02  5.80404401e-02\\n  2.24126666e-03  3.16596776e-02 -7.26126507e-03  4.13888209e-02\\n  6.85196742e-02  4.08223569e-02 -1.51046235e-02  3.86821479e-02\\n -7.62183443e-02 -3.39503996e-02  2.23587230e-02  1.97075773e-02\\n -1.23250410e-02 -2.10580714e-02 -2.21370123e-02 -2.66954284e-02\\n  8.27205405e-02  1.46656903e-02 -7.16698123e-04  4.35430231e-03\\n  8.03672150e-03 -2.52107065e-03  1.98194552e-02  4.68272157e-03\\n -2.21089683e-02 -7.44881481e-03  8.83542150e-02  5.06837256e-02\\n -1.94015682e-01 -8.66306294e-03  2.01727599e-02  8.19475763e-03\\n  3.66629437e-02 -5.32794520e-02  2.02396652e-03  3.02232057e-02\\n  8.18951130e-02  5.04795723e-02 -3.12246643e-02  9.95416287e-03\\n -1.24807898e-02  7.51853883e-02 -6.55192835e-03 -2.13549715e-02\\n  2.64254026e-02 -2.68670395e-02  2.01052912e-02  7.96683971e-03\\n -7.28948265e-02 -2.65027098e-02 -1.83888730e-02  3.71409580e-02\\n -1.63844414e-02 -1.05356155e-02  1.80197358e-02  2.34196754e-03\\n  3.51120718e-02  2.88832700e-03 -2.72423420e-02  1.10260323e-02\\n  1.59895904e-02  3.86901721e-02  6.74628168e-02  1.82767995e-02\\n -6.83660526e-03 -1.05834352e-02  3.29710022e-02  3.64360288e-02\\n  7.94188026e-03  5.50744776e-03  4.76242714e-02  4.89136623e-03\\n  4.50361148e-02 -5.88705093e-02  1.79137141e-02  2.86543686e-02\\n  2.39158049e-02 -2.39428133e-02 -4.21401858e-03 -1.96764544e-02\\n -2.11084299e-02 -2.51110122e-02  4.32752520e-02 -3.48655045e-01\\n -1.01487152e-02 -1.35154119e-02  2.77390983e-02  8.24941322e-03\\n  5.06648421e-02  2.49740649e-02 -4.62482944e-02  3.49487588e-02\\n  3.62271518e-02  3.82588990e-02  1.09270200e-01 -1.58369821e-02\\n -2.35250872e-03  4.22325507e-02 -2.34303577e-03  5.14646582e-02\\n -5.28977141e-02  6.26666937e-03 -9.40714180e-02  6.28293872e-01\\n  3.30941230e-02  2.97023971e-02  4.91056219e-02 -5.66426292e-03\\n  8.10780562e-03  7.26868063e-02  3.76272440e-01  1.21014737e-01\\n -1.05160758e-01  3.74957826e-03  5.91281289e-03  4.66574766e-02\\n -1.24773011e-03  5.60426600e-02  2.67222002e-02 -3.06908265e-02\\n  7.97657669e-03  2.14917623e-02 -2.39024609e-02  1.31161772e-02\\n  5.56829795e-02  1.44604340e-01  2.03636177e-02  4.26756740e-02\\n  5.23880403e-03  7.25504160e-02  1.14118503e-02 -6.98877219e-03\\n  5.76861650e-02  7.21448064e-02 -1.29906256e-02 -1.67573560e-02\\n  7.55893579e-03  8.50343108e-02  1.31703898e-01  3.54605988e-02\\n -1.94769427e-02  9.02418196e-02 -9.00976360e-03  1.71969086e-03\\n  3.29011213e-03 -1.21374980e-01 -1.51128508e-02 -4.77130117e-04\\n -6.07221620e-03  9.05133635e-02  2.56935120e-01  1.42230722e-03\\n -2.18003942e-03  1.13021120e-01  1.43161993e-02  2.36742292e-03\\n -8.67509171e-02  1.49684690e-03 -5.47284074e-02 -1.07260291e-02\\n  4.98563275e-02 -2.97100693e-02  5.09029850e-02  5.99671677e-02\\n -4.79407329e-03 -2.58081928e-02  1.00850989e-03  7.32691288e-02\\n -3.12570040e-03 -1.72457360e-02 -4.03409038e-04  5.18490188e-03\\n  6.23249449e-02  4.16351184e-02 -8.56462680e-03 -2.25801989e-02\\n -2.87372023e-02  1.72799788e-02 -4.70990986e-02  1.63761489e-02\\n  1.87168103e-02  5.49463965e-02 -6.27990067e-02  7.24114925e-02\\n  4.41634804e-02  2.69142687e-02  1.80900022e-02  2.05490319e-03\\n  3.12868133e-02  2.88406778e-02  4.23100032e-03  2.43749116e-02\\n  2.38198135e-03  5.28363548e-02  6.97483122e-02 -5.47632016e-02\\n  4.18908559e-02  2.37473138e-02  9.98288766e-03 -2.32312037e-03\\n -1.03889238e-02  6.44874051e-02  2.96720248e-02 -4.55179662e-02\\n -9.82317328e-03  4.33071777e-02  2.08339281e-02  7.83222094e-02\\n -9.83080710e-04 -8.23421497e-03 -1.24681927e-02 -9.76974517e-03\\n  5.61369397e-03  1.40712187e-02 -3.14247683e-02 -5.71081089e-03\\n -1.03779277e-02  1.94829926e-02  8.98805913e-04  2.56343782e-02\\n  8.17067623e-02 -1.59789383e-01 -2.28610337e-02 -4.36163843e-02\\n  2.92825606e-02  4.79733609e-02  2.98538506e-02  3.93259823e-02\\n  1.23966336e-02  2.97481362e-02  1.06140953e-02 -1.26474584e-02\\n  2.29954137e-03 -1.05705624e-02  6.94627315e-03 -8.22535008e-02\\n  9.25173052e-03  2.28113905e-02  3.30775902e-02  1.76825430e-02\\n  3.69482413e-02 -2.85035409e-02  4.21256423e-02 -6.45405520e-03\\n  4.77137342e-02  1.92409884e-02 -7.98478425e-02 -1.00055952e-02\\n -4.02051443e-03  1.84811056e-02  4.04086187e-02  1.79190263e-02\\n  2.16272287e-02  2.60865074e-02  6.45671561e-02 -2.00106446e-02\\n  1.99956726e-03 -1.62081756e-02  6.14662841e-02  5.88867534e-03\\n  5.79722002e-02  1.51427342e-02  5.14369458e-02  4.05662656e-02\\n  2.45936029e-02  3.91590074e-02 -3.13631035e-02 -1.46289496e-02\\n  3.05526983e-02 -1.07943259e-01 -4.38483171e-02  1.92160271e-02\\n -9.91094857e-05  1.06752999e-02  2.17759162e-02  2.10965201e-02\\n  6.24303892e-02 -2.40442343e-02 -3.11964620e-02  3.85453179e-03\\n  2.81243473e-02  2.88685448e-02 -5.90667576e-02  1.04908701e-02\\n  3.07763014e-02  4.62764278e-02 -1.56936441e-02  5.30768707e-02\\n  2.82412544e-02  2.63803601e-02 -5.59713785e-03  9.49210953e-03\\n -6.35750890e-02 -3.82128824e-03 -8.06453987e-04  2.07070746e-02\\n  7.60782659e-02 -9.63486452e-03  2.74755601e-02 -1.37721803e-02\\n -2.13726237e-02  2.97349077e-02  8.04183185e-02 -1.62674618e+00\\n  3.62168401e-02  3.11171226e-02  5.88582978e-02  4.33642194e-02\\n -1.79771166e-02  4.80949208e-02  3.48453857e-02  9.35307145e-02\\n -2.11683847e-02 -3.02930512e-02  3.29142585e-02 -4.40148311e-03\\n  2.46433988e-02  5.63144684e-02  9.32360217e-02 -1.48468819e-02\\n  9.09297541e-03  6.39230311e-02  4.15899865e-02 -4.93331030e-02\\n  4.10740972e-02  1.51255634e-02  1.07968943e-02  9.18682106e-03\\n -5.77479973e-03  4.40888181e-02  3.02161812e-03  9.56360698e-02\\n  5.58469631e-02 -5.27183786e-02  7.59448409e-02 -5.70153929e-02\\n  1.50435581e-03  3.12638655e-02 -7.40543520e-03  3.13590989e-02\\n -6.14189692e-02 -1.15944438e-01  3.18137854e-02 -2.61678151e-03\\n -1.87914483e-02  1.79462954e-02  4.32350188e-02  2.32433900e-02\\n  3.98200974e-02  5.42707443e-02 -1.86507665e-02  7.55695105e-02\\n  4.51710522e-02 -8.96807935e-04  3.35022986e-01  2.41559371e-02\\n  7.85830838e-04 -6.03813045e-02  8.68941545e-02  9.07514393e-02\\n  9.20793333e-04  3.09374891e-02  3.42693999e-02 -5.14695828e-04\\n  5.76584891e-04  1.75493397e-02  3.54973674e-02  6.76049888e-02\\n -3.94247705e-04 -2.43344903e-02  3.02380547e-02 -2.28131153e-02\\n  2.07713135e-02 -8.11166912e-02  5.22832945e-02  5.43836616e-02\\n  7.72414654e-02 -3.26912791e-01 -2.63939649e-02 -9.97160561e-03\\n -1.89468788e-03  2.69330870e-02 -1.19001325e-02  1.32825645e-02\\n  5.22982851e-02  2.87831388e-02  1.34190936e-02  3.59007204e-03\\n  3.15409228e-02  3.44149321e-02 -4.33770102e-03  1.38424558e-03\\n  2.79099215e-02  7.06261545e-02  1.07070310e-02 -8.98755528e-03\\n -2.99171489e-02 -1.90088283e-02  1.69939045e-02  7.36019202e-03\\n -1.59812886e-02  6.00131825e-02  6.57884181e-02 -4.72846106e-02\\n  4.77887541e-02  6.16808049e-03  1.59659777e-02 -1.49449920e-02\\n  3.62064480e-03 -1.44926207e-02  1.06625259e-02  5.36493137e-02\\n  6.71187695e-03 -2.04664487e-02  1.00264363e-02  3.18009928e-02\\n  3.84085439e-03 -4.45068628e-02  3.13649289e-02 -7.23695150e-03\\n  1.22410432e-02  8.76406021e-03 -5.89180784e-03 -1.26348466e-01\\n -5.82992937e-03  2.52042674e-02  2.05817726e-03  6.60153665e-03\\n  5.10483198e-02  1.61290192e-03  6.16018325e-02  7.96896368e-02\\n -6.25338507e+00  2.24601999e-02  1.34794256e-02 -6.62762392e-03\\n -1.57655422e-02  4.29181289e-03 -1.04341889e-03  8.11560731e-03\\n -2.98776049e-02  3.47263180e-03 -1.15973670e-02 -3.34123857e-02\\n  1.41411508e-02  2.18579452e-02  1.09383734e-02  4.21990752e-02\\n -1.03448576e-03 -2.99469866e-02  5.85004594e-03  4.13574390e-02\\n  4.09185141e-03  6.93164989e-02  8.15075189e-02  6.16426207e-02\\n  3.84232141e-02 -1.80032104e-02  3.88043486e-02 -1.53995976e-02\\n  1.54100740e-02  3.82174700e-02 -1.13990717e-02  1.27059128e-02\\n -1.95308006e-03 -3.46448161e-02 -2.29923762e-02  4.50030640e-02\\n -4.53794226e-02 -7.23076705e-03  3.39048803e-02  1.53308762e-02\\n -1.10156834e-02 -6.47895224e-03  1.21200886e-02  2.09190156e-02\\n -4.47697705e-04 -5.13239503e-02  6.20433092e-02 -2.47372724e-02\\n -2.94770561e-02  1.22981519e-03 -3.07948627e-02  9.36498120e-03\\n -2.74271965e-02  2.55023390e-02 -2.84295063e-04  3.12817767e-02\\n -5.03724813e-03  9.73081402e-03 -3.30972411e-02 -8.68785009e-02\\n  4.36045080e-02  5.99764921e-02  1.37875546e-02  2.24691294e-02\\n  1.60931740e-02 -2.21394701e-03  8.99806693e-02  4.73830923e-02\\n  8.42369255e-03  4.41106632e-02  1.37147726e-02  3.65645513e-02\\n -8.77711475e-02  1.87920660e-01 -8.95276107e-03  9.13105160e-02\\n  3.54640298e-02  1.35201812e-02  4.10043448e-02  6.76967576e-02\\n -8.80347285e-03  4.62475382e-02 -1.59114785e-02  1.85002256e-02\\n  2.45679729e-02 -7.39061385e-02  4.04695831e-02 -2.27692090e-02\\n  5.04102893e-02  2.21864581e-02  3.26582082e-02 -6.13022186e-02\\n -4.19887863e-02  1.24648158e-02  6.71631917e-02 -3.95405516e-02\\n -6.89861625e-02  5.19022020e-03  3.29588316e-02  3.01138107e-02\\n  1.20907567e-01 -3.31213921e-02 -1.29465498e-02  6.05994128e-02\\n  5.40764863e-03  4.90032025e-02 -1.53140038e-01  6.10899515e-02\\n  2.44084932e-02  3.49421725e-02  1.17079047e-02 -7.15637254e-03\\n  6.04734197e-03 -1.80443807e-04  2.39255242e-02  1.35590844e-02\\n  9.79932547e-02 -3.91382203e-02  1.07612181e-02  2.75858082e-02\\n  1.44456578e-02  3.22250910e-02  1.06116859e-02 -1.82377007e-02\\n  8.98506790e-02  2.57329177e-02  3.19515206e-02 -5.36163822e-02\\n -5.15450276e-02  1.16629899e-02 -7.60353208e-02 -1.32038593e-02\\n  4.72938605e-02  5.36334552e-02 -6.22561052e-02 -2.44580358e-02\\n -1.46798175e-02 -2.77853827e-03  3.84471342e-02  1.03333499e-02\\n  1.33795008e-01  6.99952543e-02  3.69583555e-02  4.93423343e-02\\n  2.83505535e-03  5.01885526e-02 -2.27112640e-02 -4.10741791e-02\\n  7.12852627e-02  7.07632899e-02 -2.18832307e-03 -7.63418823e-02\\n  2.05796622e-02  1.77905502e+01  1.16128847e-02  2.04386245e-02\\n -2.42578462e-02  2.34907344e-02  6.88486360e-03 -1.55191645e-02\\n  5.31095043e-02  2.59526800e-02  4.09125946e-02  2.90408544e-02\\n -1.08523704e-02 -1.13106340e-01 -3.18631977e-02  1.50905992e-03\\n  5.28633893e-02  1.45142693e-02 -4.39746976e-02  6.29462749e-02\\n  2.73520611e-02  4.60899919e-02 -1.93198409e-03 -4.11830507e-02\\n  9.21429768e-02  1.01238810e-01  4.29603457e-02  9.45691764e-02]\",\n          \"[-1.55352280e-02  3.24675217e-02 -1.80989541e-02  2.53027212e-02\\n  1.34104520e-01 -4.77434397e-02 -2.68317796e-02  1.05513081e-01\\n -5.91805624e-03 -3.22675183e-02  5.64424172e-02  5.30261034e-03\\n -2.38104202e-02 -1.18364263e-02  3.96488234e-02  6.96924864e-04\\n  1.95684731e-02 -5.40070683e-02  8.88028443e-02  1.44400317e-02\\n -2.08757296e-02  1.60826668e-02 -3.27156484e-03  5.39916791e-02\\n  3.54956090e-02  6.52823644e-03  2.73977611e-02 -4.08549681e-02\\n  2.23964043e-02  7.01237321e-02  2.62554456e-02 -1.03353858e-02\\n -1.37825892e-03  5.71364574e-02  4.21685603e-04  2.00321861e-02\\n -9.35705937e-03  5.82036749e-03  3.85657288e-02  3.84493470e-02\\n  4.36821878e-02  4.34937440e-02 -3.67049798e-02  3.87689956e-02\\n  1.99005194e-02  1.41278412e-02  2.77965590e-02  2.66817305e-02\\n -6.81110541e-04 -5.23256138e-02  2.96845101e-02  9.47636813e-02\\n  6.06206758e-03  2.22802013e-01  2.97933556e-02 -1.44168474e-02\\n  4.79433611e-02  3.11538391e-03  2.27517299e-02  9.89659876e-02\\n  4.56470884e-02 -1.61210336e-02  4.95719723e-03  9.65249166e-02\\n  1.00340374e-01 -7.38710538e-03 -1.69939436e-02 -2.36928463e-02\\n -1.70438699e-02  1.51995718e-02  9.84053165e-02  7.29711354e-02\\n  5.38123958e-02 -7.17283338e-02  2.59713922e-02 -7.93351792e-03\\n  5.16909063e-02  8.99457932e-03 -4.45324704e-02  2.31698118e-02\\n  7.83293624e-04  1.05865851e-01  1.99736226e-02 -3.87001447e-02\\n  1.13209203e-01  3.76107618e-02 -2.06482643e-03 -2.49794833e-02\\n -3.58264893e-04  9.66953784e-02  1.03661641e-02 -3.43289748e-02\\n -1.07660312e-02  8.26234370e-03  4.45140339e-03 -1.37935271e-02\\n  2.15989854e-02  5.00171185e-02  1.90895516e-02 -3.31658348e-02\\n -1.84977185e-02 -5.91187663e-02  9.26224887e-03  1.68511987e-01\\n -1.07002556e-01 -2.75802035e-02  2.04429030e-02  3.11044194e-02\\n  5.58618270e-02  8.69991556e-02  4.58589345e-02  1.59764830e-02\\n  7.66359121e-02  1.97110996e-02  4.84458730e-03 -4.16317694e-02\\n  4.77882996e-02 -2.70607695e-02  3.09696179e-02  1.63307544e-02\\n  2.45940667e-02 -6.11686427e-03 -2.70078257e-02  7.20239943e-03\\n -8.71151499e-03 -2.05435324e-03 -3.03484127e-02 -6.17586263e-03\\n  5.08356057e-02  3.91969718e-02  6.06921241e-02  1.44313639e-02\\n  2.22571287e-02 -2.37190761e-02 -1.73455626e-02  6.66504055e-02\\n  2.00216249e-02  5.20151444e-02  4.10075523e-02  5.68008982e-02\\n -6.26694690e-03  5.08572906e-02 -2.97909752e-02  1.57042090e-02\\n -2.58907350e-03 -5.57582021e-01  3.43706757e-02  5.01976907e-02\\n -4.09339890e-02  4.59860526e-02  3.20665985e-02 -8.05859417e-02\\n -1.09589660e+00  7.63113657e-03  1.36742201e-02  4.32722867e-02\\n  1.52311940e-02  4.47550789e-03  4.45638821e-02  5.20759895e-02\\n  7.52001926e-02  5.19288853e-02 -7.89238699e-03  3.93662266e-02\\n -5.72436526e-02 -7.01972246e-02  5.06271869e-02  1.89200137e-02\\n -2.01507974e-02 -2.49104425e-02  1.00188479e-02  6.50642812e-03\\n  1.06845230e-01  1.99984405e-02  2.08710339e-02 -1.32903317e-02\\n  1.19353728e-02 -3.83444242e-02  1.24703934e-02 -2.04362758e-02\\n  4.59525548e-03 -3.99507098e-02  7.01865256e-02  6.11203425e-02\\n -1.87548339e-01 -9.26376041e-03  2.80413665e-02 -5.72896842e-03\\n  1.87034700e-02 -3.59065197e-02 -2.58375965e-02  5.10022454e-02\\n  1.02040619e-01  4.68837693e-02 -4.07635681e-02 -1.25875128e-02\\n -2.67749093e-03  5.98798357e-02  1.81967835e-03 -4.79527889e-03\\n  3.73836905e-02 -1.37286149e-02  8.39712098e-03  8.21910705e-03\\n -4.72845659e-02 -4.16973345e-02  2.18943767e-02  1.28095653e-02\\n -2.81804167e-02  2.18245797e-02  3.66336033e-02 -8.40490498e-03\\n  5.56385443e-02  1.14243869e-02 -2.01812014e-02  3.05212587e-02\\n  8.28976929e-03  1.70360841e-02  5.47118075e-02 -2.24133898e-02\\n -1.78920496e-02 -3.61106992e-02 -1.31255249e-02  2.62305513e-02\\n  2.96983477e-02  1.62728690e-02 -7.36816740e-03 -1.14167258e-02\\n  4.18867767e-02 -3.96766514e-02  1.93445012e-02  2.86924355e-02\\n  4.39752713e-02 -1.07999251e-03 -2.76770834e-02  4.29168763e-03\\n -1.21646924e-02 -1.20978989e-02  7.21709058e-02 -2.97762483e-01\\n  1.16101466e-02 -4.44836691e-02  2.51205042e-02  2.85231788e-02\\n  1.00691855e-01  5.85855031e-03 -1.76035129e-02  1.56680159e-02\\n  4.13489416e-02  2.28394046e-02  8.61571729e-02 -2.36155409e-02\\n -9.41233244e-03  3.14205922e-02 -3.59122641e-03 -3.93077172e-02\\n -3.13030779e-02 -1.78844039e-03 -8.65073502e-02  4.84435260e-01\\n  1.61610618e-02  3.14514674e-02  6.17411956e-02  1.46997999e-02\\n  6.36650901e-03  5.06222397e-02  2.93943226e-01  1.24939732e-01\\n -9.20723826e-02  1.14109949e-04  1.62264556e-02  3.96966934e-02\\n  2.32021511e-02  4.72553298e-02  3.10449786e-02 -2.91799698e-02\\n  1.77278705e-02 -9.52784345e-03  2.72933906e-03  3.22958380e-02\\n  6.37723655e-02  1.41311139e-01 -9.16424580e-03  5.59697077e-02\\n -1.12687505e-03  3.78539227e-02  2.52792016e-02  1.42808789e-02\\n  5.58078066e-02  3.28072496e-02 -8.65860283e-03 -2.32028794e-02\\n  9.52867093e-04  2.38020904e-02  1.05890796e-01  2.58910395e-02\\n  1.42008346e-02  5.29894158e-02  3.47388163e-02  1.11108450e-02\\n -6.50633313e-03 -1.48345441e-01  8.79210420e-04 -1.64766684e-02\\n -1.61866862e-02  1.10435143e-01  2.49674171e-01 -2.47432254e-02\\n -4.72498871e-02  1.05635509e-01 -1.40846120e-02  4.30241041e-03\\n -5.35965078e-02  1.99859068e-02 -8.38773847e-02 -4.73999791e-03\\n  3.70845832e-02 -2.47786194e-02  4.01392505e-02  7.92179853e-02\\n  6.05847174e-03 -3.57049629e-02  2.39361003e-02  9.94673520e-02\\n -2.26382464e-02 -1.80651024e-02 -1.36042815e-02  4.20879126e-02\\n  2.43046433e-02  5.03768176e-02 -1.19773392e-02  2.10871156e-02\\n -3.14855725e-02  4.16981019e-02 -1.10387981e-01  9.97544080e-03\\n  4.67653796e-02  4.22931239e-02 -9.22620818e-02  1.51885211e-01\\n  3.77122648e-02  2.67335363e-02  1.54872164e-02  1.72249991e-02\\n  4.43792082e-02  3.76741076e-03 -3.23471893e-03  3.03683570e-03\\n  1.55849755e-03  3.67390625e-02  5.89924008e-02 -2.27237009e-02\\n  5.02057672e-02  8.59062225e-02  2.65828543e-03  2.70045139e-02\\n -8.89795274e-03  4.55553923e-03 -5.46389027e-04 -5.82771301e-02\\n -1.49955535e-02  3.52869369e-03 -7.91687146e-03  8.11917633e-02\\n  3.42013128e-03 -4.42101657e-02  1.39004327e-02 -5.24009094e-02\\n  7.03072129e-03  4.33061458e-02 -3.31855286e-03 -1.30465603e-03\\n  1.34083163e-02 -1.89675596e-02 -2.26783361e-02  2.91756466e-02\\n  1.00241691e-01 -1.44322753e-01 -5.48977964e-03 -1.66037232e-02\\n  5.95060885e-02  5.75173870e-02  1.83465891e-02  3.42587866e-02\\n  4.10472155e-02  1.66697567e-03  1.26853576e-02  1.07094562e-02\\n  3.29840370e-03 -2.27659009e-02  2.35417951e-03 -1.21624112e-01\\n  1.24867922e-02  9.27084684e-03  4.61429060e-02  9.19664279e-03\\n  6.01552054e-02 -3.41428667e-02  3.32514867e-02  4.60056737e-02\\n  6.13214746e-02  5.41066425e-03 -5.28488234e-02  4.41452302e-03\\n -2.85684457e-03  6.62533939e-02  9.29386467e-02  2.57699694e-02\\n  1.60105098e-02  3.11712902e-02  1.15442336e-01 -8.21632985e-03\\n -9.66417883e-03 -6.13733754e-02  7.94024691e-02  6.57803379e-03\\n  7.33779967e-02  1.67142451e-02  1.82035156e-02  8.50419402e-02\\n  2.05510389e-02  2.78676860e-02 -1.60711762e-02 -1.46302776e-02\\n -2.47870688e-03 -5.10105789e-02 -5.47694154e-02  6.78431708e-03\\n -9.41437110e-03 -1.68014865e-03  3.15709710e-02  2.24185139e-02\\n  3.51797491e-02 -3.08730663e-03 -1.61735490e-02  3.84088308e-02\\n  9.17175226e-03  3.32533233e-02 -5.37604392e-02  5.51101053e-03\\n  2.01369431e-02  3.02060619e-02 -2.15924233e-02  6.09261915e-02\\n  4.09246609e-02  4.98605482e-02  1.33771710e-02  2.27146391e-02\\n -5.89828342e-02  8.83565098e-03 -5.15778689e-03  8.73137079e-03\\n  6.96602389e-02 -2.63983384e-03  9.64068994e-03  1.73714533e-02\\n -4.47953865e-02  3.89134064e-02  6.72926307e-02 -1.85475898e+00\\n  6.36495929e-03  7.74882361e-03  5.00540957e-02  8.57726708e-02\\n  1.57892313e-02  3.93656045e-02  2.09394954e-02  1.08224623e-01\\n  2.32014619e-02 -4.29266430e-02  5.77159226e-03  2.41674036e-02\\n  3.63467224e-02  2.15264056e-02  4.88468967e-02  4.89885407e-03\\n  1.03047788e-02  1.10723689e-01  4.11027893e-02 -6.41188323e-02\\n  8.36221352e-02  1.68979466e-02  3.14156222e-03 -7.20090559e-03\\n -2.74398047e-02  5.51982820e-02  6.11922666e-02  1.28688604e-01\\n  6.21474534e-02 -5.00651710e-02  4.23530377e-02 -3.87939513e-02\\n  1.42729478e-02  5.08146621e-02 -4.33900952e-02  4.12495956e-02\\n -6.47435933e-02 -1.53146222e-01  4.90975194e-02 -5.18502900e-03\\n -3.16390321e-02  6.15687389e-03  4.53235134e-02  9.17341374e-03\\n  1.26140416e-02  1.67970918e-02 -8.07210617e-03  7.68253058e-02\\n  4.19373251e-02 -6.97470084e-03  3.08891177e-01 -1.55772287e-02\\n  4.62481715e-02 -5.08256480e-02  7.85626993e-02  9.07117352e-02\\n  1.97983030e-02  3.47947665e-02  3.49159986e-02  1.01600122e-03\\n  2.42701564e-02  3.15978490e-02  6.38671666e-02  5.39748631e-02\\n -6.22177683e-03 -9.82088596e-03  2.41813026e-02 -2.16573440e-02\\n -6.09339681e-03 -8.42930228e-02  1.85899772e-02  6.17070645e-02\\n  5.24273813e-02 -3.19730461e-01 -2.04062704e-02 -5.23071038e-04\\n -7.59858591e-03  2.61597801e-02 -1.14316065e-02  3.52994073e-03\\n  5.83265796e-02  3.08682211e-02  1.40801799e-02  4.73682210e-03\\n  5.61879948e-03  5.47136255e-02 -2.78382748e-02 -2.40466017e-02\\n  2.59246118e-02  3.30614820e-02 -3.40225152e-03 -2.25792229e-02\\n -3.17859091e-02  2.94770766e-02 -1.26090515e-02  6.76750857e-03\\n -1.32009108e-02  5.17098010e-02  3.46379057e-02 -2.83877105e-02\\n  6.48948997e-02  3.24332900e-03  2.17910931e-02  4.71389219e-02\\n -1.79973114e-02  1.86438709e-02  1.66231170e-02  5.83064631e-02\\n -1.91072226e-02 -3.39854285e-02  3.70705780e-03  4.13854271e-02\\n  1.03722513e-02 -6.97653890e-02  3.99979129e-02  3.72377108e-05\\n  1.27755487e-02 -1.41751925e-02  2.77734478e-03 -1.79238498e-01\\n -3.90688889e-02  3.31384614e-02  7.44372327e-03  1.78503729e-02\\n  6.06165566e-02 -2.36166455e-02  4.26757000e-02  1.09954998e-01\\n -6.18658781e+00  2.38447580e-02  1.65719446e-02 -2.19420865e-02\\n  1.05632767e-02  2.68432102e-03  7.20114866e-03  2.04983279e-02\\n -2.24561002e-02 -1.16788726e-02 -6.25796570e-03 -3.62463966e-02\\n  4.08944190e-02  4.37608659e-02 -1.49375177e-04  2.99910549e-02\\n -1.06193610e-02  1.10394135e-02  2.88079605e-02  3.42397317e-02\\n -2.37402171e-02  4.83914427e-02  7.55573586e-02  6.51400909e-02\\n  3.08936816e-02 -3.94897461e-02  3.90308723e-02 -6.79995790e-02\\n  2.21290067e-02  5.90237789e-02 -2.48579755e-02 -3.32739651e-02\\n -6.51367521e-03 -1.68660767e-02 -3.40091716e-03  2.41611917e-02\\n -6.08032271e-02 -2.33597383e-02  3.04556359e-02  1.66300554e-02\\n  1.80611536e-02  2.56669670e-02  3.41989473e-02  1.24178212e-02\\n  2.08600275e-02 -3.04938443e-02  9.04181153e-02 -3.52845970e-03\\n -2.05761082e-02  4.85339435e-03 -2.95306668e-02  6.33370306e-04\\n -3.50519978e-02  3.94733399e-02  1.63988471e-02  2.38003675e-02\\n  1.40034361e-02  3.00411489e-02 -1.94660760e-02 -3.33716199e-02\\n  2.86202654e-02  5.05605452e-02  3.52037996e-02  1.49361081e-02\\n  2.63891816e-02  1.78107172e-02  6.52628690e-02  2.59727109e-02\\n  2.30811685e-02  5.28264716e-02 -2.46056784e-02  4.11429852e-02\\n -1.32095903e-01  1.56949356e-01  1.75669556e-04  7.19762295e-02\\n  2.83741932e-02  2.30989978e-02  7.06742927e-02  2.69477144e-02\\n  1.06206711e-03  2.41232887e-02 -7.20733125e-03  1.51729472e-02\\n  8.93617608e-03 -6.89828694e-02  3.76258120e-02  2.99646216e-03\\n  2.82660779e-02  9.71854664e-03  3.36286314e-02 -6.40631169e-02\\n -6.30829670e-03  3.29237841e-02  3.56793664e-02 -6.25305343e-03\\n -2.30798200e-02 -1.93026979e-02  7.09942803e-02  2.29352303e-02\\n  1.40369773e-01 -2.56873425e-02 -1.27088632e-02  6.40121922e-02\\n  6.73445174e-04  9.30116326e-02 -1.89853013e-01  2.09866930e-02\\n  3.45119163e-02  5.90800717e-02 -2.29942948e-02  2.10526697e-02\\n -1.98839009e-02  2.94253975e-03  4.20059599e-02  1.20415248e-03\\n  9.16356891e-02 -8.70422460e-03  2.47757547e-02  1.32114962e-02\\n  3.09696998e-02  1.32028339e-02 -1.32943522e-02 -9.08268057e-03\\n  1.11862272e-01  2.41138656e-02  4.67833467e-02 -6.13659434e-02\\n -1.31619722e-02  2.22884528e-02 -2.90211122e-02 -1.21086510e-02\\n  1.01419903e-01  5.34135178e-02 -5.55616580e-02 -8.10351074e-02\\n -3.38617270e-03  5.40651008e-03  3.41174752e-02  3.32907364e-02\\n  1.12173557e-01  8.66269618e-02  4.07205597e-02  2.35670712e-02\\n -5.10694343e-04  3.60328183e-02 -3.34740132e-02 -5.03874272e-02\\n  5.88530675e-02  4.93209325e-02 -1.54167507e-03 -1.43157810e-01\\n  3.14329611e-03  1.78003597e+01  1.72477476e-02  3.16834636e-02\\n -4.86559719e-02  4.37821411e-02  7.81458057e-03 -1.16978455e-02\\n  6.60722032e-02  5.71882278e-02  1.91286765e-02  3.40521410e-02\\n -5.04684076e-03 -8.50251615e-02 -2.68580727e-02 -2.57326066e-02\\n  2.15040147e-02  1.11039877e-02 -3.29259820e-02  8.32312927e-02\\n  1.14312563e-02  2.06908188e-03  1.38265124e-04 -2.27733478e-02\\n  5.93040287e-02  9.77839679e-02  3.50420550e-02  1.56161949e-01]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"actants_embedding\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 395,\n        \"samples\": [\n          \"[-3.00715454e-02  2.02393215e-02  1.40158256e-04 -7.80816749e-03\\n  1.36442199e-01 -8.47218782e-02  6.48144633e-03  2.61247326e-02\\n  7.88368843e-03 -8.11852887e-02  1.35935590e-01 -2.67638937e-02\\n  4.03070562e-02  6.41217083e-02 -4.50981874e-03 -1.34036094e-02\\n  5.05701592e-03 -4.09049429e-02  7.89024159e-02  4.76531126e-02\\n  4.47514933e-03  3.88896801e-02  6.36649281e-02  1.50052952e-02\\n -5.27606532e-03 -8.07766244e-03  6.50766306e-03 -2.49541719e-02\\n -8.41281097e-03  4.32387963e-02  2.30474584e-03 -1.04879197e-02\\n  1.17866357e-03  9.51178297e-02  7.92039558e-03  4.71393242e-02\\n  1.99289108e-03 -3.64612266e-02  7.60081410e-02  7.19275177e-02\\n  4.63963374e-02  3.29168700e-02  1.80445313e-02  7.00908527e-02\\n  2.66386550e-02  2.92471633e-03  1.97915845e-02  2.04640981e-02\\n  4.66820858e-02 -6.76310062e-02  3.00082806e-02  1.84028409e-03\\n  4.33912575e-02  1.96234226e-01  4.75009158e-02 -3.57989520e-02\\n  5.11354953e-02 -5.75210601e-02 -6.84987695e-04  1.60159722e-01\\n  4.69768196e-02  1.96498353e-02 -2.41725519e-03 -3.42343003e-02\\n  5.79827204e-02  1.31445490e-02 -2.61896495e-02  1.41246663e-02\\n -4.53468934e-02  1.39744170e-02  3.06719095e-02  2.66944095e-02\\n  5.12398243e-01 -4.06519882e-02 -1.65081061e-02  1.98832154e-02\\n  3.91737372e-02  5.96085340e-02  1.48897832e-02 -5.01531595e-03\\n  1.16598513e-02  4.30304110e-02  3.81820016e-02 -9.00072828e-02\\n  1.68117687e-01  1.23129606e-01 -3.98860537e-02  1.47398235e-02\\n  1.99091416e-02  1.08101860e-01  3.96601595e-02  1.25566749e-02\\n  5.13162389e-02 -8.10738504e-02 -2.67037861e-02 -1.94129217e-02\\n  2.31876131e-02  3.43040042e-02 -2.66362960e-03  4.04130183e-02\\n  7.17805000e-04 -1.02924921e-01 -1.84797589e-02  5.48632517e-02\\n -9.87866446e-02 -1.73123721e-02 -4.24277000e-02  3.13637890e-02\\n  1.02690130e-01  7.85608515e-02  4.32440564e-02  3.71370837e-02\\n  3.40972394e-02  2.09889878e-02  7.74872974e-02 -4.46930379e-02\\n  3.33810300e-02 -5.57482392e-02  1.17986714e-02  5.73007762e-02\\n  3.24264653e-02  3.89457308e-02 -5.15254773e-02  4.15831059e-02\\n -3.44667560e-03  3.70069705e-02 -2.31845807e-02 -2.92128045e-03\\n  2.26403903e-02 -1.72746275e-02  3.81066576e-02 -2.47591175e-02\\n  3.09846886e-02  1.53491674e-02 -2.29789759e-03  1.97635088e-02\\n -3.42601053e-02  3.36641707e-02  2.88685206e-02  2.29630210e-02\\n  8.73505976e-03 -3.01135313e-02 -3.40815075e-02  2.20368486e-02\\n  1.85393430e-02  1.38842687e-01 -3.83455143e-03  3.06256544e-02\\n -7.50712119e-03  4.43420894e-02  2.08900888e-02  1.71833858e-01\\n -1.67290890e+00  4.96372469e-02 -3.12372507e-03  7.53777996e-02\\n -2.59390771e-02  2.24685343e-03  3.56398709e-02  2.48664077e-02\\n  6.93629608e-02  5.09867482e-02 -5.92194684e-03  4.03334610e-02\\n -1.21824141e-03 -1.40480390e-02  3.63452137e-02  2.99170669e-02\\n  2.92674918e-02 -4.83939052e-02  4.06485051e-02  3.89002543e-03\\n  1.00020142e-02  4.08432372e-02 -1.44085812e-03 -3.27542201e-02\\n  3.13731022e-02 -8.28422979e-03  3.19240354e-02  4.00963873e-02\\n -5.47169428e-03 -1.46057336e-02  1.36206806e-01  6.11644760e-02\\n -7.95460418e-02 -7.71473674e-03  2.19529271e-02 -2.14264560e-02\\n  7.10896552e-02 -1.00606708e-02  3.78253646e-02 -1.22247031e-03\\n  3.43564786e-02  8.37451518e-02 -6.27375171e-02 -1.05410084e-01\\n  8.15748703e-03  5.11809662e-02  1.58658233e-02 -4.67889197e-02\\n  1.29824849e-02 -4.67254873e-03  7.39951432e-02  3.19008939e-02\\n -2.84875277e-02  1.13545209e-02 -4.38169651e-02  2.82312986e-02\\n -2.79509295e-02  3.96661460e-02  1.52402165e-04  5.75895142e-03\\n  1.51745165e-02  1.14008430e-02 -3.67237106e-02 -1.05701266e-02\\n  2.41664499e-02  3.14634629e-02  4.71648276e-02 -2.30819895e-03\\n -5.06161675e-02  4.66145836e-02  5.96838929e-02  5.93619160e-02\\n -2.19753515e-02  3.99719365e-02  6.75096549e-03  2.44238339e-02\\n  6.79008514e-02 -6.31515309e-02  1.30651845e-02 -6.60449713e-02\\n  1.74191454e-03 -8.97568017e-02 -4.63475585e-02 -8.24899180e-04\\n  1.77464820e-03 -3.22944038e-02  6.53737560e-02 -3.40830684e-01\\n -9.01682954e-03 -4.85608019e-02  3.03560682e-02  2.26319246e-02\\n  7.48043805e-02  3.79505493e-02 -3.93644571e-02  2.22422145e-02\\n -6.52809143e-02  2.75951810e-02 -1.74825545e-02  1.13792941e-02\\n -2.81259953e-03  4.35821638e-02 -1.34978844e-02  4.30263765e-03\\n  2.31248792e-03  3.04009952e-02 -9.26696137e-02  1.62336379e-01\\n -6.47490025e-02 -4.86145215e-03  1.79840736e-02  6.98021427e-02\\n -2.60416511e-02 -4.78652027e-03  2.42199749e-01  2.62099981e-01\\n -4.95096017e-03  6.22950420e-02  1.47295985e-02 -2.45903321e-02\\n  4.91557755e-02  6.03750646e-02  1.71986669e-02  5.50469384e-04\\n -4.62390203e-03  1.14961974e-02 -1.87855046e-02  7.92559683e-02\\n  8.61227959e-02  9.84580740e-02 -3.42743471e-02  3.97528671e-02\\n -1.77138839e-02  5.17172515e-02 -1.25767756e-02  4.13483121e-02\\n -1.55217694e-02  6.69306293e-02 -2.68434100e-02 -2.70818621e-02\\n  1.71433557e-02  9.90846232e-02  1.77705139e-01  3.02533899e-02\\n -1.12049635e-02  3.33371609e-02 -2.28574071e-02 -9.52586979e-02\\n  2.46521141e-02 -5.68760671e-02 -5.42105250e-02 -3.95271145e-02\\n -3.56109999e-02  1.88342869e-01  5.10654747e-01 -7.68656097e-03\\n -6.89722374e-02  1.22804530e-01  4.02516723e-02  3.08725424e-03\\n -5.62952794e-02  3.82210501e-02  8.17451626e-02  4.08072285e-02\\n  8.13750923e-02  1.10048233e-02  5.00590988e-02  9.87783670e-02\\n  8.97228718e-03 -3.90862264e-02 -1.79505057e-03  3.72402705e-02\\n -4.69514877e-02  2.99629886e-02  8.16232618e-03  1.06586833e-02\\n  5.01593389e-02  4.16230820e-02 -3.28760371e-02  4.71706465e-02\\n -1.90361403e-03  3.71349826e-02 -9.79625732e-02  1.58716086e-02\\n  1.48911746e-02  1.12481480e-02  6.27682731e-02  1.56076644e-02\\n -3.29212211e-02 -2.49224249e-03  3.02875787e-02 -1.07587703e-01\\n  1.01407215e-01  3.20402123e-02  1.18927816e-02  4.02420238e-02\\n -2.58979965e-02  2.56765634e-02  4.50008996e-02 -7.00330734e-02\\n  2.08011232e-02  8.58283117e-02 -2.68527400e-02 -1.92173850e-03\\n -1.55362505e-02 -2.94040423e-02 -2.59227175e-02 -1.32709458e-01\\n -1.67460814e-02  1.18508963e-02  2.73582973e-02  7.59226531e-02\\n -2.80950703e-02  2.16218960e-02 -2.86089201e-02 -3.93439829e-03\\n -4.57666144e-02  2.17701960e-03  2.85577774e-02 -2.34009698e-03\\n -3.32926773e-02 -6.80582523e-02  4.81513962e-02  2.66196951e-02\\n  8.68904144e-02 -7.05792606e-02 -2.26488076e-02 -4.60709026e-03\\n  3.37597132e-02  8.57310444e-02  1.46495719e-02 -3.79002304e-03\\n -9.69742611e-03 -2.85985041e-02 -1.71980262e-02  1.35942223e-02\\n -4.47059013e-02  3.38054672e-02 -1.12974094e-02 -6.74533844e-02\\n  4.22061374e-03 -4.06094380e-02  6.08527288e-02  2.97926478e-02\\n  5.08329421e-02 -5.77390194e-03  3.90635654e-02 -1.78095797e-05\\n  9.39160585e-02  2.90478114e-02 -2.03857105e-02 -3.26699354e-02\\n  2.26129442e-02  6.37262613e-02  4.01242226e-02 -3.96593399e-02\\n -1.16712218e-02  1.67731382e-02  5.47318049e-02 -4.64260299e-03\\n  3.09848376e-02 -2.38496102e-02  6.95591867e-02 -1.02574257e-02\\n  5.98884821e-02  3.65624875e-02 -1.25482380e-01 -4.21196548e-03\\n  6.45525847e-03  8.01470727e-02 -3.03237420e-03  4.15678555e-03\\n  5.16269170e-02 -7.78486580e-02 -4.87300977e-02  5.90967853e-03\\n -9.62061435e-03 -1.32747255e-02  6.79437816e-03 -1.20426156e-02\\n -6.24691369e-03 -6.98323641e-03  3.61980535e-02  3.04643461e-03\\n  3.60294953e-02  1.01864273e-02 -2.90276539e-02  2.92175654e-02\\n  5.44299558e-02  4.97732824e-03 -2.29899846e-02  4.81283963e-02\\n  2.24406626e-02  5.40522300e-03  8.27327296e-02 -4.45150392e-04\\n -1.23469876e-02  2.00132634e-02  8.06211866e-03  1.54138566e-03\\n  8.44081584e-03  2.55605690e-02 -3.55252028e-02  4.86812703e-02\\n  7.52134481e-03  1.16657048e-01  2.10204124e-02 -9.26765621e-01\\n  3.88143212e-02 -4.92664091e-02  1.06123239e-02  2.50785816e-02\\n -3.23953703e-02  8.13713223e-02  3.61266099e-02  4.87180054e-03\\n  4.89776731e-02 -1.68529563e-02  2.83247773e-02 -7.43881054e-03\\n  3.05513069e-02  3.83118317e-02  4.11048643e-02  1.41589409e-02\\n  4.42668386e-02  9.03466623e-03  2.07777461e-03 -2.84546427e-03\\n  1.90788984e-01  2.23055435e-03  3.86555344e-02  1.23179164e-02\\n -1.98646844e-03  1.01512164e-01  1.35404235e-02  1.30604014e-01\\n -6.61129206e-02 -4.99057993e-02  7.71842971e-02 -4.64447141e-02\\n -2.94135027e-02  1.88186746e-02  4.32657683e-03  8.92896429e-02\\n -7.19372765e-04 -2.35897347e-01  5.29834330e-02 -1.15334326e-02\\n -3.24812457e-02  1.50101958e-02  7.80766271e-03 -1.36628496e-02\\n -9.07968450e-03  8.49698558e-02  5.01586171e-03  1.07852489e-01\\n  3.22304107e-03 -3.64190452e-02  3.46292943e-01  2.01305468e-02\\n  2.25182418e-02 -6.21474274e-02  4.55682203e-02  7.42134079e-02\\n  4.25545350e-02  7.26623554e-03  2.01847032e-02 -7.69339548e-03\\n  1.69390291e-02  3.97459678e-02 -4.31891046e-02  3.86044942e-02\\n  2.91764010e-02 -1.15673523e-02  8.91071837e-03 -8.72405842e-02\\n  1.64583772e-02 -1.05116718e-01  7.14988858e-02  3.99641581e-02\\n  9.16582569e-02 -4.29174066e-01 -2.70185266e-02  4.86080913e-04\\n  1.06296828e-02  3.15109231e-02 -1.65238772e-02  2.15499904e-02\\n  7.77550638e-02  3.74063030e-02  6.95987493e-02  1.81841385e-02\\n -9.81453247e-03  4.69605550e-02 -3.81076261e-02  3.02350055e-02\\n  4.15585898e-02  3.31321508e-02 -1.25366775e-02 -4.76000607e-02\\n  3.56182903e-02 -3.98389176e-02 -4.11342941e-02 -1.54442415e-02\\n  3.84913422e-02  4.30830680e-02  6.13535568e-02 -5.46792634e-02\\n -2.45115589e-02 -7.99889024e-03  1.65409259e-02  4.15814482e-02\\n  1.46810459e-02  1.36219086e-02 -1.19729142e-03  1.43346367e-02\\n -2.26854384e-02  5.88059016e-02 -4.66274936e-03 -2.81767752e-02\\n -4.52412292e-02 -1.28055885e-02  9.96842757e-02 -3.90853221e-03\\n  1.88064408e-02 -7.46735185e-03  4.43431437e-02 -2.12299824e-01\\n  3.42938974e-02  4.70436690e-03  8.39193091e-02  7.33608902e-02\\n -6.33669179e-03  2.86974758e-03  6.44411668e-02  1.66408345e-01\\n -6.09627247e+00  1.41426800e-02  4.91940491e-02  2.74937991e-02\\n  1.24328882e-02  3.88354238e-04  4.36544642e-02  1.06740268e-02\\n -4.49428055e-03 -2.13110466e-02  1.86656718e-03 -2.99506765e-02\\n -1.38236014e-02  3.44913406e-03  1.36022912e-02  1.06522895e-01\\n -1.16257984e-02  4.27121483e-02 -1.11668352e-02  2.19286829e-02\\n -3.40837985e-02  7.68380091e-02  1.09669361e-02  9.89244506e-02\\n  5.14797419e-02  7.29973335e-03  8.11771601e-02  3.73970866e-02\\n -1.37199461e-03  5.21727651e-02  3.33011188e-02  2.09318791e-02\\n  4.47247811e-02  3.68760638e-02 -3.42709050e-02  8.84552579e-03\\n -1.24284392e-02 -1.01490726e-03 -3.58691700e-02  4.20034528e-02\\n  4.43152804e-03  1.24690693e-03  1.00284889e-02 -5.67082549e-03\\n -2.35370807e-02 -8.59984476e-03  4.29533347e-02 -3.24551649e-02\\n -1.96758658e-02  5.08341342e-02 -3.27376090e-02 -3.70383896e-02\\n -1.38813898e-01  9.24346328e-04 -1.39656384e-02  8.17995593e-02\\n  2.97474600e-02  8.17535818e-03 -4.05272804e-02 -3.79345603e-02\\n -2.15112120e-02  6.00498840e-02  9.92627442e-02  2.68431604e-02\\n  1.58711448e-02  2.46037170e-02 -5.35819679e-03  3.76484282e-02\\n  4.82910546e-03  6.82034120e-02 -2.75393855e-02  5.85732572e-02\\n -4.65455279e-02  1.11448325e-01 -7.73717016e-02  6.95520565e-02\\n  4.01506126e-02 -3.18109803e-02  9.29276645e-03  1.65170003e-02\\n  3.69235650e-02  8.30530524e-02 -5.36333397e-02  2.76487917e-02\\n  4.21508253e-02 -2.64785700e-02  8.39918386e-03  2.98776105e-03\\n  3.98221845e-03  9.87787615e-04  2.94584129e-03 -2.00136434e-02\\n -5.18104434e-02  1.31965317e-02  7.85920918e-02 -7.75820613e-02\\n -2.94155236e-02 -5.18024852e-03  3.99611369e-02  4.15388830e-02\\n  2.22341530e-03 -1.82128511e-02 -1.99782476e-02  9.01138596e-03\\n  6.73909497e-04  7.74946064e-02 -2.34634772e-01  1.06959315e-02\\n  2.28163470e-02  1.78047549e-02 -2.25701611e-02  6.58751503e-02\\n -1.91231947e-02  1.51151710e-03  2.06869002e-02 -2.16544792e-02\\n  1.42113108e-03  2.43298803e-02 -5.45303971e-02  6.12225607e-02\\n  2.95729470e-02  5.29540405e-02  1.62633657e-02 -1.22598195e-02\\n  1.47580773e-01  1.10653915e-01  7.02723935e-02 -7.88146481e-02\\n -2.56404448e-02 -6.40707323e-03 -6.31095096e-02 -6.15734085e-02\\n -1.13707051e-01  5.34677505e-02 -9.30296779e-02 -1.76987723e-01\\n  2.76531391e-02  6.99546328e-03  2.89576519e-02  7.37136835e-03\\n  1.21443599e-01  6.35268167e-02  2.80553233e-02  1.25188250e-02\\n  3.00427657e-02  3.30783166e-02 -2.43408885e-02 -1.68891922e-02\\n  9.22478512e-02  4.61256206e-02  9.60426172e-04 -2.57601798e-01\\n  4.39203195e-02  1.77944183e+01  1.68088693e-02  4.88578826e-02\\n -1.41943740e-02  4.03487496e-02 -4.94721085e-02  7.65798474e-03\\n -1.82634499e-02  9.63295251e-03  3.11540384e-02  1.02157481e-01\\n  1.18190255e-02 -1.22258656e-01  5.51897159e-04 -4.87572234e-03\\n -3.58967483e-02  2.14881301e-02 -1.69055890e-02  2.02217307e-02\\n -2.13520359e-02 -3.24128084e-02 -4.66758013e-03 -2.92956866e-02\\n  1.94172412e-01  5.58612645e-02  3.11668054e-03  1.32001311e-01]\",\n          \"[ 3.33590321e-02  4.10246328e-02  9.89064388e-03  1.24518471e-02\\n  9.26291198e-02 -6.61514103e-02 -1.37356222e-02  1.03771769e-01\\n  5.14630489e-02 -3.54082733e-02  1.93280935e-01  1.00498544e-02\\n  1.22674093e-01 -2.90113520e-02  2.53649373e-02  1.16221812e-02\\n  1.42999869e-02 -1.16652129e-02  3.29943486e-02 -6.89140614e-03\\n -2.77212262e-02  5.72089292e-03  2.66856165e-03  3.67328189e-02\\n -2.75230967e-02 -6.02918910e-03  1.99680347e-02 -5.31747825e-02\\n  4.08838689e-02  6.27140254e-02  3.25068310e-02 -2.03215200e-02\\n -8.46127793e-03  6.89539537e-02  1.80126429e-02  2.96910573e-02\\n  2.00687088e-02 -4.55465466e-02 -1.01991575e-02  7.08208829e-02\\n  5.73779196e-02  2.82387491e-02  5.61970146e-03  5.65278754e-02\\n -1.06452471e-02  9.93256085e-03  2.27108821e-02  5.91337867e-02\\n  7.05916882e-02 -6.98947385e-02  3.83420475e-02  5.72890341e-02\\n  1.57429408e-02  1.88606083e-01  7.89828300e-02 -3.31617333e-02\\n  6.63698912e-02 -2.43895762e-02 -3.32462378e-02  1.95073843e-01\\n  1.61764137e-02 -1.91519726e-02  5.53288385e-02 -5.40334955e-02\\n  6.72846362e-02  5.82499104e-03 -4.91669867e-03  4.20049913e-02\\n -5.61696105e-02  3.35454382e-02  5.13865314e-02  5.03996238e-02\\n  1.65049389e-01  1.08051673e-02 -3.94298369e-03 -1.25198197e-02\\n  1.44798299e-02  3.79057974e-02 -1.24957996e-05 -2.00939197e-02\\n  1.75227504e-02  2.21334267e-02 -5.45196841e-03 -4.87932526e-02\\n  1.34392351e-01  7.10745901e-02 -1.52400052e-02  3.46537642e-02\\n  1.49958609e-02  1.77646309e-01  2.23435052e-02 -2.71399296e-03\\n -7.52004758e-02 -6.87905475e-02  1.83552336e-02 -2.45357510e-02\\n  3.92957889e-02  3.83631065e-02 -4.27414104e-03  4.24850993e-02\\n  4.47582424e-04 -1.42378271e-01 -6.66712038e-03  6.84703663e-02\\n -7.15089515e-02 -2.42891479e-02  2.51039322e-02  3.29849236e-02\\n  1.00531548e-01  2.60107499e-02  2.17397884e-02  2.63494775e-02\\n  2.21144445e-02  2.69697141e-02  4.18271199e-02  3.49115171e-02\\n -7.06407009e-03 -2.78572962e-02  3.51332910e-02  2.33049039e-02\\n  3.07095181e-02  6.37059808e-02 -3.22705135e-02  3.62865143e-02\\n -1.94912534e-02  1.16694830e-02 -3.53006832e-02 -2.75706463e-02\\n  3.15715820e-02 -1.88188329e-02  3.65120247e-02  1.36356158e-02\\n -5.72528178e-03 -2.77521349e-02  9.58397612e-03 -3.63730788e-02\\n  2.28670463e-02  8.12500045e-02  2.52387337e-02  2.07987130e-02\\n  1.34293863e-03  8.98329467e-02 -6.87526399e-03 -6.25357702e-02\\n  1.59231238e-02 -2.36607939e-01  3.61823477e-02  4.87820655e-02\\n -8.39174241e-02  6.52452111e-02  1.40535377e-03  1.58888280e-01\\n -1.68435860e+00  3.06924526e-02 -5.18088229e-03  6.23563081e-02\\n  8.30778480e-02  3.50077562e-02  2.56311353e-02  1.68728475e-02\\n  8.72475579e-02  5.67199923e-02 -3.93789932e-02  2.95157954e-02\\n  2.55933199e-02 -2.62934435e-03  4.88582626e-02 -9.51149128e-03\\n  1.53616825e-02 -2.49841250e-02  4.10372540e-02 -1.61422254e-03\\n  1.00743413e-01  1.51701709e-02  2.58978233e-02 -1.40699968e-02\\n  2.41532084e-02  7.31062517e-02  5.00130579e-02  1.42083894e-02\\n -5.26151285e-02 -1.25619797e-02  1.17203884e-01  7.56673068e-02\\n -1.12886377e-01  3.96098336e-03  6.63549581e-04  4.35661040e-02\\n  3.73068154e-02  9.90283396e-03  1.51655413e-02  3.09962053e-02\\n  5.08337729e-02  4.83361781e-02 -5.42445891e-02  4.02560085e-02\\n -9.06663295e-03  5.23260683e-02  1.36129512e-02 -4.21444699e-02\\n  2.50105988e-02 -5.04451506e-02  1.28967404e-01 -3.33577581e-02\\n -3.93924341e-02  2.75919456e-02  1.56387482e-02  1.05387114e-01\\n -9.27894842e-03 -2.80098198e-03  2.07922235e-02  1.29845587e-03\\n -3.57925915e-03  9.01186652e-03 -1.37363859e-02 -1.77425053e-02\\n  5.62136583e-02 -1.07684163e-02  6.18912056e-02 -1.53993405e-02\\n -3.43303718e-02  3.15737985e-02  9.99911651e-02  3.58734839e-02\\n -3.47455069e-02 -5.59688313e-04 -2.14362331e-02  2.22957730e-02\\n  3.28150205e-02 -4.33530100e-02  1.16113378e-02  5.41578047e-03\\n  1.48443328e-02 -2.88440306e-02 -4.67337407e-02 -6.72862008e-02\\n -1.01981848e-01 -4.74224752e-03  3.32948454e-02 -1.63285166e-01\\n -3.09912749e-02 -3.75428051e-02  4.28019911e-02  5.25090061e-02\\n  7.31464401e-02  1.77087747e-02 -7.22181499e-02 -9.64792818e-03\\n -6.72059879e-02 -9.37461108e-02  2.08751429e-02 -2.18737703e-02\\n  6.26863213e-03  4.00698595e-02 -5.30062207e-05  3.40885185e-02\\n -5.57326488e-02  6.74490109e-02 -5.50671108e-02 -8.06243718e-02\\n -7.04174712e-02  9.77121852e-03  3.03787328e-02  1.22684523e-01\\n  9.44481511e-03  7.32474998e-02  2.28703588e-01  3.26141477e-01\\n -8.85388069e-03  1.21511966e-02 -6.52432023e-03 -7.03373626e-02\\n  4.03530933e-02 -2.92263329e-02  2.20360346e-02 -2.02263854e-02\\n  2.04457734e-02  2.35204566e-02 -7.71724293e-03  1.92554519e-02\\n  4.50593978e-02  7.65838549e-02  1.09547703e-02  4.37789857e-02\\n  1.95586588e-02  7.12661147e-02 -2.96187755e-02  7.76335523e-02\\n  5.22364080e-02 -7.36768777e-03 -2.22201087e-02 -4.51847315e-02\\n  6.54455600e-03  6.42870665e-02  2.47711033e-01  4.41148542e-02\\n -7.51132565e-03  7.28886053e-02  5.57640940e-02 -3.19318622e-02\\n -4.04182598e-02 -1.68437079e-01  1.78843252e-02 -5.33122979e-02\\n  4.19575274e-02  5.67662418e-02  6.26368761e-01  2.24947575e-02\\n -2.64691729e-02  9.42048654e-02  1.84331127e-02  1.39129721e-03\\n -6.61486164e-02  8.25155303e-02 -4.16096970e-02  4.74457890e-02\\n  5.60658202e-02  1.03176828e-03  3.76024507e-02  6.64563701e-02\\n -3.26771103e-02 -3.05331666e-02  1.63854356e-03  6.56435415e-02\\n  5.79832960e-03  1.50776757e-02  1.15938092e-04  3.13832052e-02\\n  2.71811783e-02  4.35700156e-02 -3.17516923e-02  1.28946498e-01\\n -4.53375094e-02  7.74852699e-03 -3.11919544e-02 -2.06580888e-02\\n  3.19998199e-03  2.46107616e-02  5.60306199e-02 -4.31255475e-02\\n -3.21977697e-02  7.48405233e-02 -1.31821688e-02 -1.45631298e-01\\n  8.10359344e-02  8.47491610e-04  2.02643666e-02  1.30639300e-02\\n -1.74965058e-02  1.99727546e-02  5.38050346e-02  5.52116968e-02\\n -1.97553374e-02  6.36513233e-02 -1.96585134e-02 -3.70695302e-03\\n -6.21228814e-02 -8.60035419e-02 -2.43054274e-02 -5.70765100e-02\\n -4.16130200e-03 -7.00293947e-03  3.52248317e-03  1.14366986e-01\\n -3.99292968e-02  9.24281590e-03 -5.11112437e-02 -3.14393975e-02\\n -3.17935944e-02 -1.29966706e-04  6.02309033e-02  7.05645513e-03\\n -2.57692952e-03 -9.45823733e-03 -1.38923177e-03  3.49970125e-02\\n  1.39089957e-01 -4.45180275e-02  1.79195050e-02 -3.20139714e-02\\n  4.62141670e-02  8.02019015e-02  4.96772900e-02  1.92033108e-02\\n  9.28304996e-03 -6.35102838e-02  4.02441509e-02 -1.77619215e-02\\n -1.70957092e-02 -9.34022851e-03 -6.43488392e-02 -3.10023520e-02\\n -1.09329901e-03  5.37083931e-02  6.29458055e-02  1.19131766e-02\\n  8.40985477e-02  8.47828835e-02  5.49523160e-02  3.52701098e-02\\n  1.22934110e-01  1.89504866e-02 -3.57148307e-03 -5.21963686e-02\\n  4.78194542e-02  7.61266649e-02  1.31466454e-02  1.99844744e-02\\n -1.18895583e-02  1.29280733e-02 -5.22143729e-02 -2.10958719e-02\\n  6.26195148e-02  1.44077139e-02  2.58592926e-02  1.48015358e-02\\n  3.40432636e-02  6.42055180e-03 -8.57649893e-02 -8.67947750e-03\\n  7.31418878e-02  1.05064124e-01 -2.96990462e-02 -1.92398280e-02\\n  1.91522036e-02 -1.02680862e-01 -3.96399423e-02 -3.17947716e-02\\n -2.38191485e-02 -8.29237793e-03 -6.79928949e-03  3.08248922e-02\\n -5.24309836e-03  3.30239609e-02  5.94879733e-03  5.99019676e-02\\n  5.18556722e-02  4.05963697e-02 -3.23744044e-02  1.81942452e-02\\n  6.21532314e-02 -1.54113453e-02  8.86520650e-03  7.00260326e-02\\n  6.46052090e-03  6.58244118e-02  4.69328575e-02  9.87408310e-03\\n -3.31799574e-02 -4.74036904e-03  8.26450996e-04  9.64692421e-03\\n  4.05152403e-02  2.67364066e-02 -4.22687158e-02  7.80798262e-03\\n  3.49811800e-02  5.32444976e-02  8.26497450e-02 -5.64764917e-01\\n  2.20191553e-02 -3.40289176e-02 -1.22920731e-02  1.99462194e-02\\n -8.54329988e-02  1.04714490e-01  2.82985419e-02  3.99553590e-02\\n -2.18949560e-02 -1.79375354e-02  5.87458797e-02  2.54889764e-02\\n  2.73996480e-02  6.19163290e-02  1.68534126e-02 -1.00738893e-03\\n  5.61891682e-02  1.58070147e-01  2.06274968e-02 -1.33516109e-02\\n  1.43188626e-01  9.60644567e-04  3.10153682e-02 -2.30005588e-02\\n -8.38477984e-02  8.13984498e-02 -1.19536994e-02  4.52648476e-02\\n  3.39473481e-03 -7.83292428e-02  7.50085413e-02 -2.93678883e-02\\n  2.38263458e-02  3.40225585e-02  1.72249246e-02  2.54056156e-02\\n -8.52588639e-02 -2.79901057e-01 -1.43978391e-02 -2.13644151e-02\\n -2.68937629e-02 -2.42056977e-02  2.94144060e-02  1.73602309e-02\\n  6.46246001e-02  1.70830935e-02 -1.84798352e-02  5.62324014e-04\\n  2.88724657e-02 -4.18083780e-02  3.16208988e-01  9.66771971e-03\\n -6.30794093e-03 -5.45517430e-02  3.81813832e-02  1.07392929e-01\\n  1.38474405e-02  3.93441878e-02  1.78983156e-02 -5.46427863e-03\\n  4.94497968e-03 -3.91957257e-03  2.14993511e-03  5.08054867e-02\\n -4.40552756e-02  1.00466972e-02  4.42272387e-02 -1.23538159e-01\\n -2.79558524e-02 -9.90017205e-02  6.87825903e-02  3.48266140e-02\\n  4.70884331e-02 -4.06982869e-01 -3.97452600e-02 -3.45108286e-02\\n  3.75245623e-02  2.47758962e-02  8.12352076e-03  4.34303246e-02\\n  4.44798805e-02  2.50043701e-02  5.16495071e-02  4.33375314e-02\\n  3.14093232e-02  5.14236093e-02 -1.24732573e-02  2.14611404e-02\\n  2.66366564e-02  4.49700393e-02 -1.85242295e-02 -2.73234714e-02\\n -4.37718164e-03 -8.22185129e-02 -8.14721957e-02  4.60616574e-02\\n  7.92503916e-03  5.30268587e-02  5.46492971e-02 -2.34255437e-02\\n  1.06102359e-02 -1.05151115e-02 -5.14812348e-03  1.41636785e-02\\n  2.05702800e-02  1.61193181e-02  1.77548975e-02 -6.84672268e-04\\n -4.15351428e-02  1.75869390e-02  3.96116497e-03 -3.38989263e-03\\n -1.14441942e-02  5.46680875e-02  8.51619691e-02  1.16261868e-02\\n  3.09649967e-02 -7.44718267e-03  4.72033210e-03 -6.57568723e-02\\n  4.60969144e-03  4.92786169e-02  3.68728042e-02  7.37974346e-02\\n  6.72910139e-02  5.84512204e-03  7.42252618e-02  1.66420266e-01\\n -6.11754656e+00  9.50130895e-02  1.75478701e-02  7.98613429e-02\\n -3.78607661e-02 -2.01202314e-02  1.75130609e-02  8.90458096e-03\\n -1.58402428e-03 -2.79147495e-02  8.14823899e-03 -1.15667544e-01\\n -3.75366472e-02 -1.59282219e-02 -3.29360850e-02  5.06871492e-02\\n -5.49250543e-02  7.40325525e-02 -6.38337864e-04  5.01102880e-02\\n -7.83783477e-03  1.02099702e-01  7.59196058e-02  1.09837785e-01\\n  2.34418586e-02  6.10419884e-02  5.18716276e-02  5.51287122e-02\\n -1.13986302e-02 -2.62615867e-02 -4.84220264e-03 -5.33538051e-02\\n -6.75622327e-03 -2.11859308e-02 -3.34642618e-03  1.43339830e-02\\n -1.62192713e-02 -5.33236517e-03 -2.43225284e-02  4.75151315e-02\\n -1.79500598e-02  8.14044476e-03 -7.41897821e-02  7.74411578e-03\\n -1.93878682e-03  3.26243266e-02  5.17768189e-02 -2.70627476e-02\\n -1.23234559e-03  6.27315566e-02 -1.06255315e-01 -1.58143099e-02\\n -1.87082633e-01 -1.27072902e-02 -1.22482749e-02  3.32328714e-02\\n -1.36155970e-02  1.91245060e-02 -8.10695663e-02 -1.03762792e-02\\n -3.07979248e-02  1.49583593e-01  4.97856364e-02  2.80631557e-02\\n  3.22674518e-03  3.52847315e-02 -4.84554768e-02  6.20764755e-02\\n  1.24806408e-02  5.74602783e-02  5.05730161e-04  3.77475321e-02\\n -8.61658305e-02  4.25796248e-02 -8.87353271e-02  9.25917849e-02\\n  4.97990027e-02 -5.76780923e-03  3.80290952e-03  6.48121834e-02\\n  4.38264683e-02  6.70055524e-02 -1.97295062e-02  4.39198688e-02\\n  2.83332318e-02 -1.53920418e-02  7.41654634e-02 -3.73801999e-02\\n  6.72133043e-02  1.22847306e-02  7.68526569e-02 -3.72391380e-02\\n -2.66881622e-02  3.60055827e-02  6.03205711e-02 -6.29948974e-02\\n -5.61763458e-02  6.15342241e-03 -7.93136016e-04  1.53228613e-02\\n -1.38859106e-02 -3.60608697e-02 -1.01722470e-02  2.85611991e-02\\n  7.08173169e-03  1.25460830e-02 -2.36329928e-01 -2.88457586e-03\\n  5.84307499e-02  2.52814218e-02 -1.99551675e-02  4.15055528e-02\\n -3.20034251e-02 -3.71597484e-02  1.57322381e-02  1.62919483e-03\\n  5.03338724e-02 -3.54415178e-02 -5.46300737e-03  9.33099687e-02\\n  1.88706741e-02  5.58265224e-02  9.71040968e-03  2.65672716e-04\\n  2.00715899e-01  1.12576177e-02  4.25807312e-02 -5.27611673e-02\\n  1.06636155e-02  1.61863454e-02 -7.77330026e-02 -5.53944521e-02\\n  3.31173465e-02  5.59320450e-02 -3.89565639e-02 -1.43161669e-01\\n  1.86360572e-02 -7.01149285e-04  3.25455656e-03 -1.20561346e-02\\n  8.16524923e-02  1.69537812e-02  1.19431559e-02 -2.78024543e-02\\n  3.88018675e-02  5.82400188e-02 -3.89153548e-02 -1.72556583e-02\\n  4.64565195e-02  3.00796162e-02  4.78869528e-02 -1.90942481e-01\\n -1.85892228e-02  1.78184719e+01  1.45209767e-02  3.10189016e-02\\n -1.38941118e-02  1.61557812e-02 -3.59523445e-02 -3.38944048e-03\\n  2.09001526e-02  4.28359210e-02  5.64457290e-02  5.09515740e-02\\n  1.40252365e-02 -1.16866767e-01 -2.50465400e-03 -4.01123166e-02\\n  3.55431587e-02  2.34924499e-02 -9.20282677e-03  1.10180201e-02\\n  2.34832950e-02  3.96149382e-02  3.12064216e-02 -3.89708281e-02\\n  4.60279658e-02  4.15797047e-02  1.20851630e-02  1.15645200e-01]\",\n          \"[ 4.33314331e-02  3.71905267e-02 -1.03577394e-02  2.02020500e-02\\n  1.12353779e-01 -1.20821640e-01 -3.39944661e-02  1.21866323e-01\\n  2.90593728e-02 -1.44710038e-02  2.17901781e-01 -1.36769414e-02\\n  1.49612620e-01 -3.87036093e-02  3.37114669e-02  1.08590005e-02\\n  4.19068001e-02 -3.87091078e-02  4.84754220e-02  3.43307294e-02\\n -3.76512520e-02  6.48093503e-03  2.71655507e-02  4.28241491e-02\\n -1.11479582e-02 -3.11211534e-02  2.68926863e-02 -7.30985999e-02\\n  9.72151477e-03  2.90272981e-02  4.59699929e-02 -5.12431897e-02\\n -3.09240762e-02  5.39557375e-02  6.19266240e-04  3.83984037e-02\\n -7.39347795e-03 -4.72743437e-02  6.48781210e-02  8.03978667e-02\\n  4.47493978e-02  4.35020104e-02  2.39135679e-02  6.91748187e-02\\n  4.78990702e-03  2.02064663e-02  3.43472399e-02  7.76075497e-02\\n  6.07720688e-02 -7.41307586e-02  5.00389822e-02  1.04596047e-02\\n  3.42484005e-02  1.93850368e-01  1.56825185e-01 -2.11697966e-02\\n  6.22146130e-02 -3.61042060e-02 -3.27766836e-02  2.33371988e-01\\n  3.31588238e-02 -2.91426461e-02  3.87430489e-02 -1.78688020e-02\\n  2.00324375e-02  1.88667513e-02  1.16075510e-02  3.57473008e-02\\n -6.07955828e-02  3.42488587e-02  4.09883447e-02  1.44034466e-02\\n  2.40534425e-01 -1.14241047e-02 -2.58702785e-02 -1.43892653e-02\\n  3.73196672e-03  5.72405569e-02  3.77563946e-02 -4.67306003e-03\\n  1.60396751e-02  4.60727587e-02  3.43395607e-03 -8.96572024e-02\\n  1.37351900e-01  8.04854855e-02 -2.17566490e-02  9.50889383e-03\\n  4.17292910e-03  2.01469526e-01  4.60618772e-02 -7.96988606e-03\\n  2.68364325e-02 -6.52660578e-02  1.05562741e-02 -2.23474596e-02\\n  5.98434955e-02  4.12520654e-02 -1.37152355e-02  3.66546027e-02\\n -5.75634232e-03 -1.23219140e-01  1.96845755e-02  7.05839768e-02\\n -1.03395991e-01 -2.26455703e-02 -1.16558746e-02  2.04599332e-02\\n  1.02634929e-01  3.11633479e-02  3.22819203e-02  5.41167520e-03\\n  2.56589847e-03  1.91687290e-02  3.05834692e-02  4.53022607e-02\\n  1.43838497e-02 -5.57538010e-02  6.90028816e-02  1.06305059e-03\\n -4.52709850e-03  8.39935094e-02 -4.50408123e-02  3.65643390e-02\\n -2.95485985e-02  2.69891210e-02 -1.34619493e-02 -5.07998839e-03\\n  3.37431878e-02 -1.83913987e-02  4.24868055e-02 -2.68486980e-02\\n  4.91139153e-03 -5.16945031e-04 -1.14768036e-02 -5.13099469e-02\\n  2.93323938e-02  7.16647878e-02  1.48565909e-02  4.60691750e-02\\n  1.39548965e-02  3.62697579e-02 -1.62622184e-02 -7.17116818e-02\\n  9.49019007e-03 -1.87750757e-01  4.60864566e-02  5.55818342e-02\\n -7.88819939e-02  7.13889599e-02 -2.29153200e-04  1.78829268e-01\\n -1.69414520e+00  3.28147523e-02  1.90415856e-04  6.14395887e-02\\n  8.28195140e-02  2.11838540e-02 -4.12765687e-04  1.54521558e-02\\n  8.82184207e-02  4.03262116e-02 -3.55736278e-02  2.03854367e-02\\n -3.29235308e-02  2.33653411e-02  2.22388655e-02 -3.17778857e-03\\n  1.28724137e-02 -5.46385497e-02  2.03384217e-02 -1.47290900e-02\\n  7.95520097e-02 -1.05121988e-03 -4.66346508e-03 -2.29942962e-03\\n  4.18416969e-02  6.86220378e-02  4.46842611e-02  2.61623319e-02\\n  9.31813382e-03 -2.23016180e-02  6.01849183e-02  6.50354028e-02\\n -5.25414981e-02 -4.55133291e-03 -9.26365610e-04  4.08576466e-02\\n  5.38233519e-02 -2.84381229e-02  1.24874618e-02  2.63251532e-02\\n  3.64762358e-02  5.19175790e-02 -6.15824349e-02  3.43758129e-02\\n -2.01086942e-02  6.18110597e-02  2.65847445e-02 -4.91025895e-02\\n  3.56131345e-02 -4.33997475e-02  1.05438016e-01 -7.93978851e-03\\n -4.47735041e-02  2.53837779e-02  7.60140782e-03  1.34078011e-01\\n -2.33150106e-02 -9.86658316e-03  1.44750522e-02 -4.57974337e-03\\n  1.24383727e-02  1.06265629e-02 -4.14861888e-02  8.14360846e-03\\n  4.07738872e-02  2.62892190e-02  4.04741131e-02 -1.31886257e-02\\n -4.10415977e-02  3.30117494e-02  4.07839119e-02  4.06767316e-02\\n -4.10023294e-02 -1.50290914e-02 -2.52913870e-03  3.53297517e-02\\n  6.34834170e-02 -7.19042197e-02 -1.36988210e-02  1.74383745e-02\\n  3.20918672e-02 -3.98409069e-02 -3.36179473e-02 -6.95649087e-02\\n -7.69578144e-02 -2.99463309e-02  3.03512942e-02 -2.14601189e-01\\n -1.84521358e-02 -2.99122836e-02  3.34513485e-02  4.22683135e-02\\n  1.20636813e-01  8.81243031e-03 -6.39184788e-02 -7.43263029e-03\\n -9.92477834e-02 -1.02395512e-01  1.02451928e-02 -1.76743735e-02\\n  2.47766322e-04  3.96655910e-02 -1.65645946e-02  3.99303809e-02\\n -5.29392324e-02  6.27042279e-02 -9.75420624e-02 -7.17212707e-02\\n -1.13937706e-01  1.77985113e-02  3.93762216e-02  8.99001658e-02\\n -1.13214238e-03  5.99329099e-02  2.25550056e-01  2.99619019e-01\\n  2.11436278e-03  1.06601669e-02 -2.17240918e-02 -3.66946161e-02\\n  5.69579974e-02 -3.40624936e-02  2.76796822e-03 -3.66960699e-03\\n  5.90620413e-02  7.04015642e-02 -2.34608762e-02  2.91709304e-02\\n  7.70169050e-02  4.94046696e-02 -1.16429878e-02  3.52228619e-02\\n  1.01575069e-02  6.11764193e-02 -4.92446572e-02  3.32205929e-02\\n  6.86762258e-02  2.77902335e-02 -3.55788097e-02  2.12252624e-02\\n -8.05515703e-03  5.57942502e-02  2.76646048e-01  2.22755112e-02\\n -2.52304021e-02  8.31342340e-02  8.31760466e-02 -2.75913104e-02\\n -5.47336452e-02 -1.63008362e-01  7.74972932e-03 -6.79085404e-02\\n  2.37144530e-02  8.97085518e-02  6.15022838e-01  2.09889058e-02\\n  1.80043764e-02  1.52984768e-01  1.64438896e-02 -2.88538300e-02\\n -1.24453969e-01  8.00191090e-02 -6.17175177e-02  3.65412310e-02\\n  1.12948067e-01 -1.09829744e-02  3.70327123e-02  9.22213197e-02\\n -1.84309725e-02 -4.34295312e-02 -1.22084352e-03  4.01287489e-02\\n  2.34701484e-02  4.97846715e-02 -1.80314034e-02  2.08198410e-02\\n  4.42685150e-02  4.80056442e-02 -4.77089994e-02  7.68324062e-02\\n -3.16172838e-02 -2.12146677e-02  2.28324067e-02 -1.22215757e-02\\n -8.23710696e-04  2.45748181e-02  6.46087229e-02  2.07961556e-02\\n -8.04551691e-02  7.12704584e-02  1.49371000e-02 -4.63721789e-02\\n  1.01825893e-01  1.38244219e-02  2.22580899e-02  5.53523041e-02\\n -7.48107955e-03  1.63569041e-02  4.48360555e-02 -3.25456969e-02\\n  5.17323762e-02  8.18217546e-02 -5.68983257e-02 -5.46508329e-03\\n -7.28333890e-02 -6.03394583e-02 -2.66573988e-02 -8.69936943e-02\\n -1.64162386e-02  9.90171917e-03  2.55189873e-02  1.02391854e-01\\n -4.88911159e-02  1.64048467e-02 -2.57261954e-02 -4.62100878e-02\\n -2.26002187e-02 -1.89749978e-03  2.61977222e-02  1.38558336e-02\\n -4.27586958e-03 -1.66725178e-04 -1.15596624e-02  4.75853682e-02\\n  1.43873155e-01 -8.41294974e-02 -8.21845699e-03 -8.73042122e-02\\n  3.26937325e-02  1.10172622e-01  2.79460829e-02  3.60299982e-02\\n  3.73553089e-03 -4.02489416e-02  1.16597442e-02  2.09937543e-02\\n -4.49471176e-02  4.32501873e-03 -5.83305284e-02 -1.57094598e-02\\n  1.70009807e-02 -4.95923683e-03  6.72472939e-02  1.43624609e-02\\n  9.04533714e-02  5.07436283e-02  6.06312566e-02  6.62382413e-03\\n  1.41873404e-01  3.02114636e-02  6.38418272e-03 -4.03171293e-02\\n  4.89194244e-02  4.88063917e-02 -1.76122785e-02  5.57535049e-03\\n  1.34844144e-04  1.05497679e-02 -4.07025889e-02 -2.31805388e-02\\n  5.60186654e-02 -4.72629964e-02  5.53517826e-02  2.70934980e-02\\n  4.91552725e-02  1.26172546e-02 -8.52848366e-02 -2.15445235e-02\\n  9.03614908e-02  7.43895322e-02 -2.34963652e-02 -2.10757945e-02\\n  5.33954836e-02 -1.05647139e-01 -5.61008081e-02 -1.50281116e-02\\n -2.54250485e-02  7.44741876e-04 -2.14220472e-02  2.19580326e-02\\n  7.98552483e-03  5.27356789e-02 -5.45326015e-03  8.74771737e-03\\n  6.74080625e-02  4.77220677e-02 -1.01438448e-01  1.67343263e-02\\n  5.83386794e-02  1.56406034e-02 -6.43783994e-03  3.57924588e-02\\n  1.27482670e-03  5.84517792e-02  4.74017411e-02  1.78078581e-02\\n -5.40941767e-02 -1.55145931e-03 -1.03417104e-02  1.29258363e-02\\n  6.83051795e-02  3.91078182e-03 -2.66590212e-02  2.47993711e-02\\n  8.23136512e-03  5.45862615e-02  8.28886405e-02 -8.81106317e-01\\n  7.98248798e-02 -3.04240678e-02 -1.74441736e-03  2.40878593e-02\\n -9.46713090e-02  5.83823211e-02  3.34128439e-02  1.00526355e-01\\n -2.86995228e-02 -1.79352763e-03  5.10210805e-02  1.20028099e-02\\n  3.97829711e-02  4.36517559e-02  6.05924614e-02 -1.88345613e-03\\n  6.23586662e-02  8.96285474e-02 -1.47955371e-02 -1.07910335e-02\\n  1.65056601e-01  1.07654007e-02  8.22856650e-03 -3.77023150e-03\\n -7.76603594e-02  8.56262669e-02  2.95348410e-02  7.49583170e-02\\n  7.48458668e-04 -1.05147891e-01  7.59839863e-02 -5.86395003e-02\\n  2.51337588e-02  3.53066288e-02  3.24166263e-03  5.07288426e-02\\n -1.00400783e-01 -2.61453003e-01  7.23789493e-03 -3.03078094e-03\\n -2.46230606e-02  9.11788922e-03  3.15579101e-02  1.02437316e-02\\n  4.95082252e-02  4.30621095e-02 -6.28548414e-02  4.71933335e-02\\n  3.09451967e-02 -3.51604968e-02  2.83438891e-01  4.42434801e-03\\n -6.53416477e-03 -6.39612973e-02  4.62407582e-02  1.07135117e-01\\n  1.01700053e-02  2.28928477e-02  4.62815538e-03  9.13134217e-03\\n -5.47250062e-02 -1.22418823e-02 -9.32769664e-03  5.94273619e-02\\n -1.53725427e-02  1.65418033e-02  4.09354903e-02 -1.14588082e-01\\n -6.01147395e-03 -1.10143162e-01  4.66291904e-02  2.80426703e-02\\n  7.23426193e-02 -4.04292107e-01 -3.57814841e-02 -3.75507511e-02\\n  1.26649421e-02  8.90110340e-03  2.21913084e-02  4.39295471e-02\\n  1.14552462e-02  2.75197309e-02  5.31970337e-02  3.53288725e-02\\n  2.55993214e-02  5.75586371e-02 -2.75253095e-02  1.83491427e-02\\n  5.04866466e-02  5.26783951e-02  3.23171495e-04 -8.62668157e-02\\n -1.46692218e-02 -1.00467026e-01 -1.17288150e-01  9.15812515e-03\\n  3.23944017e-02  2.05575265e-02  5.61246127e-02 -1.97397973e-02\\n -1.49545791e-02 -3.12099513e-02 -7.76725449e-03  1.07153244e-02\\n  4.76779975e-03 -6.69341674e-03  1.93873663e-02  2.24574264e-02\\n -9.65787563e-03  1.56193599e-02  1.37924394e-02 -9.26114211e-04\\n -1.75597314e-02 -5.55513566e-03  8.60740766e-02  3.13988142e-02\\n  4.86786477e-02 -3.64267477e-03  4.77144830e-02 -6.60521388e-02\\n  4.71153855e-03  5.89334704e-02  5.86179132e-03  9.81238037e-02\\n  7.02244788e-02  1.40450206e-02  6.77942783e-02  1.54805303e-01\\n -6.28955460e+00  4.58518639e-02  3.27026360e-02  7.15827048e-02\\n -7.20309317e-02 -4.25228029e-02  2.60125473e-02  4.90467716e-03\\n -1.40302200e-02 -8.69828742e-03  1.77613646e-02 -9.64834988e-02\\n -1.72496885e-02 -6.56571425e-03 -2.66971048e-02  7.72643313e-02\\n -3.22071202e-02 -5.37071750e-03 -7.64192780e-03  2.20416654e-02\\n  1.39459735e-03  1.10724740e-01  1.29335150e-01  1.34015188e-01\\n  7.40811974e-02  4.33491021e-02  1.01002879e-01  3.17047350e-02\\n -7.25489995e-03 -1.38610508e-02  3.88455694e-03 -3.27314250e-02\\n -2.16576215e-02 -1.65781677e-02 -2.84068938e-02  1.69395395e-02\\n -4.02895687e-03 -1.15386127e-02 -2.56787185e-02  6.72391197e-03\\n  3.52488336e-04  7.42305815e-02  2.48673204e-02  1.66563299e-02\\n -2.86953766e-02 -7.90474191e-02  5.41117191e-02 -3.96748595e-02\\n -5.18567301e-03  2.93841735e-02 -1.63838744e-01 -1.05836112e-02\\n -1.81840569e-01  2.25500222e-02 -3.25447088e-03  7.24601671e-02\\n -1.34760924e-02  2.78482996e-02 -8.77222493e-02 -2.06240043e-02\\n -2.34716460e-02  1.86763585e-01  2.84051020e-02  2.96412949e-02\\n  3.92211223e-04  4.42672223e-02 -1.22469645e-02  5.57196252e-02\\n  2.06305422e-02  5.59340417e-02  2.64036898e-02  5.28468154e-02\\n -8.11308920e-02  3.83765809e-02 -8.90576914e-02  1.54312566e-01\\n  4.45301048e-02  1.09305116e-03  8.00726563e-03  8.93648043e-02\\n  3.05009447e-02  3.56524736e-02 -2.14213673e-02  3.15984860e-02\\n  3.61668915e-02  1.48600340e-02  7.95685649e-02 -2.08698567e-02\\n  8.50607082e-02  1.22070732e-02  1.08527005e-01 -4.66979258e-02\\n -7.76773244e-02  5.84740378e-02  8.28831196e-02 -6.41381145e-02\\n  5.49336569e-03  1.38047962e-02  1.79193486e-02  3.41002680e-02\\n -8.84073321e-03 -7.60027617e-02 -3.34886052e-02  1.30345579e-02\\n  1.12530133e-02  5.21403663e-02 -2.13583991e-01  7.28560984e-03\\n  6.68660104e-02  6.66683838e-02 -3.57632712e-02  8.08905959e-02\\n -1.13329887e-02 -2.76407003e-02  2.40222998e-02  1.43484613e-02\\n  2.25231275e-02 -3.84424464e-04 -1.01595232e-02  9.47291628e-02\\n  2.74183434e-02  7.17341453e-02  1.08329533e-03 -1.26976985e-02\\n  2.27819115e-01  4.05786745e-02  4.07469310e-02 -1.48974080e-02\\n  3.25486925e-03  2.54480224e-02 -1.11217149e-01 -5.27096801e-02\\n -3.30389664e-02  5.28270304e-02 -1.87059920e-02 -7.52190128e-02\\n  1.75367836e-02 -2.50392687e-02  1.20840287e-02 -6.12260075e-03\\n  9.34569463e-02  1.10080302e-01  1.34827653e-02  4.84538078e-02\\n  6.54675588e-02  4.83008884e-02 -2.19656788e-02 -2.32241303e-02\\n  6.50434047e-02  4.14697565e-02  5.07213138e-02 -1.65045619e-01\\n  1.88108273e-02  1.77565899e+01  1.86637733e-02  3.08259577e-02\\n -4.93748896e-02  2.17960719e-02 -5.83777241e-02 -1.86588503e-02\\n -4.14926186e-02 -4.74015288e-02  4.93118353e-02  6.23788014e-02\\n  1.12888999e-02 -1.22875877e-01 -1.26754688e-02 -4.75159883e-02\\n  5.11635542e-02  1.59778632e-02  6.33238582e-04  3.66618298e-02\\n  1.67782884e-02  4.27812822e-02  4.71008234e-02 -1.40382331e-02\\n  9.86068398e-02 -3.29261227e-03  1.27319247e-03  1.15942977e-01]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"combined_embedding\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 396,\n        \"samples\": [\n          \"[-0.01011756  0.03073166 -0.00500749 ...  0.05586126  0.00311668\\n  0.13200131]\",\n          \"[-0.0005354   0.03475491 -0.01803118 ...  0.00596634  0.01067833\\n  0.12197942]\",\n          \"[-0.01553523  0.03246752 -0.01809895 ...  0.04675647  0.00033047\\n  0.14809202]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment_scores_y\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"level2_sentiment_scores_y\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MS1dnBRiwAXj",
        "outputId": "97e467c8-88aa-4df4-a5fd-067b377a944c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Label Encoding"
      ],
      "metadata": {
        "id": "FXssIkqpM6Yy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encoding for 'narrative'\n",
        "def one_hot_encode_column(df, column_name):\n",
        "    unique_values = df[column_name].unique()\n",
        "    mapping = {val: idx for idx, val in enumerate(unique_values)}\n",
        "    df[f'{column_name}_onehot'] = df[column_name].map(mapping)\n",
        "    return df, mapping\n",
        "\n",
        "# Process level_1 and level_2 columns to create unique mappings and embeddings\n",
        "def process_levels(df, level_column):\n",
        "    # Get unique classes for the level\n",
        "    unique_classes = df[level_column].unique()\n",
        "\n",
        "    # Create a mapping of class to embedding\n",
        "    class_to_embedding = {cls: generate_embedding(cls) for cls in unique_classes}\n",
        "\n",
        "    # Map embeddings back to class for reversibility\n",
        "    embedding_to_class = {tuple(v): k for k, v in class_to_embedding.items()}\n",
        "\n",
        "    # Apply embedding to the DataFrame\n",
        "    df[f'{level_column}_embedding'] = df[level_column].map(class_to_embedding)\n",
        "\n",
        "    return df, class_to_embedding, embedding_to_class\n",
        "\n",
        "# Save processed DataFrame\n",
        "def save_processed_data(train_df, dev_df, train_path, dev_path):\n",
        "    train_df.to_csv(train_path, index=False)\n",
        "    dev_df.to_csv(dev_path, index=False)\n",
        "    print(f\"Train saved to {train_path}\")\n",
        "    print(f\"Dev saved to {dev_path}\")\n",
        "\n",
        "# Process train and dev datasets\n",
        "def process_annotations(train_df, dev_df):\n",
        "    # One-hot encode the narrative column\n",
        "    train_df, narrative_mapping = one_hot_encode_column(train_df, 'narrative')\n",
        "    dev_df['narrative_onehot'] = dev_df['narrative'].map(narrative_mapping)\n",
        "\n",
        "    # One-hot encode level_1\n",
        "    train_df, level_1_mapping = one_hot_encode_column(train_df, 'level_1')\n",
        "    dev_df['level_1_onehot'] = dev_df['level_1'].map(level_1_mapping)\n",
        "\n",
        "    # One-hot encode level_2\n",
        "    train_df, level_2_mapping = one_hot_encode_column(train_df, 'level_2')\n",
        "    dev_df['level_2_onehot'] = dev_df['level_2'].map(level_2_mapping)\n",
        "\n",
        "\n",
        "    # Combine all embeddings into a single column for training\n",
        "    def combine_embeddings(row):\n",
        "        return np.hstack([\n",
        "            row['narrative_onehot'],\n",
        "            row['level_1_onehot'],\n",
        "            row['level_2_onehot']\n",
        "\n",
        "        ])\n",
        "\n",
        "    # Save mappings for later use\n",
        "    mappings = {\n",
        "        'narrative_mapping': narrative_mapping,\n",
        "        'level_1_mapping': level_1_mapping,\n",
        "        'level_2_mapping': level_2_mapping,\n",
        "    }\n",
        "\n",
        "    return train_df, dev_df, mappings\n",
        "\n",
        "# Process the data\n",
        "train_processed, dev_processed, mappings = process_annotations(expanded_train_annotations, expanded_dev_annotations)\n",
        "\n",
        "# Save the processed data\n",
        "save_processed_data(train_processed, dev_processed, \"/content/drive/MyDrive/NLP_Proj/embedded_article/train_processed.csv\", \"/content/drive/MyDrive/NLP_Proj/embedded_article/dev_processed.csv\")\n",
        "\n",
        "\n",
        "# Display processed data\n",
        "print(train_processed.head())\n",
        "print(dev_processed.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CU0kfG4gWW1T",
        "outputId": "9b648f67-d74c-48de-86b1-994d0dc7ba31",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train saved to /content/drive/MyDrive/NLP_Proj/embedded_article/train_processed.csv\n",
            "Dev saved to /content/drive/MyDrive/NLP_Proj/embedded_article/dev_processed.csv\n",
            "   article_id narrative                         level_1  \\\n",
            "0          12        CC   Criticism of climate movement   \n",
            "1         310     Other                           Other   \n",
            "2         317     Other                           Other   \n",
            "3          16     Other                           Other   \n",
            "4         336     Other                           Other   \n",
            "\n",
            "                                level_2  narrative_onehot  level_1_onehot  \\\n",
            "0   Ad hominem attacks on key activists                 0               0   \n",
            "1                                 Other                 1               1   \n",
            "2                                 Other                 1               1   \n",
            "3                                 Other                 1               1   \n",
            "4                                 Other                 1               1   \n",
            "\n",
            "   level_2_onehot combined_embedding  \n",
            "0               0          [0, 0, 0]  \n",
            "1               1          [1, 1, 1]  \n",
            "2               1          [1, 1, 1]  \n",
            "3               1          [1, 1, 1]  \n",
            "4               1          [1, 1, 1]  \n",
            "   article_id narrative                            level_1  \\\n",
            "0         428       URW   Discrediting the West, Diplomacy   \n",
            "1         428       URW               Discrediting Ukraine   \n",
            "2         410     Other                              Other   \n",
            "3         405        CC      Criticism of climate movement   \n",
            "4         405        CC      Criticism of climate movement   \n",
            "\n",
            "                                             level_2  narrative_onehot  \\\n",
            "0   The West does not care about Ukraine, only ab...                 2   \n",
            "1                  Ukraine is associated with nazism                 2   \n",
            "2                                              Other                 1   \n",
            "3                                              Other                 0   \n",
            "4                       Climate movement is alarmist                 0   \n",
            "\n",
            "   level_1_onehot  level_2_onehot combined_embedding  \n",
            "0              10            41.0  [2.0, 10.0, 41.0]  \n",
            "1               8            25.0   [2.0, 8.0, 25.0]  \n",
            "2               1             1.0    [1.0, 1.0, 1.0]  \n",
            "3               0             3.0    [0.0, 0.0, 3.0]  \n",
            "4               0             4.0    [0.0, 0.0, 4.0]  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(mappings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "goXGNtz8mWTr",
        "outputId": "0e16a06d-1fed-40f5-da2e-e0c4e8e577aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'narrative_mapping': {'CC': 0, 'Other': 1, 'URW': 2}, 'level_1_mapping': {' Criticism of climate movement': 0, 'Other': 1, ' Questioning the measurements and science': 2, ' Speculating war outcomes': 3, ' Praise of Russia': 4, ' Russia is the Victim': 5, ' Amplifying war-related fears': 6, ' Blaming the war on others rather than the invader': 7, ' Discrediting Ukraine': 8, ' Hidden plots by secret schemes of powerful groups': 9, ' Discrediting the West, Diplomacy': 10, ' Downplaying climate change': 11, ' Overpraising the West': 12, ' Criticism of institutions and authorities': 13, ' Distrust towards Media': 14, ' Negative Consequences for the West': 15, ' Controversy about green technologies': 16, ' Climate change is beneficial': 17, ' Criticism of climate policies': 18, ' Amplifying Climate Fears': 19, ' Green policies are geopolitical instruments': 20}, 'level_2_mapping': {' Ad hominem attacks on key activists': 0, 'Other': 1, ' Scientific community is unreliable': 2, ' Other': 3, ' Climate movement is alarmist': 4, ' Russian army is collapsing': 5, ' Russia has international support from a number of countries and people': 6, ' The West is russophobic': 7, ' Russia will also attack other countries': 8, ' The West are the aggressors': 9, ' By continuing the war we risk WWIII': 10, ' Discrediting Ukrainian government and officials and policies': 11, ' Praise of Russian military might': 12, ' Discrediting Ukrainian military': 13, ' The EU is divided': 14, ' Ukraine is the aggressor': 15, ' There is a real possibility that nuclear weapons will be employed': 16, ' Weather suggests the trend is global cooling': 17, ' Temperature increase does not have significant impact': 18, ' Methodologies/metrics used are unreliable/faulty': 19, ' The West has the strongest international support': 20, ' Diplomacy does/will not work': 21, ' Ukraine is a puppet of the West': 22, ' The West is overreacting': 23, ' Western media is an instrument of propaganda': 24, ' Ukraine is associated with nazism': 25, ' Sanctions imposed by Western countries will backfire': 26, ' Criticism of political organizations and figures': 27, ' Climate movement is corrupt': 28, ' Renewable energy is unreliable': 29, ' Renewable energy is costly': 30, ' Climate agenda has hidden motives': 31, ' Blaming global elites': 32, ' Russia is a guarantor of peace and prosperity': 33, ' Russian invasion has strong national support': 34, ' Criticism of national governments': 35, ' Renewable energy is dangerous': 36, ' CO2 concentrations are too small to have an impact': 37, ' CO2 is beneficial': 38, ' Climate policies are only for profit': 39, ' Climate policies have negative impact on the economy': 40, ' The West does not care about Ukraine, only about its interests': 41, ' Russia actions in Ukraine are only self-defence': 42, ' The West belongs in the right side of history': 43, ' Climate cycles are natural': 44, ' Temperature increase is beneficial': 45, ' Amplifying existing fears of global warming': 46, ' Ukrainian army is collapsing': 47, ' Situation in Ukraine is hopeless': 48, ' West is tired of Ukraine': 49, ' Human activities do not impact climate change': 50, ' Data shows no temperature increase': 51, ' Ukraine is a hub for criminal activities': 52, ' Criticism of international entities': 53, ' Green activities are a form of neo-colonialism': 54, ' Climate-related international relations are abusive/exploitative': 55, ' Climate policies are ineffective': 56, ' The West is weak': 57, ' NATO should/will directly intervene': 58, ' Rewriting Ukraine’s history': 59, ' The conflict will increase the Ukrainian refugee flows to Europe': 60, ' UA is anti-RU extremists': 61, ' Ice is not melting': 62, ' Greenhouse effect/carbon dioxide do not drive climate change': 63, ' Ukrainian media cannot be trusted': 64, ' Criticism of the EU': 65, ' Praise of Russian President Vladimir Putin': 66, ' Sea levels are not rising': 67, ' Humans and nature will adapt to the changes': 68, ' Doomsday scenarios for humans': 69}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_processed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqDfbbLixypZ",
        "outputId": "dfd769a5-6e8f-4de5-bfaf-faacf7bd44df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "875"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Test Split"
      ],
      "metadata": {
        "id": "NMILxt6_NDz0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "common_ids = processed_dev_df['article_id'][processed_dev_df['article_id'].isin(dev_processed['article_id'])]\n",
        "print(f\"Number of common article IDs: {len(common_ids)}\")\n",
        "print(\"Common article IDs:\", len(common_ids.unique()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rLUYLQattxS",
        "outputId": "c10c0439-b17c-46a5-8643-21fd3d135f45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of common article IDs: 41\n",
            "Common article IDs: 41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import ast\n",
        "\n",
        "# Load processed datasets\n",
        "processed_train_df = pd.read_csv('/content/drive/MyDrive/NLP/processed_train_articles.csv')\n",
        "processed_dev_df = pd.read_csv('/content/drive/MyDrive/NLP/processed_dev_articles.csv')\n",
        "train_processed = pd.read_csv('/content/drive/MyDrive/NLP/train_processed.csv')\n",
        "dev_processed = pd.read_csv('/content/drive/MyDrive/NLP/dev_processed.csv')\n",
        "\n",
        "# Merge article embeddings with annotation embeddings\n",
        "merged_train = pd.merge(\n",
        "    processed_train_df[['article_id', 'token_based_embedding', 'actants_embedding', 'sentiment_scores_x', 'level2_sentiment_scores_x']],\n",
        "    train_processed[['article_id', 'narrative_onehot', 'level_1_onehot', 'level_2_onehot']],\n",
        "    on='article_id'\n",
        ")\n",
        "\n",
        "merged_dev = pd.merge(\n",
        "    processed_dev_df[['article_id', 'token_based_embedding', 'actants_embedding', 'sentiment_scores_x', 'level2_sentiment_scores_x']],\n",
        "    dev_processed[['article_id', 'narrative_onehot', 'level_1_onehot', 'level_2_onehot']],\n",
        "    on='article_id'\n",
        ")\n",
        "\n",
        "def string_to_array_embeds(embed_str):\n",
        "    try:\n",
        "        # Remove brackets and newline characters, then split into components\n",
        "        embed_str = embed_str.strip(\"[]\").replace(\"\\n\", \"\")\n",
        "        # Convert each component to a float and return as a NumPy array\n",
        "        return np.array([float(x) for x in embed_str.split() if x.strip()])\n",
        "    except (ValueError, TypeError):\n",
        "        # Return an empty array if parsing fails\n",
        "        return np.array([])\n",
        "\n",
        "\n",
        "def string_to_array(embed_str):\n",
        "    try:\n",
        "        # Safely evaluate the string to a Python list\n",
        "        return np.array(ast.literal_eval(embed_str))\n",
        "    except (ValueError, SyntaxError, TypeError):\n",
        "        # Return an empty array if parsing fails\n",
        "        return np.array([])\n",
        "\n",
        "\n",
        "merged_train['token_based_embedding'] = merged_train['token_based_embedding'].apply(string_to_array_embeds)\n",
        "merged_train['actants_embedding'] = merged_train['actants_embedding'].apply(string_to_array_embeds)\n",
        "merged_train['sentiment_scores_x'] = merged_train['sentiment_scores_x'].apply(string_to_array)\n",
        "merged_train['level2_sentiment_scores_x'] = merged_train['level2_sentiment_scores_x'].apply(string_to_array)\n",
        "\n",
        "merged_dev['token_based_embedding'] = merged_dev['token_based_embedding'].apply(string_to_array_embeds)\n",
        "merged_dev['actants_embedding'] = merged_dev['actants_embedding'].apply(string_to_array_embeds)\n",
        "merged_dev['sentiment_scores_x'] = merged_dev['sentiment_scores_x'].apply(string_to_array)\n",
        "merged_dev['level2_sentiment_scores_x'] = merged_dev['level2_sentiment_scores_x'].apply(string_to_array)\n",
        "\n",
        "#merged_train.head()\n",
        "\n",
        "# Pad or truncate arrays to the maximum length\n",
        "def pad_or_truncate(array, target_length):\n",
        "    if len(array) < target_length:\n",
        "        return np.pad(array, (0, target_length - len(array)), mode='constant')\n",
        "    elif len(array) > target_length:\n",
        "        return array[:target_length]\n",
        "    return array\n",
        "\n",
        "# Find maximum lengths for padding\n",
        "max_sentence_length = max(\n",
        "    max(merged_train['token_based_embedding'].apply(len), default=0),\n",
        "    max(merged_dev['token_based_embedding'].apply(len), default=0)\n",
        ")\n",
        "\n",
        "max_actants_length = max(\n",
        "    max(merged_train['actants_embedding'].apply(len), default=0),\n",
        "    max(merged_dev['actants_embedding'].apply(len), default=0)\n",
        ")\n",
        "\n",
        "max_senti_length = max(\n",
        "    max(merged_train['sentiment_scores_x'].apply(len), default=0),\n",
        "    max(merged_dev['sentiment_scores_x'].apply(len), default=0)\n",
        ")\n",
        "\n",
        "max_senti_level2_length = max(\n",
        "    max(merged_train['level2_sentiment_scores_x'].apply(len), default=0),\n",
        "    max(merged_dev['level2_sentiment_scores_x'].apply(len), default=0)\n",
        ")\n",
        "\n",
        "# Pad embeddings for sentence and actants\n",
        "for df in [merged_train, merged_dev]:\n",
        "    df['token_based_embedding'] = df['token_based_embedding'].apply(lambda x: pad_or_truncate(x, max_sentence_length))\n",
        "    df['actants_embedding'] = df['actants_embedding'].apply(lambda x: pad_or_truncate(x, max_actants_length))\n",
        "    df['sentiment_scores_x'] = df['sentiment_scores_x'].apply(lambda x: pad_or_truncate(x, max_senti_length))\n",
        "    df['level2_sentiment_scores_x'] = df['level2_sentiment_scores_x'].apply(lambda x: pad_or_truncate(x, max_senti_level2_length))\n",
        "\n",
        "\n",
        "# Perform stratified splitting for validation and test sets\n",
        "validation_df, test_df = train_test_split(\n",
        "    merged_dev,\n",
        "    test_size=0.5,  # Split evenly between validation and test\n",
        "    stratify=merged_dev['narrative_onehot'],  # Stratify by 'narrative_onehot'\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Prepare training and validation splits\n",
        "X_train = np.hstack([\n",
        "    np.vstack(merged_train['token_based_embedding']),\n",
        "    np.vstack(merged_train['actants_embedding']),\n",
        "    np.vstack(merged_train['sentiment_scores_x'])\n",
        "    #np.vstack(merged_train['level2_sentiment_scores'])\n",
        "])\n",
        "\n",
        "y_train = merged_train[['narrative_onehot', 'level_1_onehot', 'level_2_onehot']].to_dict(orient='list')\n",
        "\n",
        "X_val = np.hstack([\n",
        "    np.vstack(validation_df['token_based_embedding']),\n",
        "    np.vstack(validation_df['actants_embedding']),\n",
        "    np.vstack(validation_df['sentiment_scores_x'])\n",
        "    #np.vstack(validation_df['level2_sentiment_scores'])\n",
        "])\n",
        "\n",
        "y_val = validation_df[['narrative_onehot', 'level_1_onehot', 'level_2_onehot']].to_dict(orient='list')\n",
        "\n",
        "# Prepare test splits\n",
        "X_test = np.hstack([\n",
        "    np.vstack(test_df['token_based_embedding']),\n",
        "    np.vstack(test_df['actants_embedding']),\n",
        "    np.vstack(test_df['sentiment_scores_x'])\n",
        "    #np.vstack(test_df['level2_sentiment_scores'])\n",
        "])\n",
        "\n",
        "y_test = test_df[['narrative_onehot', 'level_1_onehot', 'level_2_onehot']].to_dict(orient='list')\n",
        "\n",
        "# Print train-validation-test split details\n",
        "print(f\"Train: X_train: {X_train.shape}, y_train: {[len(y) for y in y_train.values()]}\")\n",
        "print(f\"Validation: X_val: {X_val.shape}, y_val: {[len(y) for y in y_val.values()]}\")\n",
        "print(f\"Test: X_test: {X_test.shape}, y_test: {[len(y) for y in y_test.values()]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvyrMtxTGpzv",
        "outputId": "93b73995-9d48-4e09-a46a-1fb5d4929290",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: X_train: (875, 1576), y_train: [875, 875, 875]\n",
            "Validation: X_val: (57, 1576), y_val: [57, 57, 57]\n",
            "Test: X_test: (57, 1576), y_test: [57, 57, 57]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unpack target labels for training\n",
        "# Reshape X_train, X_val, and X_test to remove the extra dimension\n",
        "X_train = X_train.reshape(X_train.shape[0], -1)\n",
        "X_val = X_val.reshape(X_val.shape[0], -1)\n",
        "X_test = X_test.reshape(X_test.shape[0], -1)\n",
        "\n",
        "print(f\"X_train shape: {X_train.shape}\")  # Should be (526, 1536)\n",
        "print(f\"X_val shape: {X_val.shape}\")      # Should be (14, 1536)\n",
        "print(f\"X_test shape: {X_test.shape}\")    # Should be (57, 1536)\n",
        "\n",
        "y_train_narrative = np.array(y_train['narrative_onehot'])\n",
        "y_train_level_1 = np.array(y_train['level_1_onehot'])\n",
        "y_train_level_2 = np.array(y_train['level_2_onehot'])\n",
        "\n",
        "# Unpack target labels for validation\n",
        "y_val_narrative = np.array(y_val['narrative_onehot'])\n",
        "y_val_level_1 = np.array(y_val['level_1_onehot'])\n",
        "y_val_level_2 = np.array(y_val['level_2_onehot'])\n",
        "\n",
        "# Unpack target labels for testing\n",
        "y_test_narrative = np.array(y_test['narrative_onehot'])\n",
        "y_test_level_1 = np.array(y_test['level_1_onehot'])\n",
        "y_test_level_2 = np.array(y_test['level_2_onehot'])\n",
        "\n",
        "# Print the shapes to verify\n",
        "print(f\"y_train_narrative shape: {y_train_narrative.shape}\")\n",
        "print(f\"y_train_level_1 shape: {y_train_level_1.shape}\")\n",
        "print(f\"y_train_level_2 shape: {y_train_level_2.shape}\")\n",
        "\n",
        "print(f\"y_val_narrative shape: {y_val_narrative.shape}\")\n",
        "print(f\"y_val_level_1 shape: {y_val_level_1.shape}\")\n",
        "print(f\"y_val_level_2 shape: {y_val_level_2.shape}\")\n",
        "\n",
        "print(f\"y_test_narrative shape: {y_test_narrative.shape}\")\n",
        "print(f\"y_test_level_1 shape: {y_test_level_1.shape}\")\n",
        "print(f\"y_test_level_2 shape: {y_test_level_2.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zROxnI6ZC3s-",
        "outputId": "baa71865-19af-4189-d4c2-58aa684f077d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (875, 1576)\n",
            "X_val shape: (57, 1576)\n",
            "X_test shape: (57, 1576)\n",
            "y_train_narrative shape: (875,)\n",
            "y_train_level_1 shape: (875,)\n",
            "y_train_level_2 shape: (875,)\n",
            "y_val_narrative shape: (57,)\n",
            "y_val_level_1 shape: (57,)\n",
            "y_val_level_2 shape: (57,)\n",
            "y_test_narrative shape: (57,)\n",
            "y_test_level_1 shape: (57,)\n",
            "y_test_level_2 shape: (57,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Class Imbalance"
      ],
      "metadata": {
        "id": "82nxFIqqWQJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Plotting function\n",
        "def plot_class_distribution(title, class_counts):\n",
        "    labels = list(class_counts.keys())\n",
        "    values = list(class_counts.values())\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.bar(labels, values, alpha=0.75)\n",
        "    plt.title(f\"{title} Class Distribution\")\n",
        "    plt.xlabel(\"Classes\")\n",
        "    plt.ylabel(\"Counts\")\n",
        "    plt.xticks(labels)\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "    plt.show()\n",
        "\n",
        "# Visualize distributions\n",
        "plot_class_distribution(\"Training Narrative\", train_class_counts_narrative)\n",
        "plot_class_distribution(\"Training Level 1\", train_class_counts_level_1)\n",
        "plot_class_distribution(\"Training Level 2\", train_class_counts_level_2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EaquCISizMCL",
        "outputId": "7bb4ddd6-6272-470f-e03c-acd764100b7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformer Based Attention"
      ],
      "metadata": {
        "id": "UF23pC2yoNFZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n",
        "\n",
        "# Function to replace NaN with -1 in the labels\n",
        "def replace_nan_with_negative_one(array):\n",
        "    return np.where(np.isnan(array), -1, array)\n",
        "\n",
        "# Replace NaN values in all levels with -1\n",
        "y_train_level2 = replace_nan_with_negative_one(np.array(y_train_level_2))\n",
        "y_val_level2 = replace_nan_with_negative_one(np.array(y_val_level_2))\n",
        "y_test_level2 = replace_nan_with_negative_one(np.array(y_test_level_2))\n",
        "\n",
        "# Narrative Level\n",
        "y_train_narrative_onehot = to_categorical(y_train_narrative, num_classes=len(np.unique(y_train_narrative)))\n",
        "y_val_narrative_onehot = to_categorical(y_val_narrative, num_classes=len(np.unique(y_train_narrative)))\n",
        "y_test_narrative_onehot = to_categorical(y_test_narrative, num_classes=len(np.unique(y_train_narrative)))\n",
        "\n",
        "narrative_class_weights = compute_class_weight('balanced', classes=np.unique(y_train_narrative), y=y_train_narrative)\n",
        "narrative_class_weights = dict(enumerate(narrative_class_weights))\n",
        "\n",
        "# Level 1\n",
        "y_train_level1_onehot = to_categorical(y_train_level_1, num_classes=len(np.unique(y_train_level_1)))\n",
        "y_val_level1_onehot = to_categorical(y_val_level_1, num_classes=len(np.unique(y_train_level_1)))\n",
        "y_test_level1_onehot = to_categorical(y_test_level_1, num_classes=len(np.unique(y_train_level_1)))\n",
        "\n",
        "level1_class_weights = compute_class_weight('balanced', classes=np.unique(y_train_level_1), y=y_train_level_1)\n",
        "level1_class_weights = dict(enumerate(level1_class_weights))\n",
        "\n",
        "# Level 2 (including -1 as a separate class)\n",
        "y_train_level2_onehot = to_categorical(y_train_level2, num_classes=len(np.unique(y_train_level2)))\n",
        "y_val_level2_onehot = to_categorical(y_val_level2, num_classes=len(np.unique(y_train_level2)))\n",
        "y_test_level2_onehot = to_categorical(y_test_level2, num_classes=len(np.unique(y_train_level2)))\n",
        "\n",
        "level2_class_weights = compute_class_weight('balanced', classes=np.unique(y_train_level_2), y=y_train_level_2)\n",
        "level2_class_weights = dict(enumerate(level2_class_weights))\n",
        "\n",
        "# Print shapes for verification\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"y_train_narrative_onehot shape: {y_train_narrative_onehot.shape}\")\n",
        "print(f\"y_val_narrative_onehot shape: {y_val_narrative_onehot.shape}\")\n",
        "print(f\"y_test_narrative_onehot shape: {y_test_narrative_onehot.shape}\")\n",
        "\n",
        "print(f\"y_train_level1_onehot shape: {y_train_level1_onehot.shape}\")\n",
        "print(f\"y_val_level1_onehot shape: {y_val_level1_onehot.shape}\")\n",
        "print(f\"y_test_level1_onehot shape: {y_test_level1_onehot.shape}\")\n",
        "\n",
        "print(f\"y_train_level2_onehot shape: {y_train_level2_onehot.shape}\")\n",
        "print(f\"y_val_level2_onehot shape: {y_val_level2_onehot.shape}\")\n",
        "print(f\"y_test_level2_onehot shape: {y_test_level2_onehot.shape}\")\n",
        "\n",
        "# Print class weights\n",
        "print(\"\\nNarrative Class Weights:\", narrative_class_weights)\n",
        "print(\"Level 1 Class Weights:\", level1_class_weights)\n",
        "print(\"Level 2 Class Weights:\", level2_class_weights)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDGvLjaYVHfp",
        "outputId": "b67bfce7-4fdb-419f-fc47-308a7fda47b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (875, 1576)\n",
            "y_train_narrative_onehot shape: (875, 3)\n",
            "y_val_narrative_onehot shape: (57, 3)\n",
            "y_test_narrative_onehot shape: (57, 3)\n",
            "y_train_level1_onehot shape: (875, 21)\n",
            "y_val_level1_onehot shape: (57, 21)\n",
            "y_test_level1_onehot shape: (57, 21)\n",
            "y_train_level2_onehot shape: (875, 70)\n",
            "y_val_level2_onehot shape: (57, 70)\n",
            "y_test_level2_onehot shape: (57, 70)\n",
            "\n",
            "Narrative Class Weights: {0: 0.8169934640522876, 1: 1.7258382642998027, 2: 0.8357211079274116}\n",
            "Level 1 Class Weights: {0: 0.7309941520467836, 1: 0.2465483234714004, 2: 1.3440860215053763, 3: 1.893939393939394, 4: 2.192982456140351, 5: 1.9841269841269842, 6: 0.6944444444444444, 7: 1.1904761904761905, 8: 0.7716049382716049, 9: 0.6944444444444444, 10: 0.49019607843137253, 11: 1.4367816091954022, 12: 3.787878787878788, 13: 0.49603174603174605, 14: 3.2051282051282053, 15: 2.6041666666666665, 16: 1.2254901960784315, 17: 8.333333333333334, 18: 0.7183908045977011, 19: 5.9523809523809526, 20: 8.333333333333334}\n",
            "Level 2 Class Weights: {0: 0.78125, 1: 0.07396449704142012, 2: 0.9615384615384616, 3: 0.09689922480620156, 4: 0.6578947368421053, 5: 3.125, 6: 6.25, 7: 1.5625, 8: 1.0416666666666667, 9: 0.46296296296296297, 10: 0.8928571428571429, 11: 0.7352941176470589, 12: 1.3888888888888888, 13: 2.0833333333333335, 14: 2.0833333333333335, 15: 1.5625, 16: 0.625, 17: 12.5, 18: 6.25, 19: 1.3888888888888888, 20: 4.166666666666667, 21: 0.8928571428571429, 22: 0.9615384615384616, 23: 4.166666666666667, 24: 1.0416666666666667, 25: 1.5625, 26: 1.25, 27: 0.390625, 28: 1.5625, 29: 1.3888888888888888, 30: 1.25, 31: 0.5434782608695652, 32: 0.78125, 33: 4.166666666666667, 34: 6.25, 35: 0.3787878787878788, 36: 3.125, 37: 2.5, 38: 4.166666666666667, 39: 1.3888888888888888, 40: 0.5681818181818182, 41: 0.8928571428571429, 42: 2.5, 43: 1.5625, 44: 2.5, 45: 6.25, 46: 2.5, 47: 1.5625, 48: 2.5, 49: 1.1363636363636365, 50: 3.125, 51: 6.25, 52: 3.125, 53: 1.0416666666666667, 54: 4.166666666666667, 55: 6.25, 56: 0.8928571428571429, 57: 1.1363636363636365, 58: 1.7857142857142858, 59: 12.5, 60: 6.25, 61: 2.5, 62: 6.25, 63: 6.25, 64: 12.5, 65: 4.166666666666667, 66: 12.5, 67: 12.5, 68: 12.5, 69: 12.5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Ensure y_train_narrative is correctly sourced and matches X_train\n",
        "y_train_narrative = np.array(y_train_narrative)  # Ensure it's a NumPy array\n",
        "y_train_narrative_onehot = to_categorical(y_train_narrative, num_classes=len(np.unique(y_train_narrative)))\n",
        "\n",
        "# Repeat for validation and test sets\n",
        "y_val_narrative = np.array(y_val_narrative)  # Ensure it's a NumPy array\n",
        "y_val_narrative_onehot = to_categorical(y_val_narrative, num_classes=len(np.unique(y_train_narrative)))\n",
        "\n",
        "y_test_narrative = np.array(y_test_narrative)  # Ensure it's a NumPy array\n",
        "y_test_narrative_onehot = to_categorical(y_test_narrative, num_classes=len(np.unique(y_train_narrative)))\n",
        "\n",
        "# Check shapes again\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"y_train_narrative_onehot shape: {y_train_narrative_onehot.shape}\")\n",
        "print(f\"X_val shape: {X_val.shape}\")\n",
        "print(f\"y_val_narrative_onehot shape: {y_val_narrative_onehot.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_test_narrative_onehot shape: {y_test_narrative_onehot.shape}\")\n",
        "\n",
        "\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Compute class weights for the narrative labels\n",
        "unique_classes = np.unique(y_train_narrative)\n",
        "class_weights = compute_class_weight('balanced', classes=unique_classes, y=y_train_narrative)\n",
        "narrative_class_weights = dict(enumerate(class_weights))\n",
        "\n",
        "print(\"Narrative Class Weights:\", narrative_class_weights)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cD1-n1Yu0VS-",
        "outputId": "75bf9654-03ae-4e27-88aa-bd290becd0ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (875, 1576)\n",
            "y_train_narrative_onehot shape: (875, 3)\n",
            "X_val shape: (57, 1576)\n",
            "y_val_narrative_onehot shape: (57, 3)\n",
            "X_test shape: (57, 1576)\n",
            "y_test_narrative_onehot shape: (57, 3)\n",
            "Narrative Class Weights: {0: 0.8169934640522876, 1: 1.7258382642998027, 2: 0.8357211079274116}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "\n",
        "from tensorflow.keras.layers import (\n",
        "    Input,\n",
        "    Dense,\n",
        "    Dropout,\n",
        "    MultiHeadAttention,\n",
        "    LayerNormalization,\n",
        "    GlobalAveragePooling1D,\n",
        "    Flatten,\n",
        "    Embedding,\n",
        "    Add,\n",
        ")\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "\n",
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "    def __init__(self, input_dim, embed_dim):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.embed_dim = embed_dim\n",
        "        self.embedding = Embedding(input_dim=input_dim, output_dim=embed_dim)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Create a range for positional indices\n",
        "        positions = tf.range(self.input_dim, dtype=tf.int32)\n",
        "        positional_encoding = self.embedding(positions)  # Positional embeddings\n",
        "        positional_encoding = tf.expand_dims(positional_encoding, axis=0)  # Add batch dimension\n",
        "        positional_encoding = tf.repeat(positional_encoding, repeats=tf.shape(inputs)[0], axis=0)  # Repeat for batch size\n",
        "        return positional_encoding\n",
        "\n",
        "\n",
        "def create_transformer_based_model(input_shape, num_classes, num_transformer_layers=2):\n",
        "    inputs = Input(shape=(input_shape,))  # Input feature vector (e.g., embeddings)\n",
        "\n",
        "    # Project input to a lower dimension (matching feedforward dimensions)\n",
        "    projected_inputs = Dense(\n",
        "        256, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(0.01)\n",
        "    )(inputs)  # Project input features to 256 dimensions\n",
        "    reshaped_inputs = tf.keras.layers.Reshape((1, 256))(projected_inputs)  # Reshape for Multi-Head Attention\n",
        "\n",
        "    # Positional Encoding Layer\n",
        "    positional_encoding_layer = PositionalEncoding(input_dim=input_shape, embed_dim=256)\n",
        "    positional_encoding = positional_encoding_layer(reshaped_inputs)\n",
        "\n",
        "    # Add Positional Encoding\n",
        "    reshaped_inputs_with_positional = Add()([reshaped_inputs, positional_encoding])  # Add positional information\n",
        "\n",
        "    # Stacked Transformer Layers\n",
        "    transformer_output = reshaped_inputs_with_positional\n",
        "    for _ in range(num_transformer_layers):\n",
        "        attention_output = MultiHeadAttention(num_heads=8, key_dim=32)(\n",
        "            transformer_output, transformer_output\n",
        "        )\n",
        "        attention_output = LayerNormalization(epsilon=1e-6)(\n",
        "            attention_output + transformer_output\n",
        "        )  # Residual connection\n",
        "\n",
        "        # Feedforward Network with L2 Regularization and Dropout\n",
        "        ff_output = Dense(\n",
        "            256,\n",
        "            activation=\"relu\",\n",
        "            kernel_regularizer=tf.keras.regularizers.l2(0.01),\n",
        "        )(attention_output)\n",
        "        ff_output = Dropout(0.4)(ff_output)  # Dropout Regularization\n",
        "        transformer_output = LayerNormalization(epsilon=1e-6)(\n",
        "            ff_output + attention_output\n",
        "        )  # Residual connection\n",
        "        # Batch Normalization after Dense layers\n",
        "        ff_output = Dense(\n",
        "            256,\n",
        "            activation=\"relu\",\n",
        "            kernel_regularizer=tf.keras.regularizers.l2(0.01),\n",
        "        )(attention_output)\n",
        "        ff_output = BatchNormalization()(ff_output)  # Add Batch Normalization\n",
        "        ff_output = Dropout(0.4)(ff_output)\n",
        "\n",
        "    # Global Pooling Layer (applied after all transformer layers)\n",
        "    pooled_output = GlobalAveragePooling1D()(transformer_output)  # Collapse sequence dimension\n",
        "\n",
        "    # Dropout for Regularization\n",
        "    pooled_output = Dropout(0.5)(pooled_output)\n",
        "\n",
        "    # Output Layer for Classification with Regularization\n",
        "    outputs = Dense(\n",
        "        num_classes,\n",
        "        activation=\"softmax\",\n",
        "        kernel_regularizer=tf.keras.regularizers.l2(0.01),\n",
        "        )(pooled_output)\n",
        "\n",
        "    # Define Model\n",
        "    model = Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "\n",
        "# Apply SMOTE for Oversampling Minority Classes\n",
        "def apply_smote(X, y):\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "    return X_resampled, y_resampled\n",
        "\n",
        "\n",
        "# Oversample the training data using SMOTE\n",
        "X_train_resampled, y_train_narrative_resampled = apply_smote(X_train, y_train_narrative)\n",
        "\n",
        "# One-hot encode the resampled target labels\n",
        "y_train_narrative_onehot_resampled = tf.keras.utils.to_categorical(\n",
        "    y_train_narrative_resampled, num_classes=len(np.unique(y_train_narrative))\n",
        ")\n",
        "\n",
        "# Calculate class weights (optional, may not be needed after SMOTE)\n",
        "class_weights = compute_class_weight(\n",
        "    'balanced', classes=np.unique(y_train_narrative_resampled), y=y_train_narrative_resampled\n",
        ")\n",
        "class_weights = {i: weight for i, weight in enumerate(class_weights)}\n",
        "\n",
        "# Learning Rate Scheduler\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=0.001,  # Higher initial learning rate\n",
        "    decay_steps=500,             # Faster decay\n",
        "    decay_rate=0.9\n",
        ")\n",
        "\n",
        "# Early Stopping Callback\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    patience=5,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "# Model Parameters\n",
        "input_shape = X_train.shape[1]  # Number of features in the input\n",
        "num_classes_narrative = len(np.unique(y_train_narrative))  # Number of narrative classes\n",
        "\n",
        "# Create the model with regularization\n",
        "narrative_model = create_transformer_based_model(input_shape=input_shape, num_classes=num_classes_narrative)\n",
        "\n",
        "# Compile the model\n",
        "narrative_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "# Train the model with Early Stopping\n",
        "history = narrative_model.fit(\n",
        "    X_train_resampled,\n",
        "    y_train_narrative_onehot_resampled,\n",
        "    validation_data=(X_val, y_val_narrative_onehot),\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    verbose=1,\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = narrative_model.evaluate(X_test, y_test_narrative_onehot, verbose=1)\n",
        "\n",
        "# Predict on the test set\n",
        "y_test_preds = narrative_model.predict(X_test, batch_size=64)\n",
        "y_test_pred_classes = np.argmax(y_test_preds, axis=1)  # Convert probabilities to class labels\n",
        "\n",
        "# True class labels\n",
        "y_test_true_classes = np.argmax(y_test_narrative_onehot, axis=1)\n",
        "\n",
        "# Calculate metrics\n",
        "test_accuracy = accuracy_score(y_test_true_classes, y_test_pred_classes)\n",
        "f1_macro = f1_score(y_test_true_classes, y_test_pred_classes, average=\"macro\")\n",
        "f1_weighted = f1_score(y_test_true_classes, y_test_pred_classes, average=\"weighted\")\n",
        "\n",
        "# Print results\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"F1-Score (Macro): {f1_macro:.4f}\")\n",
        "print(f\"F1-Score (Weighted): {f1_weighted:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogyW9q5DoRXh",
        "outputId": "67a687cc-9a67-4e2a-c7f5-8bc4ee77474e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 976ms/step - accuracy: 0.3970 - loss: 9.6114 - val_accuracy: 0.8947 - val_loss: 5.0048\n",
            "Epoch 2/20\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 534ms/step - accuracy: 0.5619 - loss: 4.8749 - val_accuracy: 0.8421 - val_loss: 3.1909\n",
            "Epoch 3/20\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 565ms/step - accuracy: 0.6305 - loss: 3.4137 - val_accuracy: 0.9474 - val_loss: 2.2854\n",
            "Epoch 4/20\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 603ms/step - accuracy: 0.7397 - loss: 2.4702 - val_accuracy: 0.9298 - val_loss: 1.7624\n",
            "Epoch 5/20\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 597ms/step - accuracy: 0.7584 - loss: 1.9929 - val_accuracy: 0.9298 - val_loss: 1.4875\n",
            "Epoch 6/20\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 579ms/step - accuracy: 0.7399 - loss: 1.7608 - val_accuracy: 0.8772 - val_loss: 1.4211\n",
            "Epoch 7/20\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 586ms/step - accuracy: 0.7838 - loss: 1.4822 - val_accuracy: 0.8772 - val_loss: 1.2139\n",
            "Epoch 8/20\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 588ms/step - accuracy: 0.7972 - loss: 1.2524 - val_accuracy: 0.9474 - val_loss: 1.0294\n",
            "Epoch 9/20\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 600ms/step - accuracy: 0.8010 - loss: 1.2329 - val_accuracy: 0.8947 - val_loss: 0.9552\n",
            "Epoch 10/20\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 590ms/step - accuracy: 0.8051 - loss: 1.0689 - val_accuracy: 0.8772 - val_loss: 0.8201\n",
            "Epoch 11/20\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 585ms/step - accuracy: 0.8459 - loss: 0.9149 - val_accuracy: 0.7719 - val_loss: 1.0630\n",
            "Epoch 12/20\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 588ms/step - accuracy: 0.8828 - loss: 0.7786 - val_accuracy: 0.8772 - val_loss: 0.8104\n",
            "Epoch 13/20\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 597ms/step - accuracy: 0.8952 - loss: 0.7069 - val_accuracy: 0.8947 - val_loss: 0.8050\n",
            "Epoch 14/20\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 591ms/step - accuracy: 0.8936 - loss: 0.6825 - val_accuracy: 0.8772 - val_loss: 0.8023\n",
            "Epoch 15/20\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 600ms/step - accuracy: 0.8832 - loss: 0.6850 - val_accuracy: 0.8421 - val_loss: 0.7366\n",
            "Epoch 16/20\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 589ms/step - accuracy: 0.8834 - loss: 0.6164 - val_accuracy: 0.8070 - val_loss: 1.0238\n",
            "Epoch 17/20\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 589ms/step - accuracy: 0.8701 - loss: 0.6423 - val_accuracy: 0.9474 - val_loss: 0.5312\n",
            "Epoch 18/20\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 590ms/step - accuracy: 0.9445 - loss: 0.4411 - val_accuracy: 0.6842 - val_loss: 1.7909\n",
            "Epoch 19/20\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 598ms/step - accuracy: 0.9152 - loss: 0.5479 - val_accuracy: 0.7895 - val_loss: 1.1601\n",
            "Epoch 20/20\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 590ms/step - accuracy: 0.9296 - loss: 0.4510 - val_accuracy: 0.7544 - val_loss: 1.2374\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.9324 - loss: 0.5290\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
            "Test Accuracy: 0.9298\n",
            "F1-Score (Macro): 0.8077\n",
            "F1-Score (Weighted): 0.9140\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get predictions for the first 5 test samples\n",
        "num_samples = 10\n",
        "sample_inputs = X_test[:num_samples]\n",
        "sample_preds = narrative_model.predict(sample_inputs)\n",
        "sample_pred_classes = np.argmax(sample_preds, axis=1)\n",
        "sample_true_classes = np.argmax(y_test_narrative_onehot[:num_samples], axis=1)\n",
        "\n",
        "# Print results for each sample\n",
        "for i in range(num_samples):\n",
        "    print(f\"Sample Index: {i}\")\n",
        "    print(f\"Predicted Class: {sample_pred_classes[i]}\")\n",
        "    print(f\"True Class: {sample_true_classes[i]}\")\n",
        "    print(\"---\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgO3xivEDuFG",
        "outputId": "d1f99ac2-6483-4f32-f04c-04dbc917a724"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "Sample Index: 0\n",
            "Predicted Class: 2\n",
            "True Class: 1\n",
            "---\n",
            "Sample Index: 1\n",
            "Predicted Class: 1\n",
            "True Class: 0\n",
            "---\n",
            "Sample Index: 2\n",
            "Predicted Class: 0\n",
            "True Class: 0\n",
            "---\n",
            "Sample Index: 3\n",
            "Predicted Class: 2\n",
            "True Class: 2\n",
            "---\n",
            "Sample Index: 4\n",
            "Predicted Class: 0\n",
            "True Class: 0\n",
            "---\n",
            "Sample Index: 5\n",
            "Predicted Class: 0\n",
            "True Class: 0\n",
            "---\n",
            "Sample Index: 6\n",
            "Predicted Class: 2\n",
            "True Class: 2\n",
            "---\n",
            "Sample Index: 7\n",
            "Predicted Class: 2\n",
            "True Class: 2\n",
            "---\n",
            "Sample Index: 8\n",
            "Predicted Class: 0\n",
            "True Class: 0\n",
            "---\n",
            "Sample Index: 9\n",
            "Predicted Class: 0\n",
            "True Class: 0\n",
            "---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combined"
      ],
      "metadata": {
        "id": "wJrX1GuULLPc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import (\n",
        "    Embedding, Concatenate, Input, Dense, Dropout, BatchNormalization, Reshape,\n",
        "    MultiHeadAttention, LayerNormalization, GlobalAveragePooling1D, Add\n",
        ")\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "from tensorflow.keras.regularizers import l2\n",
        "import tensorflow as tf\n",
        "\n",
        "def create_regularized_hierarchical_model(\n",
        "    input_shape, num_narrative_classes, num_level1_classes, num_level2_classes,\n",
        "    num_transformer_layers=3, num_heads=8,  # Reduce transformer layers and heads\n",
        "    hidden_units=128, shared_hidden_units=256,  # Reduce hidden units\n",
        "    narrative_embedding_dim=50, level1_embedding_dim=16,  # Reduce embedding dimensions\n",
        "    attention_dropout_rate=0.3, dropout_rate=0.5, l2_lambda=0.02  # Stronger regularization\n",
        "):\n",
        "    # Inputs\n",
        "    features_input = Input(shape=(input_shape,), name=\"features_input\")\n",
        "    narrative_input = Input(shape=(1,), name=\"narrative_input\")\n",
        "    level1_input = Input(shape=(1,), name=\"level1_input\")\n",
        "\n",
        "    # Narrative Embedding\n",
        "    narrative_embedding = Embedding(\n",
        "        input_dim=num_narrative_classes,\n",
        "        output_dim=narrative_embedding_dim,\n",
        "        embeddings_initializer=\"he_normal\",\n",
        "        input_length=1\n",
        "    )(narrative_input)\n",
        "    narrative_embedding = Reshape((narrative_embedding_dim,))(narrative_embedding)\n",
        "\n",
        "    # Level 1 Embedding\n",
        "    level1_embedding = Embedding(\n",
        "        input_dim=num_level1_classes,\n",
        "        output_dim=level1_embedding_dim,\n",
        "        embeddings_initializer=\"he_normal\",\n",
        "        input_length=1\n",
        "    )(level1_input)\n",
        "    level1_embedding = Reshape((level1_embedding_dim,))(level1_embedding)\n",
        "\n",
        "    # **Narrative Prediction**\n",
        "    narrative_features = Dense(\n",
        "        hidden_units, activation=\"relu\", kernel_initializer=\"he_normal\",\n",
        "        kernel_regularizer=l2(l2_lambda)\n",
        "    )(features_input)\n",
        "    narrative_features = BatchNormalization()(narrative_features)\n",
        "    narrative_features = Dropout(dropout_rate)(narrative_features)\n",
        "    narrative_output = Dense(\n",
        "        num_narrative_classes, activation=\"softmax\", kernel_regularizer=l2(l2_lambda),\n",
        "        name=\"narrative_output\"\n",
        "    )(narrative_features)\n",
        "\n",
        "    # **Level 1 Prediction**\n",
        "    level1_features = Concatenate()([features_input, narrative_embedding])\n",
        "    level1_shared_features = Dense(\n",
        "        shared_hidden_units, activation=\"relu\", kernel_initializer=\"he_normal\",\n",
        "        kernel_regularizer=l2(l2_lambda)\n",
        "    )(level1_features)\n",
        "    level1_shared_features = BatchNormalization()(level1_shared_features)\n",
        "    level1_shared_features = Dropout(dropout_rate)(level1_shared_features)\n",
        "    level1_shared_features = Reshape((1, shared_hidden_units))(level1_shared_features)\n",
        "\n",
        "    # Transformer for Level 1\n",
        "    transformer_output_level1 = level1_shared_features\n",
        "    for _ in range(num_transformer_layers):\n",
        "        attention_output = MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=shared_hidden_units // num_heads,\n",
        "            dropout=attention_dropout_rate\n",
        "        )(transformer_output_level1, transformer_output_level1)\n",
        "        attention_output = LayerNormalization(epsilon=1e-6)(Add()([attention_output, transformer_output_level1]))\n",
        "\n",
        "        ff_output = Dense(\n",
        "            shared_hidden_units, activation=\"relu\", kernel_initializer=\"he_normal\",\n",
        "            kernel_regularizer=l2(l2_lambda)\n",
        "        )(attention_output)\n",
        "        ff_output = Dropout(dropout_rate)(ff_output)\n",
        "        transformer_output_level1 = LayerNormalization(epsilon=1e-6)(Add()([ff_output, attention_output]))\n",
        "\n",
        "    pooled_level1_output = GlobalAveragePooling1D()(transformer_output_level1)\n",
        "    pooled_level1_output = Dropout(dropout_rate)(pooled_level1_output)\n",
        "    level1_output = Dense(\n",
        "        num_level1_classes, activation=\"softmax\", kernel_regularizer=l2(l2_lambda),\n",
        "        name=\"level1_output\"\n",
        "    )(pooled_level1_output)\n",
        "\n",
        "    # **Level 2 Prediction**\n",
        "    level2_features = Concatenate()([features_input, narrative_embedding, level1_embedding])\n",
        "    level2_shared_features = Dense(\n",
        "        shared_hidden_units, activation=\"relu\", kernel_initializer=\"he_normal\",\n",
        "        kernel_regularizer=l2(l2_lambda)\n",
        "    )(level2_features)\n",
        "    level2_shared_features = BatchNormalization()(level2_shared_features)\n",
        "    level2_shared_features = Dropout(dropout_rate)(level2_shared_features)\n",
        "    level2_shared_features = Reshape((1, shared_hidden_units))(level2_shared_features)\n",
        "\n",
        "    # Transformer for Level 2\n",
        "    transformer_output_level2 = level2_shared_features\n",
        "    for _ in range(num_transformer_layers):\n",
        "        attention_output = MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=shared_hidden_units // num_heads,\n",
        "            dropout=attention_dropout_rate\n",
        "        )(transformer_output_level2, transformer_output_level2)\n",
        "        attention_output = LayerNormalization(epsilon=1e-6)(Add()([attention_output, transformer_output_level2]))\n",
        "\n",
        "        ff_output = Dense(\n",
        "            shared_hidden_units, activation=\"relu\", kernel_initializer=\"he_normal\",\n",
        "            kernel_regularizer=l2(l2_lambda)\n",
        "        )(attention_output)\n",
        "        ff_output = Dropout(dropout_rate)(ff_output)\n",
        "        transformer_output_level2 = LayerNormalization(epsilon=1e-6)(Add()([ff_output, attention_output]))\n",
        "\n",
        "    pooled_level2_output = GlobalAveragePooling1D()(transformer_output_level2)\n",
        "    pooled_level2_output = Dropout(dropout_rate)(pooled_level2_output)\n",
        "    level2_output = Dense(\n",
        "        num_level2_classes, activation=\"softmax\", kernel_regularizer=l2(l2_lambda),\n",
        "        name=\"level2_output\"\n",
        "    )(pooled_level2_output)\n",
        "\n",
        "    # Define the Model\n",
        "    model = Model(\n",
        "        inputs=[features_input, narrative_input, level1_input],\n",
        "        outputs=[narrative_output, level1_output, level2_output]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "\n",
        "\n",
        "# **Learning Rate Scheduler**\n",
        "lr_schedule = ExponentialDecay(\n",
        "    initial_learning_rate=1e-3,\n",
        "    decay_steps=10000,\n",
        "    decay_rate=0.9\n",
        ")\n",
        "\n",
        "# Compile the Model\n",
        "model = create_improved_hierarchical_model(\n",
        "    input_shape=X_train.shape[1],\n",
        "    num_narrative_classes=len(np.unique(y_train_narrative)),\n",
        "    num_level1_classes=len(np.unique(y_train_level_1)),\n",
        "    num_level2_classes=len(np.unique(y_train_level_2))\n",
        ")\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=lr_schedule),\n",
        "    loss=[\"categorical_crossentropy\", \"categorical_crossentropy\", \"categorical_crossentropy\"],\n",
        "    metrics=[\"accuracy\", \"accuracy\", \"accuracy\"]\n",
        ")\n",
        "\n",
        "# Train the Model\n",
        "history = model.fit(\n",
        "    X_train_combined,\n",
        "    [y_train_narrative_onehot, y_train_level1_onehot, y_train_level2_onehot],\n",
        "    validation_data=(X_val_combined, [y_val_narrative_onehot, y_val_level1_onehot, y_val_level2_onehot]),\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    verbose=1,\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "# Evaluate the Model\n",
        "test_loss, narrative_loss, level1_loss, level2_loss, narrative_acc, level1_acc, level2_acc = model.evaluate(\n",
        "    X_test_combined, [y_test_narrative_onehot, y_test_level1_onehot, y_test_level2_onehot]\n",
        ")\n",
        "\n",
        "print(f\"Test Accuracy (Narrative): {narrative_acc:.4f}\")\n",
        "print(f\"Test Accuracy (Level 1): {level1_acc:.4f}\")\n",
        "print(f\"Test Accuracy (Level 2): {level2_acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFVFcq9zcTwl",
        "outputId": "d8415356-116f-4393-822d-d4172cfd7b66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (None, 12, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 2s/step - level1_output_accuracy: 0.2246 - level1_output_loss: 3.2315 - level2_output_accuracy: 0.1961 - level2_output_loss: 4.2650 - loss: 150.2729 - narrative_output_accuracy: 0.6428 - narrative_output_loss: 0.8653 - val_level1_output_accuracy: 0.2456 - val_level1_output_loss: 2.6360 - val_level2_output_accuracy: 0.1930 - val_level2_output_loss: 3.4905 - val_loss: 123.4929 - val_narrative_output_accuracy: 0.4211 - val_narrative_output_loss: 0.9873\n",
            "Epoch 2/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 43ms/step - level1_output_accuracy: 0.3050 - level1_output_loss: 2.3596 - level2_output_accuracy: 0.2829 - level2_output_loss: 3.1536 - loss: 114.3942 - narrative_output_accuracy: 0.8804 - narrative_output_loss: 0.2941 - val_level1_output_accuracy: 0.2105 - val_level1_output_loss: 2.3130 - val_level2_output_accuracy: 0.2456 - val_level2_output_loss: 3.3595 - val_loss: 92.8550 - val_narrative_output_accuracy: 0.4211 - val_narrative_output_loss: 0.8404\n",
            "Epoch 3/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - level1_output_accuracy: 0.2899 - level1_output_loss: 2.3780 - level2_output_accuracy: 0.2780 - level2_output_loss: 3.1335 - loss: 86.0119 - narrative_output_accuracy: 0.9043 - narrative_output_loss: 0.2691 - val_level1_output_accuracy: 0.1930 - val_level1_output_loss: 2.3481 - val_level2_output_accuracy: 0.2456 - val_level2_output_loss: 3.4206 - val_loss: 69.5841 - val_narrative_output_accuracy: 0.6667 - val_narrative_output_loss: 0.6642\n",
            "Epoch 4/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - level1_output_accuracy: 0.3339 - level1_output_loss: 2.1264 - level2_output_accuracy: 0.3069 - level2_output_loss: 2.8598 - loss: 63.6730 - narrative_output_accuracy: 0.9101 - narrative_output_loss: 0.2416 - val_level1_output_accuracy: 0.2105 - val_level1_output_loss: 2.2476 - val_level2_output_accuracy: 0.1404 - val_level2_output_loss: 3.2424 - val_loss: 51.4424 - val_narrative_output_accuracy: 0.8596 - val_narrative_output_loss: 0.5513\n",
            "Epoch 5/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - level1_output_accuracy: 0.3172 - level1_output_loss: 2.1076 - level2_output_accuracy: 0.2758 - level2_output_loss: 3.0225 - loss: 47.2787 - narrative_output_accuracy: 0.9302 - narrative_output_loss: 0.1920 - val_level1_output_accuracy: 0.2456 - val_level1_output_loss: 2.2609 - val_level2_output_accuracy: 0.2105 - val_level2_output_loss: 3.1592 - val_loss: 38.4527 - val_narrative_output_accuracy: 0.8596 - val_narrative_output_loss: 0.5411\n",
            "Epoch 6/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - level1_output_accuracy: 0.3303 - level1_output_loss: 2.0427 - level2_output_accuracy: 0.3003 - level2_output_loss: 2.8643 - loss: 35.0981 - narrative_output_accuracy: 0.9243 - narrative_output_loss: 0.2117 - val_level1_output_accuracy: 0.2982 - val_level1_output_loss: 2.1464 - val_level2_output_accuracy: 0.1930 - val_level2_output_loss: 3.2087 - val_loss: 28.8256 - val_narrative_output_accuracy: 0.9474 - val_narrative_output_loss: 0.4794\n",
            "Epoch 7/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - level1_output_accuracy: 0.3544 - level1_output_loss: 1.9275 - level2_output_accuracy: 0.2921 - level2_output_loss: 2.8417 - loss: 26.1560 - narrative_output_accuracy: 0.9165 - narrative_output_loss: 0.2091 - val_level1_output_accuracy: 0.2632 - val_level1_output_loss: 2.2284 - val_level2_output_accuracy: 0.2456 - val_level2_output_loss: 3.5032 - val_loss: 22.4581 - val_narrative_output_accuracy: 0.8070 - val_narrative_output_loss: 0.5402\n",
            "Epoch 8/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - level1_output_accuracy: 0.3325 - level1_output_loss: 1.9184 - level2_output_accuracy: 0.2906 - level2_output_loss: 2.8617 - loss: 19.8643 - narrative_output_accuracy: 0.9282 - narrative_output_loss: 0.1725 - val_level1_output_accuracy: 0.2456 - val_level1_output_loss: 2.2332 - val_level2_output_accuracy: 0.1579 - val_level2_output_loss: 3.3055 - val_loss: 17.6026 - val_narrative_output_accuracy: 0.6842 - val_narrative_output_loss: 0.6410\n",
            "Epoch 9/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - level1_output_accuracy: 0.3669 - level1_output_loss: 1.9097 - level2_output_accuracy: 0.2630 - level2_output_loss: 3.0325 - loss: 15.6989 - narrative_output_accuracy: 0.9565 - narrative_output_loss: 0.1518 - val_level1_output_accuracy: 0.2456 - val_level1_output_loss: 2.3096 - val_level2_output_accuracy: 0.2456 - val_level2_output_loss: 3.1715 - val_loss: 14.5813 - val_narrative_output_accuracy: 0.6667 - val_narrative_output_loss: 0.7341\n",
            "Epoch 10/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - level1_output_accuracy: 0.3473 - level1_output_loss: 1.9333 - level2_output_accuracy: 0.2994 - level2_output_loss: 2.8097 - loss: 12.7683 - narrative_output_accuracy: 0.9252 - narrative_output_loss: 0.1997 - val_level1_output_accuracy: 0.2456 - val_level1_output_loss: 2.4425 - val_level2_output_accuracy: 0.1579 - val_level2_output_loss: 3.3150 - val_loss: 12.3142 - val_narrative_output_accuracy: 0.9474 - val_narrative_output_loss: 0.3355\n",
            "Epoch 11/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - level1_output_accuracy: 0.3515 - level1_output_loss: 1.9838 - level2_output_accuracy: 0.2605 - level2_output_loss: 2.8624 - loss: 10.8864 - narrative_output_accuracy: 0.9388 - narrative_output_loss: 0.1517 - val_level1_output_accuracy: 0.2456 - val_level1_output_loss: 2.1517 - val_level2_output_accuracy: 0.2456 - val_level2_output_loss: 3.2141 - val_loss: 10.7352 - val_narrative_output_accuracy: 0.7544 - val_narrative_output_loss: 0.5251\n",
            "Epoch 12/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - level1_output_accuracy: 0.3657 - level1_output_loss: 1.8301 - level2_output_accuracy: 0.2799 - level2_output_loss: 2.9483 - loss: 9.5355 - narrative_output_accuracy: 0.9294 - narrative_output_loss: 0.1788 - val_level1_output_accuracy: 0.2105 - val_level1_output_loss: 2.2599 - val_level2_output_accuracy: 0.0877 - val_level2_output_loss: 3.7502 - val_loss: 10.1940 - val_narrative_output_accuracy: 0.8947 - val_narrative_output_loss: 0.3554\n",
            "Epoch 13/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - level1_output_accuracy: 0.3586 - level1_output_loss: 1.8258 - level2_output_accuracy: 0.2194 - level2_output_loss: 3.2013 - loss: 8.8657 - narrative_output_accuracy: 0.9375 - narrative_output_loss: 0.1714 - val_level1_output_accuracy: 0.2105 - val_level1_output_loss: 2.0635 - val_level2_output_accuracy: 0.2456 - val_level2_output_loss: 3.1428 - val_loss: 8.7659 - val_narrative_output_accuracy: 0.7193 - val_narrative_output_loss: 0.4765\n",
            "Epoch 14/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - level1_output_accuracy: 0.3418 - level1_output_loss: 1.7710 - level2_output_accuracy: 0.3087 - level2_output_loss: 2.6121 - loss: 7.4695 - narrative_output_accuracy: 0.9368 - narrative_output_loss: 0.1620 - val_level1_output_accuracy: 0.2281 - val_level1_output_loss: 2.0389 - val_level2_output_accuracy: 0.2456 - val_level2_output_loss: 3.1418 - val_loss: 8.0947 - val_narrative_output_accuracy: 0.8070 - val_narrative_output_loss: 0.4534\n",
            "Epoch 15/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - level1_output_accuracy: 0.2828 - level1_output_loss: 2.2055 - level2_output_accuracy: 0.2991 - level2_output_loss: 2.7297 - loss: 7.5063 - narrative_output_accuracy: 0.9457 - narrative_output_loss: 0.1617 - val_level1_output_accuracy: 0.1930 - val_level1_output_loss: 2.7643 - val_level2_output_accuracy: 0.2456 - val_level2_output_loss: 3.1674 - val_loss: 9.5889 - val_narrative_output_accuracy: 0.3158 - val_narrative_output_loss: 1.2902\n",
            "Epoch 16/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - level1_output_accuracy: 0.2303 - level1_output_loss: 2.3402 - level2_output_accuracy: 0.3157 - level2_output_loss: 2.7063 - loss: 7.4926 - narrative_output_accuracy: 0.9475 - narrative_output_loss: 0.1376 - val_level1_output_accuracy: 0.1579 - val_level1_output_loss: 2.6585 - val_level2_output_accuracy: 0.2456 - val_level2_output_loss: 3.1806 - val_loss: 9.2800 - val_narrative_output_accuracy: 0.3333 - val_narrative_output_loss: 1.4814\n",
            "Epoch 17/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - level1_output_accuracy: 0.2800 - level1_output_loss: 2.1992 - level2_output_accuracy: 0.3097 - level2_output_loss: 2.6570 - loss: 6.8627 - narrative_output_accuracy: 0.9613 - narrative_output_loss: 0.1297 - val_level1_output_accuracy: 0.1930 - val_level1_output_loss: 2.3879 - val_level2_output_accuracy: 0.2456 - val_level2_output_loss: 3.0928 - val_loss: 7.9614 - val_narrative_output_accuracy: 0.6140 - val_narrative_output_loss: 0.8803\n",
            "Epoch 18/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - level1_output_accuracy: 0.2226 - level1_output_loss: 2.2284 - level2_output_accuracy: 0.2999 - level2_output_loss: 2.6657 - loss: 6.5690 - narrative_output_accuracy: 0.9630 - narrative_output_loss: 0.1208 - val_level1_output_accuracy: 0.1579 - val_level1_output_loss: 2.4898 - val_level2_output_accuracy: 0.2456 - val_level2_output_loss: 3.1416 - val_loss: 7.3595 - val_narrative_output_accuracy: 0.9298 - val_narrative_output_loss: 0.3740\n",
            "Epoch 19/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - level1_output_accuracy: 0.2447 - level1_output_loss: 2.2210 - level2_output_accuracy: 0.3398 - level2_output_loss: 2.5899 - loss: 6.2826 - narrative_output_accuracy: 0.9339 - narrative_output_loss: 0.1521 - val_level1_output_accuracy: 0.1579 - val_level1_output_loss: 2.5365 - val_level2_output_accuracy: 0.1579 - val_level2_output_loss: 3.2311 - val_loss: 7.5050 - val_narrative_output_accuracy: 0.7368 - val_narrative_output_loss: 0.5729\n",
            "Epoch 20/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - level1_output_accuracy: 0.2651 - level1_output_loss: 2.1738 - level2_output_accuracy: 0.3122 - level2_output_loss: 2.6631 - loss: 6.1497 - narrative_output_accuracy: 0.9462 - narrative_output_loss: 0.1546 - val_level1_output_accuracy: 0.1579 - val_level1_output_loss: 2.5089 - val_level2_output_accuracy: 0.2281 - val_level2_output_loss: 3.0483 - val_loss: 8.1883 - val_narrative_output_accuracy: 0.5789 - val_narrative_output_loss: 1.5467\n",
            "Epoch 21/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - level1_output_accuracy: 0.2641 - level1_output_loss: 2.2076 - level2_output_accuracy: 0.3207 - level2_output_loss: 2.6170 - loss: 6.0022 - narrative_output_accuracy: 0.9540 - narrative_output_loss: 0.1346 - val_level1_output_accuracy: 0.1053 - val_level1_output_loss: 2.3904 - val_level2_output_accuracy: 0.2456 - val_level2_output_loss: 3.0882 - val_loss: 7.1334 - val_narrative_output_accuracy: 0.8070 - val_narrative_output_loss: 0.6810\n",
            "Epoch 22/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - level1_output_accuracy: 0.2622 - level1_output_loss: 2.2018 - level2_output_accuracy: 0.2871 - level2_output_loss: 2.6894 - loss: 6.0087 - narrative_output_accuracy: 0.9537 - narrative_output_loss: 0.1262 - val_level1_output_accuracy: 0.1579 - val_level1_output_loss: 2.3379 - val_level2_output_accuracy: 0.2456 - val_level2_output_loss: 3.1299 - val_loss: 6.7632 - val_narrative_output_accuracy: 0.8947 - val_narrative_output_loss: 0.3236\n",
            "Epoch 23/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - level1_output_accuracy: 0.2251 - level1_output_loss: 2.1695 - level2_output_accuracy: 0.3056 - level2_output_loss: 2.6323 - loss: 5.9049 - narrative_output_accuracy: 0.9498 - narrative_output_loss: 0.1303 - val_level1_output_accuracy: 0.1930 - val_level1_output_loss: 2.3332 - val_level2_output_accuracy: 0.2456 - val_level2_output_loss: 3.1268 - val_loss: 6.6337 - val_narrative_output_accuracy: 0.8947 - val_narrative_output_loss: 0.2825\n",
            "Epoch 24/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - level1_output_accuracy: 0.2439 - level1_output_loss: 2.1984 - level2_output_accuracy: 0.2961 - level2_output_loss: 2.6796 - loss: 5.8678 - narrative_output_accuracy: 0.9686 - narrative_output_loss: 0.1128 - val_level1_output_accuracy: 0.1579 - val_level1_output_loss: 2.4061 - val_level2_output_accuracy: 0.2456 - val_level2_output_loss: 3.0898 - val_loss: 6.6819 - val_narrative_output_accuracy: 0.8947 - val_narrative_output_loss: 0.4127\n",
            "Epoch 25/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - level1_output_accuracy: 0.2184 - level1_output_loss: 2.2311 - level2_output_accuracy: 0.3035 - level2_output_loss: 2.7019 - loss: 5.8390 - narrative_output_accuracy: 0.9523 - narrative_output_loss: 0.1273 - val_level1_output_accuracy: 0.1579 - val_level1_output_loss: 2.4097 - val_level2_output_accuracy: 0.2807 - val_level2_output_loss: 3.0447 - val_loss: 6.5712 - val_narrative_output_accuracy: 0.8772 - val_narrative_output_loss: 0.3898\n",
            "Epoch 26/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - level1_output_accuracy: 0.2313 - level1_output_loss: 2.2088 - level2_output_accuracy: 0.3199 - level2_output_loss: 2.5621 - loss: 5.6794 - narrative_output_accuracy: 0.9459 - narrative_output_loss: 0.1791 - val_level1_output_accuracy: 0.1579 - val_level1_output_loss: 2.3995 - val_level2_output_accuracy: 0.2105 - val_level2_output_loss: 3.0951 - val_loss: 6.8497 - val_narrative_output_accuracy: 0.6842 - val_narrative_output_loss: 0.6784\n",
            "Epoch 27/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - level1_output_accuracy: 0.2583 - level1_output_loss: 2.1639 - level2_output_accuracy: 0.3144 - level2_output_loss: 2.5073 - loss: 5.5199 - narrative_output_accuracy: 0.9428 - narrative_output_loss: 0.1513 - val_level1_output_accuracy: 0.1579 - val_level1_output_loss: 2.4593 - val_level2_output_accuracy: 0.2456 - val_level2_output_loss: 2.9689 - val_loss: 6.8633 - val_narrative_output_accuracy: 0.6316 - val_narrative_output_loss: 0.7370\n",
            "Epoch 28/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - level1_output_accuracy: 0.2628 - level1_output_loss: 2.1912 - level2_output_accuracy: 0.3308 - level2_output_loss: 2.4636 - loss: 5.5056 - narrative_output_accuracy: 0.9590 - narrative_output_loss: 0.1324 - val_level1_output_accuracy: 0.1579 - val_level1_output_loss: 2.4848 - val_level2_output_accuracy: 0.3158 - val_level2_output_loss: 2.7344 - val_loss: 6.3979 - val_narrative_output_accuracy: 0.8596 - val_narrative_output_loss: 0.4903\n",
            "Epoch 29/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - level1_output_accuracy: 0.2838 - level1_output_loss: 2.1100 - level2_output_accuracy: 0.3509 - level2_output_loss: 2.3953 - loss: 5.2958 - narrative_output_accuracy: 0.9620 - narrative_output_loss: 0.1018 - val_level1_output_accuracy: 0.1579 - val_level1_output_loss: 2.4242 - val_level2_output_accuracy: 0.2456 - val_level2_output_loss: 2.8223 - val_loss: 6.4403 - val_narrative_output_accuracy: 0.8772 - val_narrative_output_loss: 0.5291\n",
            "Epoch 30/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - level1_output_accuracy: 0.2535 - level1_output_loss: 2.2035 - level2_output_accuracy: 0.3526 - level2_output_loss: 2.3611 - loss: 5.3509 - narrative_output_accuracy: 0.9565 - narrative_output_loss: 0.1152 - val_level1_output_accuracy: 0.1579 - val_level1_output_loss: 3.7353 - val_level2_output_accuracy: 0.2281 - val_level2_output_loss: 2.8537 - val_loss: 7.8270 - val_narrative_output_accuracy: 0.9123 - val_narrative_output_loss: 0.4368\n",
            "Epoch 31/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - level1_output_accuracy: 0.2700 - level1_output_loss: 2.4522 - level2_output_accuracy: 0.3384 - level2_output_loss: 2.4471 - loss: 6.1539 - narrative_output_accuracy: 0.9553 - narrative_output_loss: 0.1228 - val_level1_output_accuracy: 0.1579 - val_level1_output_loss: 2.6001 - val_level2_output_accuracy: 0.3158 - val_level2_output_loss: 2.6177 - val_loss: 8.7538 - val_narrative_output_accuracy: 0.6140 - val_narrative_output_loss: 1.3688\n",
            "Epoch 32/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - level1_output_accuracy: 0.2000 - level1_output_loss: 2.4192 - level2_output_accuracy: 0.3475 - level2_output_loss: 2.3907 - loss: 7.1479 - narrative_output_accuracy: 0.9470 - narrative_output_loss: 0.1423 - val_level1_output_accuracy: 0.1228 - val_level1_output_loss: 2.4414 - val_level2_output_accuracy: 0.2105 - val_level2_output_loss: 2.6826 - val_loss: 7.4388 - val_narrative_output_accuracy: 0.9474 - val_narrative_output_loss: 0.3039\n",
            "Epoch 33/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - level1_output_accuracy: 0.2097 - level1_output_loss: 2.2407 - level2_output_accuracy: 0.3527 - level2_output_loss: 2.2621 - loss: 6.5479 - narrative_output_accuracy: 0.9707 - narrative_output_loss: 0.1056 - val_level1_output_accuracy: 0.1754 - val_level1_output_loss: 2.4017 - val_level2_output_accuracy: 0.3158 - val_level2_output_loss: 2.5587 - val_loss: 7.0364 - val_narrative_output_accuracy: 0.8070 - val_narrative_output_loss: 0.4087\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - level1_output_accuracy: 0.2471 - level1_output_loss: 2.0438 - level2_output_accuracy: 0.2939 - level2_output_loss: 2.3830 - loss: 5.7253 - narrative_output_accuracy: 0.8439 - narrative_output_loss: 0.5856\n",
            "Test Accuracy (Narrative): 0.2456\n",
            "Test Accuracy (Level 1): 0.3158\n",
            "Test Accuracy (Level 2): 0.8596\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Predict on the test set\n",
        "y_test_preds_narrative, y_test_preds_level1, y_test_preds_level2 = model.predict(X_test_combined, batch_size=64)\n",
        "\n",
        "# Convert predictions to class labels\n",
        "y_test_pred_classes_narrative = np.argmax(y_test_preds_narrative, axis=1)\n",
        "y_test_pred_classes_level1 = np.argmax(y_test_preds_level1, axis=1)\n",
        "y_test_pred_classes_level2 = np.argmax(y_test_preds_level2, axis=1)\n",
        "\n",
        "# Convert one-hot encoded test labels to class labels\n",
        "y_test_true_classes_narrative = np.argmax(y_test_narrative_onehot, axis=1)\n",
        "y_test_true_classes_level1 = np.argmax(y_test_level1_onehot, axis=1)\n",
        "y_test_true_classes_level2 = np.argmax(y_test_level2_onehot, axis=1)\n",
        "\n",
        "# Calculate F1-Scores and Accuracy for each level\n",
        "f1_macro_narrative = f1_score(y_test_true_classes_narrative, y_test_pred_classes_narrative, average=\"macro\")\n",
        "f1_weighted_narrative = f1_score(y_test_true_classes_narrative, y_test_pred_classes_narrative, average=\"weighted\")\n",
        "\n",
        "f1_macro_level1 = f1_score(y_test_true_classes_level1, y_test_pred_classes_level1, average=\"macro\")\n",
        "f1_weighted_level1 = f1_score(y_test_true_classes_level1, y_test_pred_classes_level1, average=\"weighted\")\n",
        "\n",
        "f1_macro_level2 = f1_score(y_test_true_classes_level2, y_test_pred_classes_level2, average=\"macro\")\n",
        "f1_weighted_level2 = f1_score(y_test_true_classes_level2, y_test_pred_classes_level2, average=\"weighted\")\n",
        "\n",
        "# Display F1-scores\n",
        "print(f\"F1-Score (Macro) - Narrative: {f1_macro_narrative:.4f}\")\n",
        "print(f\"F1-Score (Weighted) - Narrative: {f1_weighted_narrative:.4f}\")\n",
        "print(f\"F1-Score (Macro) - Level 1: {f1_macro_level1:.4f}\")\n",
        "print(f\"F1-Score (Weighted) - Level 1: {f1_weighted_level1:.4f}\")\n",
        "print(f\"F1-Score (Macro) - Level 2: {f1_macro_level2:.4f}\")\n",
        "print(f\"F1-Score (Weighted) - Level 2: {f1_weighted_level2:.4f}\")\n",
        "\n",
        "# Display sample hierarchical predictions\n",
        "sample_indices = np.random.choice(len(y_test_true_classes_narrative), size=10, replace=False)\n",
        "\n",
        "print(\"\\nSample Hierarchical Predictions:\")\n",
        "for i in sample_indices:\n",
        "    print(f\"Sample {i+1}:\")\n",
        "    print(f\"  True Narrative: {y_test_true_classes_narrative[i]}, Predicted Narrative: {y_test_pred_classes_narrative[i]}\")\n",
        "    print(f\"  True Level 1: {y_test_true_classes_level1[i]}, Predicted Level 1: {y_test_pred_classes_level1[i]}\")\n",
        "    print(f\"  True Level 2: {y_test_true_classes_level2[i]}, Predicted Level 2: {y_test_pred_classes_level2[i]}\")\n",
        "    print(\"-\" * 50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFKv-F-ui8FH",
        "outputId": "518a4110-dfa8-40f6-8de0-886faca47ca6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (57, 12, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step\n",
            "F1-Score (Macro) - Narrative: 0.7889\n",
            "F1-Score (Weighted) - Narrative: 0.8727\n",
            "F1-Score (Macro) - Level 1: 0.0538\n",
            "F1-Score (Weighted) - Level 1: 0.1026\n",
            "F1-Score (Macro) - Level 2: 0.0849\n",
            "F1-Score (Weighted) - Level 2: 0.2002\n",
            "\n",
            "Sample Hierarchical Predictions:\n",
            "Sample 13:\n",
            "  True Narrative: 0, Predicted Narrative: 0\n",
            "  True Level 1: 13, Predicted Level 1: 13\n",
            "  True Level 2: 35, Predicted Level 2: 27\n",
            "--------------------------------------------------\n",
            "Sample 39:\n",
            "  True Narrative: 2, Predicted Narrative: 2\n",
            "  True Level 1: 10, Predicted Level 1: 1\n",
            "  True Level 2: 41, Predicted Level 2: 3\n",
            "--------------------------------------------------\n",
            "Sample 11:\n",
            "  True Narrative: 2, Predicted Narrative: 2\n",
            "  True Level 1: 10, Predicted Level 1: 1\n",
            "  True Level 2: 57, Predicted Level 2: 3\n",
            "--------------------------------------------------\n",
            "Sample 18:\n",
            "  True Narrative: 2, Predicted Narrative: 2\n",
            "  True Level 1: 7, Predicted Level 1: 1\n",
            "  True Level 2: 9, Predicted Level 2: 3\n",
            "--------------------------------------------------\n",
            "Sample 49:\n",
            "  True Narrative: 2, Predicted Narrative: 2\n",
            "  True Level 1: 8, Predicted Level 1: 1\n",
            "  True Level 2: 22, Predicted Level 2: 11\n",
            "--------------------------------------------------\n",
            "Sample 37:\n",
            "  True Narrative: 2, Predicted Narrative: 2\n",
            "  True Level 1: 14, Predicted Level 1: 1\n",
            "  True Level 2: 24, Predicted Level 2: 11\n",
            "--------------------------------------------------\n",
            "Sample 25:\n",
            "  True Narrative: 2, Predicted Narrative: 2\n",
            "  True Level 1: 12, Predicted Level 1: 1\n",
            "  True Level 2: 43, Predicted Level 2: 3\n",
            "--------------------------------------------------\n",
            "Sample 22:\n",
            "  True Narrative: 0, Predicted Narrative: 1\n",
            "  True Level 1: 9, Predicted Level 1: 13\n",
            "  True Level 2: 31, Predicted Level 2: 3\n",
            "--------------------------------------------------\n",
            "Sample 52:\n",
            "  True Narrative: 0, Predicted Narrative: 1\n",
            "  True Level 1: 2, Predicted Level 1: 13\n",
            "  True Level 2: 51, Predicted Level 2: 3\n",
            "--------------------------------------------------\n",
            "Sample 45:\n",
            "  True Narrative: 0, Predicted Narrative: 1\n",
            "  True Level 1: 0, Predicted Level 1: 13\n",
            "  True Level 2: 3, Predicted Level 2: 3\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parameter tuning (other architectures of the model that was tried)"
      ],
      "metadata": {
        "id": "BPWZQ0wYm6ew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Embedding, Concatenate, Input, Dense, Dropout, BatchNormalization, Reshape, MultiHeadAttention, LayerNormalization, GlobalAveragePooling1D\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def create_shared_transformer_model_with_level1(\n",
        "    input_shape, num_narrative_classes, num_level1_classes, num_level2_classes,\n",
        "    num_transformer_layers=2, num_heads=8,\n",
        "    hidden_units=128, shared_hidden_units=256,\n",
        "    narrative_embedding_dim=50, level1_embedding_dim=16,  # Embedding dimensions\n",
        "    dropout_rate=0.5, l2_lambda=0.01\n",
        "):\n",
        "    # Inputs\n",
        "    features_input = Input(shape=(input_shape,), name=\"features_input\")  # X_train features\n",
        "    narrative_input = Input(shape=(1,), name=\"narrative_input\")  # Narrative (categorical)\n",
        "    level1_input = Input(shape=(1,), name=\"level1_input\")  # Level 1 Ground Truth (categorical)\n",
        "\n",
        "    # Narrative Embedding\n",
        "    narrative_embedding = Embedding(\n",
        "        input_dim=num_narrative_classes,\n",
        "        output_dim=narrative_embedding_dim,\n",
        "        embeddings_initializer=\"he_normal\",\n",
        "        input_length=1\n",
        "    )(narrative_input)\n",
        "    narrative_embedding = Reshape((narrative_embedding_dim,))(narrative_embedding)\n",
        "\n",
        "    # Level 1 Embedding\n",
        "    level1_embedding = Embedding(\n",
        "        input_dim=num_level1_classes,\n",
        "        output_dim=level1_embedding_dim,\n",
        "        embeddings_initializer=\"he_normal\",\n",
        "        input_length=1\n",
        "    )(level1_input)\n",
        "    level1_embedding = Reshape((level1_embedding_dim,))(level1_embedding)\n",
        "\n",
        "    # Input for Level 1: X_train + narrative\n",
        "    level1_features = Concatenate()([features_input, narrative_embedding])\n",
        "\n",
        "    # Shared feature extraction for Level 1\n",
        "    level1_shared_features = Dense(\n",
        "        shared_hidden_units, activation=\"relu\", kernel_initializer=\"he_normal\",\n",
        "        kernel_regularizer=tf.keras.regularizers.l2(l2_lambda)\n",
        "    )(level1_features)\n",
        "    level1_shared_features = BatchNormalization()(level1_shared_features)\n",
        "    level1_shared_features = Dropout(dropout_rate)(level1_shared_features)\n",
        "    level1_shared_features = Reshape((1, shared_hidden_units))(level1_shared_features)\n",
        "\n",
        "    # Transformer layers for Level 1\n",
        "    transformer_output_level1 = level1_shared_features\n",
        "    for _ in range(num_transformer_layers):\n",
        "        attention_output = MultiHeadAttention(num_heads=num_heads, key_dim=shared_hidden_units // num_heads)(\n",
        "            transformer_output_level1, transformer_output_level1\n",
        "        )\n",
        "        attention_output = LayerNormalization(epsilon=1e-6)(attention_output + transformer_output_level1)\n",
        "        ff_output = Dense(\n",
        "            shared_hidden_units, activation=\"relu\", kernel_initializer=\"he_normal\",\n",
        "            kernel_regularizer=tf.keras.regularizers.l2(l2_lambda)\n",
        "        )(attention_output)\n",
        "        ff_output = Dropout(dropout_rate)(ff_output)\n",
        "        transformer_output_level1 = LayerNormalization(epsilon=1e-6)(ff_output + attention_output)\n",
        "\n",
        "    # Pooling for Level 1\n",
        "    pooled_level1_output = GlobalAveragePooling1D()(transformer_output_level1)\n",
        "    pooled_level1_output = Dropout(dropout_rate)(pooled_level1_output)\n",
        "\n",
        "    # Output for Level 1\n",
        "    level1_output = Dense(\n",
        "        num_level1_classes, activation=\"softmax\",\n",
        "        kernel_regularizer=tf.keras.regularizers.l2(l2_lambda),\n",
        "        name=\"level1_output\"\n",
        "    )(pooled_level1_output)\n",
        "\n",
        "    # Input for Level 2: X_train + narrative + Level 1 ground truth\n",
        "    level2_features = Concatenate()([features_input, narrative_embedding, level1_embedding])\n",
        "\n",
        "    # Shared feature extraction for Level 2\n",
        "    level2_shared_features = Dense(\n",
        "        shared_hidden_units, activation=\"relu\", kernel_initializer=\"he_normal\",\n",
        "        kernel_regularizer=tf.keras.regularizers.l2(l2_lambda)\n",
        "    )(level2_features)\n",
        "    level2_shared_features = BatchNormalization()(level2_shared_features)\n",
        "    level2_shared_features = Dropout(dropout_rate)(level2_shared_features)\n",
        "    level2_shared_features = Reshape((1, shared_hidden_units))(level2_shared_features)\n",
        "\n",
        "    # Transformer layers for Level 2\n",
        "    transformer_output_level2 = level2_shared_features\n",
        "    for _ in range(num_transformer_layers):\n",
        "        attention_output = MultiHeadAttention(num_heads=num_heads, key_dim=shared_hidden_units // num_heads)(\n",
        "            transformer_output_level2, transformer_output_level2\n",
        "        )\n",
        "        attention_output = LayerNormalization(epsilon=1e-6)(attention_output + transformer_output_level2)\n",
        "        ff_output = Dense(\n",
        "            shared_hidden_units, activation=\"relu\", kernel_initializer=\"he_normal\",\n",
        "            kernel_regularizer=tf.keras.regularizers.l2(l2_lambda)\n",
        "        )(attention_output)\n",
        "        ff_output = Dropout(dropout_rate)(ff_output)\n",
        "        transformer_output_level2 = LayerNormalization(epsilon=1e-6)(ff_output + attention_output)\n",
        "\n",
        "    # Pooling for Level 2\n",
        "    pooled_level2_output = GlobalAveragePooling1D()(transformer_output_level2)\n",
        "    pooled_level2_output = Dropout(dropout_rate)(pooled_level2_output)\n",
        "\n",
        "    # Output for Level 2\n",
        "    level2_output = Dense(\n",
        "        num_level2_classes, activation=\"softmax\",\n",
        "        kernel_regularizer=tf.keras.regularizers.l2(l2_lambda),\n",
        "        name=\"level2_output\"\n",
        "    )(pooled_level2_output)\n",
        "\n",
        "    # Define the model\n",
        "    model = Model(inputs=[features_input, narrative_input, level1_input], outputs=[level1_output, level2_output])\n",
        "    return model\n",
        "\n",
        "\n",
        "# Define the number of classes\n",
        "num_narrative_classes = len(np.unique(y_train_narrative))\n",
        "num_level1_classes = len(np.unique(y_train_level_1))\n",
        "num_level2_classes = len(np.unique(y_train_level_2))\n",
        "\n",
        "# Create the model\n",
        "model = create_shared_transformer_model_with_level1(\n",
        "    input_shape=X_train.shape[1],\n",
        "    num_narrative_classes=num_narrative_classes,\n",
        "    num_level1_classes=num_level1_classes,\n",
        "    num_level2_classes=num_level2_classes,\n",
        "    num_transformer_layers=4,  # Increase number of transformer layers\n",
        "    num_heads=16,             # More attention heads\n",
        "    hidden_units=256,         # Increase hidden layer size\n",
        "    shared_hidden_units=512,  # Larger shared feature dimension\n",
        "    narrative_embedding_dim=50,  # Dimension of narrative embeddings\n",
        "    level1_embedding_dim=16,  # Dimension of Level 1 embeddings\n",
        "    dropout_rate=0.3,         # Reduce dropout to avoid excessive regularization\n",
        "    l2_lambda=0.01\n",
        ")\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "    loss=[\"categorical_crossentropy\", \"categorical_crossentropy\"],\n",
        "    metrics=[\"accuracy\", \"accuracy\"]\n",
        ")\n",
        "\n",
        "# Prepare the training data\n",
        "X_train_combined = [X_train, y_train_narrative.reshape(-1, 1), y_train_level_1.reshape(-1, 1)]  # Level 1 uses X_train + narrative\n",
        "X_val_combined = [X_val, y_val_narrative.reshape(-1, 1), y_val_level_1.reshape(-1, 1)]         # Validation data\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    X_train_combined,\n",
        "    [y_train_level1_onehot, y_train_level2_onehot],  # Outputs for Level 1 and Level 2\n",
        "    validation_data=(X_val_combined, [y_val_level1_onehot, y_val_level2_onehot]),\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate on the test set\n",
        "X_test_combined = [X_test, y_test_narrative.reshape(-1, 1), y_test_level_1.reshape(-1, 1)]  # Test data includes X_test + narrative + Level 1 ground truth\n",
        "test_loss, level1_loss, level2_loss, level1_acc, level2_acc = model.evaluate(\n",
        "    X_test_combined, [y_test_level1_onehot, y_test_level2_onehot]\n",
        ")\n",
        "\n",
        "print(f\"Test Accuracy (Level 1): {level1_acc:.4f}\")\n",
        "print(f\"Test Accuracy (Level 2): {level2_acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZp14ShhQ3SR",
        "outputId": "5e875ab2-1a9a-4dbf-920f-ca4c3437ba1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 1s/step - level1_output_accuracy: 0.1439 - level1_output_loss: 3.6597 - level2_output_accuracy: 0.0945 - level2_output_loss: 4.5466 - loss: 111.5673 - val_level1_output_accuracy: 0.2456 - val_level1_output_loss: 3.1875 - val_level2_output_accuracy: 0.1053 - val_level2_output_loss: 3.9472 - val_loss: 108.2697\n",
            "Epoch 2/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 18ms/step - level1_output_accuracy: 0.3701 - level1_output_loss: 2.3548 - level2_output_accuracy: 0.2566 - level2_output_loss: 3.3553 - loss: 106.1351 - val_level1_output_accuracy: 0.2456 - val_level1_output_loss: 2.7081 - val_level2_output_accuracy: 0.2105 - val_level2_output_loss: 3.4685 - val_loss: 104.4299\n",
            "Epoch 3/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - level1_output_accuracy: 0.3345 - level1_output_loss: 2.3651 - level2_output_accuracy: 0.2938 - level2_output_loss: 2.9192 - loss: 102.8361 - val_level1_output_accuracy: 0.2456 - val_level1_output_loss: 2.6225 - val_level2_output_accuracy: 0.2281 - val_level2_output_loss: 3.1100 - val_loss: 101.1772\n",
            "Epoch 4/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - level1_output_accuracy: 0.3268 - level1_output_loss: 2.2452 - level2_output_accuracy: 0.3099 - level2_output_loss: 2.8107 - loss: 99.8267 - val_level1_output_accuracy: 0.2807 - val_level1_output_loss: 2.5691 - val_level2_output_accuracy: 0.2456 - val_level2_output_loss: 2.9873 - val_loss: 98.2843\n",
            "Epoch 5/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - level1_output_accuracy: 0.3599 - level1_output_loss: 2.0704 - level2_output_accuracy: 0.2980 - level2_output_loss: 2.7460 - loss: 96.8862 - val_level1_output_accuracy: 0.2456 - val_level1_output_loss: 2.5093 - val_level2_output_accuracy: 0.2807 - val_level2_output_loss: 2.9498 - val_loss: 95.5174\n",
            "Epoch 6/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - level1_output_accuracy: 0.3522 - level1_output_loss: 2.0722 - level2_output_accuracy: 0.3597 - level2_output_loss: 2.5068 - loss: 94.0363 - val_level1_output_accuracy: 0.2807 - val_level1_output_loss: 2.6363 - val_level2_output_accuracy: 0.2807 - val_level2_output_loss: 2.7286 - val_loss: 92.8845\n",
            "Epoch 7/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - level1_output_accuracy: 0.3686 - level1_output_loss: 2.0284 - level2_output_accuracy: 0.3462 - level2_output_loss: 2.5404 - loss: 91.5004 - val_level1_output_accuracy: 0.2456 - val_level1_output_loss: 2.3728 - val_level2_output_accuracy: 0.3684 - val_level2_output_loss: 2.5677 - val_loss: 90.0026\n",
            "Epoch 8/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - level1_output_accuracy: 0.3780 - level1_output_loss: 1.9640 - level2_output_accuracy: 0.3571 - level2_output_loss: 2.3025 - loss: 88.7624 - val_level1_output_accuracy: 0.2807 - val_level1_output_loss: 2.2882 - val_level2_output_accuracy: 0.3684 - val_level2_output_loss: 2.5336 - val_loss: 87.5064\n",
            "Epoch 9/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - level1_output_accuracy: 0.3965 - level1_output_loss: 1.8420 - level2_output_accuracy: 0.3790 - level2_output_loss: 2.2287 - loss: 86.2214 - val_level1_output_accuracy: 0.2807 - val_level1_output_loss: 2.3556 - val_level2_output_accuracy: 0.3333 - val_level2_output_loss: 2.4486 - val_loss: 85.2108\n",
            "Epoch 10/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - level1_output_accuracy: 0.3873 - level1_output_loss: 1.8772 - level2_output_accuracy: 0.4324 - level2_output_loss: 2.0052 - loss: 83.7721 - val_level1_output_accuracy: 0.3333 - val_level1_output_loss: 2.6215 - val_level2_output_accuracy: 0.3684 - val_level2_output_loss: 2.4291 - val_loss: 83.2277\n",
            "Epoch 11/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - level1_output_accuracy: 0.4156 - level1_output_loss: 1.8269 - level2_output_accuracy: 0.4250 - level2_output_loss: 1.9971 - loss: 81.5429 - val_level1_output_accuracy: 0.2456 - val_level1_output_loss: 2.6012 - val_level2_output_accuracy: 0.4035 - val_level2_output_loss: 2.3360 - val_loss: 81.0213\n",
            "Epoch 12/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - level1_output_accuracy: 0.4288 - level1_output_loss: 1.7917 - level2_output_accuracy: 0.4355 - level2_output_loss: 1.9177 - loss: 79.3348 - val_level1_output_accuracy: 0.2807 - val_level1_output_loss: 2.3829 - val_level2_output_accuracy: 0.3509 - val_level2_output_loss: 2.3152 - val_loss: 78.7457\n",
            "Epoch 13/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - level1_output_accuracy: 0.4148 - level1_output_loss: 1.7695 - level2_output_accuracy: 0.4791 - level2_output_loss: 1.7583 - loss: 77.1347 - val_level1_output_accuracy: 0.2456 - val_level1_output_loss: 2.3620 - val_level2_output_accuracy: 0.4035 - val_level2_output_loss: 2.2087 - val_loss: 76.6675\n",
            "Epoch 14/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - level1_output_accuracy: 0.4227 - level1_output_loss: 1.7653 - level2_output_accuracy: 0.4491 - level2_output_loss: 1.7716 - loss: 75.1995 - val_level1_output_accuracy: 0.2807 - val_level1_output_loss: 2.3778 - val_level2_output_accuracy: 0.4386 - val_level2_output_loss: 2.1535 - val_loss: 74.7395\n",
            "Epoch 15/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - level1_output_accuracy: 0.4525 - level1_output_loss: 1.6548 - level2_output_accuracy: 0.4614 - level2_output_loss: 1.6377 - loss: 73.0803 - val_level1_output_accuracy: 0.2807 - val_level1_output_loss: 2.5181 - val_level2_output_accuracy: 0.4035 - val_level2_output_loss: 2.1218 - val_loss: 73.0239\n",
            "Epoch 16/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - level1_output_accuracy: 0.4435 - level1_output_loss: 1.6482 - level2_output_accuracy: 0.4857 - level2_output_loss: 1.6001 - loss: 71.2257 - val_level1_output_accuracy: 0.2456 - val_level1_output_loss: 2.5047 - val_level2_output_accuracy: 0.4035 - val_level2_output_loss: 2.1587 - val_loss: 71.2694\n",
            "Epoch 17/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - level1_output_accuracy: 0.4573 - level1_output_loss: 1.6844 - level2_output_accuracy: 0.5179 - level2_output_loss: 1.4576 - loss: 69.3672 - val_level1_output_accuracy: 0.2632 - val_level1_output_loss: 2.6750 - val_level2_output_accuracy: 0.4386 - val_level2_output_loss: 2.0981 - val_loss: 69.6697\n",
            "Epoch 18/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - level1_output_accuracy: 0.4479 - level1_output_loss: 1.7210 - level2_output_accuracy: 0.5274 - level2_output_loss: 1.4367 - loss: 67.6928 - val_level1_output_accuracy: 0.2632 - val_level1_output_loss: 2.4837 - val_level2_output_accuracy: 0.4211 - val_level2_output_loss: 2.1148 - val_loss: 67.8595\n",
            "Epoch 19/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - level1_output_accuracy: 0.4022 - level1_output_loss: 1.7557 - level2_output_accuracy: 0.5146 - level2_output_loss: 1.4704 - loss: 66.1277 - val_level1_output_accuracy: 0.3158 - val_level1_output_loss: 2.5605 - val_level2_output_accuracy: 0.3860 - val_level2_output_loss: 2.1723 - val_loss: 66.4050\n",
            "Epoch 20/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - level1_output_accuracy: 0.4586 - level1_output_loss: 1.6027 - level2_output_accuracy: 0.5400 - level2_output_loss: 1.3412 - loss: 64.2631 - val_level1_output_accuracy: 0.2807 - val_level1_output_loss: 2.5855 - val_level2_output_accuracy: 0.4035 - val_level2_output_loss: 2.1926 - val_loss: 64.9045\n",
            "Epoch 21/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - level1_output_accuracy: 0.4942 - level1_output_loss: 1.5121 - level2_output_accuracy: 0.5598 - level2_output_loss: 1.3072 - loss: 62.6028 - val_level1_output_accuracy: 0.3684 - val_level1_output_loss: 2.4035 - val_level2_output_accuracy: 0.4386 - val_level2_output_loss: 2.2096 - val_loss: 63.2518\n",
            "Epoch 22/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - level1_output_accuracy: 0.4659 - level1_output_loss: 1.5820 - level2_output_accuracy: 0.5502 - level2_output_loss: 1.2949 - loss: 61.1764 - val_level1_output_accuracy: 0.2807 - val_level1_output_loss: 2.6073 - val_level2_output_accuracy: 0.4386 - val_level2_output_loss: 2.0663 - val_loss: 61.8473\n",
            "Epoch 23/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - level1_output_accuracy: 0.4818 - level1_output_loss: 1.5203 - level2_output_accuracy: 0.5710 - level2_output_loss: 1.2389 - loss: 59.6151 - val_level1_output_accuracy: 0.2982 - val_level1_output_loss: 2.6404 - val_level2_output_accuracy: 0.4035 - val_level2_output_loss: 2.0436 - val_loss: 60.4534\n",
            "Epoch 24/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - level1_output_accuracy: 0.4670 - level1_output_loss: 1.5104 - level2_output_accuracy: 0.5865 - level2_output_loss: 1.1596 - loss: 58.1283 - val_level1_output_accuracy: 0.2982 - val_level1_output_loss: 2.7333 - val_level2_output_accuracy: 0.4035 - val_level2_output_loss: 2.0659 - val_loss: 59.1927\n",
            "Epoch 25/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - level1_output_accuracy: 0.4857 - level1_output_loss: 1.5053 - level2_output_accuracy: 0.5994 - level2_output_loss: 1.1153 - loss: 56.7240 - val_level1_output_accuracy: 0.3509 - val_level1_output_loss: 2.6185 - val_level2_output_accuracy: 0.4211 - val_level2_output_loss: 2.0001 - val_loss: 57.6861\n",
            "Epoch 26/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - level1_output_accuracy: 0.5057 - level1_output_loss: 1.3679 - level2_output_accuracy: 0.6025 - level2_output_loss: 1.1442 - loss: 55.2960 - val_level1_output_accuracy: 0.2456 - val_level1_output_loss: 2.6516 - val_level2_output_accuracy: 0.4386 - val_level2_output_loss: 2.0654 - val_loss: 56.5034\n",
            "Epoch 27/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - level1_output_accuracy: 0.5020 - level1_output_loss: 1.4206 - level2_output_accuracy: 0.5969 - level2_output_loss: 1.1490 - loss: 54.0768 - val_level1_output_accuracy: 0.2632 - val_level1_output_loss: 2.7760 - val_level2_output_accuracy: 0.4211 - val_level2_output_loss: 2.0857 - val_loss: 55.3926\n",
            "Epoch 28/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - level1_output_accuracy: 0.4847 - level1_output_loss: 1.5125 - level2_output_accuracy: 0.6064 - level2_output_loss: 1.0879 - loss: 52.8636 - val_level1_output_accuracy: 0.2982 - val_level1_output_loss: 2.5330 - val_level2_output_accuracy: 0.4035 - val_level2_output_loss: 2.1984 - val_loss: 54.0383\n",
            "Epoch 29/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - level1_output_accuracy: 0.5279 - level1_output_loss: 1.3459 - level2_output_accuracy: 0.6051 - level2_output_loss: 1.1006 - loss: 51.5012 - val_level1_output_accuracy: 0.3158 - val_level1_output_loss: 2.7108 - val_level2_output_accuracy: 0.4211 - val_level2_output_loss: 2.1186 - val_loss: 52.9642\n",
            "Epoch 30/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - level1_output_accuracy: 0.5247 - level1_output_loss: 1.3833 - level2_output_accuracy: 0.6452 - level2_output_loss: 1.0001 - loss: 50.2590 - val_level1_output_accuracy: 0.2456 - val_level1_output_loss: 2.7234 - val_level2_output_accuracy: 0.4561 - val_level2_output_loss: 2.1362 - val_loss: 51.8298\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - level1_output_accuracy: 0.3589 - level1_output_loss: 2.1128 - level2_output_accuracy: 0.3732 - level2_output_loss: 2.2070 - loss: 51.3504\n",
            "Test Accuracy (Level 1): 0.3509\n",
            "Test Accuracy (Level 2): 0.4035\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
        "\n",
        "# Predict on the test set\n",
        "y_test_preds_level1, y_test_preds_level2 = model.predict(X_test_combined, batch_size=64)\n",
        "\n",
        "# Convert predictions to class labels\n",
        "y_test_pred_classes_level1 = np.argmax(y_test_preds_level1, axis=1)\n",
        "y_test_pred_classes_level2 = np.argmax(y_test_preds_level2, axis=1)\n",
        "\n",
        "# Convert one-hot encoded test labels to class labels\n",
        "y_test_true_classes_level1 = np.argmax(y_test_level1_onehot, axis=1)\n",
        "y_test_true_classes_level2 = np.argmax(y_test_level2_onehot, axis=1)\n",
        "\n",
        "# Calculate F1-Scores and Accuracy\n",
        "f1_macro_level1 = f1_score(y_test_true_classes_level1, y_test_pred_classes_level1, average=\"macro\")\n",
        "f1_weighted_level1 = f1_score(y_test_true_classes_level1, y_test_pred_classes_level1, average=\"weighted\")\n",
        "f1_macro_level2 = f1_score(y_test_true_classes_level2, y_test_pred_classes_level2, average=\"macro\")\n",
        "f1_weighted_level2 = f1_score(y_test_true_classes_level2, y_test_pred_classes_level2, average=\"weighted\")\n",
        "\n",
        "accuracy_level1 = accuracy_score(y_test_true_classes_level1, y_test_pred_classes_level1)\n",
        "accuracy_level2 = accuracy_score(y_test_true_classes_level2, y_test_pred_classes_level2)\n",
        "\n",
        "# Print scores\n",
        "print(f\"Level 1 Accuracy: {accuracy_level1:.4f}\")\n",
        "print(f\"Level 1 F1 Macro: {f1_macro_level1:.4f}\")\n",
        "print(f\"Level 1 F1 Weighted: {f1_weighted_level1:.4f}\")\n",
        "print(f\"Level 2 Accuracy: {accuracy_level2:.4f}\")\n",
        "print(f\"Level 2 F1 Macro: {f1_macro_level2:.4f}\")\n",
        "print(f\"Level 2 F1 Weighted: {f1_weighted_level2:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Hlnb5t1Wbha",
        "outputId": "fe19b9ef-5000-4b62-d972-445fac791675"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
            "Level 1 Accuracy: 0.4211\n",
            "Level 1 F1 Macro: 0.1639\n",
            "Level 1 F1 Weighted: 0.3518\n",
            "Level 2 Accuracy: 0.4211\n",
            "Level 2 F1 Macro: 0.3126\n",
            "Level 2 F1 Weighted: 0.3929\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hKcvHKYvlNEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Embedding, Concatenate, Input, Dense, Dropout, BatchNormalization, Reshape, MultiHeadAttention, LayerNormalization, GlobalAveragePooling1D, Add\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "def create_improved_transformer_model(\n",
        "    input_shape, num_narrative_classes, num_level1_classes, num_level2_classes,\n",
        "    num_transformer_layers=6, num_heads=12,  # More transformer layers and heads\n",
        "    hidden_units=256, shared_hidden_units=512,\n",
        "    narrative_embedding_dim=100, level1_embedding_dim=32,  # Tuned embedding dimensions\n",
        "    attention_dropout_rate=0.2,  # Dropout within attention\n",
        "    dropout_rate=0.4, l2_lambda=0.01\n",
        "):\n",
        "    # Inputs\n",
        "    features_input = Input(shape=(input_shape,), name=\"features_input\")\n",
        "    narrative_input = Input(shape=(1,), name=\"narrative_input\")\n",
        "    level1_input = Input(shape=(1,), name=\"level1_input\")\n",
        "\n",
        "    # Narrative Embedding\n",
        "    narrative_embedding = Embedding(\n",
        "        input_dim=num_narrative_classes,\n",
        "        output_dim=narrative_embedding_dim,\n",
        "        embeddings_initializer=\"he_normal\",\n",
        "        input_length=1\n",
        "    )(narrative_input)\n",
        "    narrative_embedding = Reshape((narrative_embedding_dim,))(narrative_embedding)\n",
        "\n",
        "    # Level 1 Embedding\n",
        "    level1_embedding = Embedding(\n",
        "        input_dim=num_level1_classes,\n",
        "        output_dim=level1_embedding_dim,\n",
        "        embeddings_initializer=\"he_normal\",\n",
        "        input_length=1\n",
        "    )(level1_input)\n",
        "    level1_embedding = Reshape((level1_embedding_dim,))(level1_embedding)\n",
        "\n",
        "    # Level 1 Features: Combine X_train + narrative\n",
        "    level1_features = Concatenate()([features_input, narrative_embedding])\n",
        "    level1_shared_features = Dense(\n",
        "        shared_hidden_units, activation=\"relu\", kernel_initializer=\"he_normal\",\n",
        "        kernel_regularizer=l2(l2_lambda)\n",
        "    )(level1_features)\n",
        "    level1_shared_features = BatchNormalization()(level1_shared_features)\n",
        "    level1_shared_features = Dropout(dropout_rate)(level1_shared_features)\n",
        "    level1_shared_features = Reshape((1, shared_hidden_units))(level1_shared_features)\n",
        "\n",
        "    # Transformer for Level 1\n",
        "    transformer_output_level1 = level1_shared_features\n",
        "    for _ in range(num_transformer_layers):\n",
        "        attention_output = MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=shared_hidden_units // num_heads,\n",
        "            dropout=attention_dropout_rate  # Attention dropout\n",
        "        )(transformer_output_level1, transformer_output_level1)\n",
        "        attention_output = LayerNormalization(epsilon=1e-6)(Add()([attention_output, transformer_output_level1]))\n",
        "\n",
        "        ff_output = Dense(\n",
        "            shared_hidden_units, activation=\"relu\", kernel_initializer=\"he_normal\",\n",
        "            kernel_regularizer=l2(l2_lambda)\n",
        "        )(attention_output)\n",
        "        ff_output = Dropout(dropout_rate)(ff_output)\n",
        "        transformer_output_level1 = LayerNormalization(epsilon=1e-6)(Add()([ff_output, attention_output]))\n",
        "\n",
        "    # Level 1 Pooling and Output\n",
        "    pooled_level1_output = GlobalAveragePooling1D()(transformer_output_level1)\n",
        "    pooled_level1_output = Dropout(dropout_rate)(pooled_level1_output)\n",
        "    level1_output = Dense(\n",
        "        num_level1_classes, activation=\"softmax\", kernel_regularizer=l2(l2_lambda),\n",
        "        name=\"level1_output\"\n",
        "    )(pooled_level1_output)\n",
        "\n",
        "    # Level 2 Features: Combine X_train + narrative + Level 1 ground truth\n",
        "    level2_features = Concatenate()([features_input, narrative_embedding, level1_embedding])\n",
        "    level2_shared_features = Dense(\n",
        "        shared_hidden_units, activation=\"relu\", kernel_initializer=\"he_normal\",\n",
        "        kernel_regularizer=l2(l2_lambda)\n",
        "    )(level2_features)\n",
        "    level2_shared_features = BatchNormalization()(level2_shared_features)\n",
        "    level2_shared_features = Dropout(dropout_rate)(level2_shared_features)\n",
        "    level2_shared_features = Reshape((1, shared_hidden_units))(level2_shared_features)\n",
        "\n",
        "    # Transformer for Level 2\n",
        "    transformer_output_level2 = level2_shared_features\n",
        "    for _ in range(num_transformer_layers):\n",
        "        attention_output = MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=shared_hidden_units // num_heads,\n",
        "            dropout=attention_dropout_rate\n",
        "        )(transformer_output_level2, transformer_output_level2)\n",
        "        attention_output = LayerNormalization(epsilon=1e-6)(Add()([attention_output, transformer_output_level2]))\n",
        "\n",
        "        ff_output = Dense(\n",
        "            shared_hidden_units, activation=\"relu\", kernel_initializer=\"he_normal\",\n",
        "            kernel_regularizer=l2(l2_lambda)\n",
        "        )(attention_output)\n",
        "        ff_output = Dropout(dropout_rate)(ff_output)\n",
        "        transformer_output_level2 = LayerNormalization(epsilon=1e-6)(Add()([ff_output, attention_output]))\n",
        "\n",
        "    # Level 2 Pooling and Output\n",
        "    pooled_level2_output = GlobalAveragePooling1D()(transformer_output_level2)\n",
        "    pooled_level2_output = Dropout(dropout_rate)(pooled_level2_output)\n",
        "    level2_output = Dense(\n",
        "        num_level2_classes, activation=\"softmax\", kernel_regularizer=l2(l2_lambda),\n",
        "        name=\"level2_output\"\n",
        "    )(pooled_level2_output)\n",
        "\n",
        "    # Define the model\n",
        "    model = Model(inputs=[features_input, narrative_input, level1_input], outputs=[level1_output, level2_output])\n",
        "    return model\n",
        "\n",
        "\n",
        "# Define and Compile the Improved Model\n",
        "model = create_improved_transformer_model(\n",
        "    input_shape=X_train.shape[1],\n",
        "    num_narrative_classes=len(np.unique(y_train_narrative)),\n",
        "    num_level1_classes=len(np.unique(y_train_level_1)),\n",
        "    num_level2_classes=len(np.unique(y_train_level_2))\n",
        ")\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=1e-4),  # Use Adam optimizer\n",
        "    loss=[\"categorical_crossentropy\", \"categorical_crossentropy\"],\n",
        "    metrics=[\"accuracy\", \"accuracy\"]\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    X_train_combined,\n",
        "    [y_train_level1_onehot, y_train_level2_onehot],  # Outputs for Level 1 and Level 2\n",
        "    validation_data=(X_val_combined, [y_val_level1_onehot, y_val_level2_onehot]),\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate on the test set\n",
        "X_test_combined = [X_test, y_test_narrative.reshape(-1, 1), y_test_level_1.reshape(-1, 1)]  # Test data includes X_test + narrative + Level 1 ground truth\n",
        "test_loss, level1_loss, level2_loss, level1_acc, level2_acc = model.evaluate(\n",
        "    X_test_combined, [y_test_level1_onehot, y_test_level2_onehot]\n",
        ")\n",
        "\n",
        "print(f\"Test Accuracy (Level 1): {level1_acc:.4f}\")\n",
        "print(f\"Test Accuracy (Level 2): {level2_acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9eFN5n-blZK",
        "outputId": "a6c4d4c2-d127-4570-ed71-d51a6bee5d38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 2s/step - level1_output_accuracy: 0.0722 - level1_output_loss: 4.2122 - level2_output_accuracy: 0.0364 - level2_output_loss: 5.3360 - loss: 153.9095 - val_level1_output_accuracy: 0.2632 - val_level1_output_loss: 3.1984 - val_level2_output_accuracy: 0.1228 - val_level2_output_loss: 4.1632 - val_loss: 149.4676\n",
            "Epoch 2/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - level1_output_accuracy: 0.3044 - level1_output_loss: 2.8506 - level2_output_accuracy: 0.2097 - level2_output_loss: 4.2273 - loss: 148.3884 - val_level1_output_accuracy: 0.2632 - val_level1_output_loss: 3.3087 - val_level2_output_accuracy: 0.1579 - val_level2_output_loss: 3.3809 - val_loss: 145.7888\n",
            "Epoch 3/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - level1_output_accuracy: 0.3453 - level1_output_loss: 2.4895 - level2_output_accuracy: 0.2429 - level2_output_loss: 3.7512 - loss: 144.5677 - val_level1_output_accuracy: 0.1930 - val_level1_output_loss: 3.0613 - val_level2_output_accuracy: 0.2456 - val_level2_output_loss: 3.7164 - val_loss: 142.8992\n",
            "Epoch 4/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - level1_output_accuracy: 0.3202 - level1_output_loss: 2.5095 - level2_output_accuracy: 0.2569 - level2_output_loss: 3.4551 - loss: 141.3684 - val_level1_output_accuracy: 0.2105 - val_level1_output_loss: 2.9364 - val_level2_output_accuracy: 0.2456 - val_level2_output_loss: 3.7084 - val_loss: 139.8514\n",
            "Epoch 5/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - level1_output_accuracy: 0.3372 - level1_output_loss: 2.4171 - level2_output_accuracy: 0.2653 - level2_output_loss: 3.4138 - loss: 138.3732 - val_level1_output_accuracy: 0.2632 - val_level1_output_loss: 2.4482 - val_level2_output_accuracy: 0.2456 - val_level2_output_loss: 3.5714 - val_loss: 136.3905\n",
            "Epoch 6/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - level1_output_accuracy: 0.3284 - level1_output_loss: 2.2966 - level2_output_accuracy: 0.2964 - level2_output_loss: 3.1677 - loss: 135.1865 - val_level1_output_accuracy: 0.1754 - val_level1_output_loss: 2.4054 - val_level2_output_accuracy: 0.2456 - val_level2_output_loss: 3.4557 - val_loss: 133.4325\n",
            "Epoch 7/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - level1_output_accuracy: 0.3433 - level1_output_loss: 2.2898 - level2_output_accuracy: 0.3027 - level2_output_loss: 3.0359 - loss: 132.2621 - val_level1_output_accuracy: 0.2105 - val_level1_output_loss: 2.4024 - val_level2_output_accuracy: 0.2456 - val_level2_output_loss: 3.3140 - val_loss: 130.5192\n",
            "Epoch 8/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - level1_output_accuracy: 0.3560 - level1_output_loss: 2.1603 - level2_output_accuracy: 0.3208 - level2_output_loss: 2.8944 - loss: 129.2375 - val_level1_output_accuracy: 0.2456 - val_level1_output_loss: 2.2300 - val_level2_output_accuracy: 0.2632 - val_level2_output_loss: 3.1366 - val_loss: 127.4409\n",
            "Epoch 9/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - level1_output_accuracy: 0.3285 - level1_output_loss: 2.1832 - level2_output_accuracy: 0.2850 - level2_output_loss: 3.0620 - loss: 126.7033 - val_level1_output_accuracy: 0.2456 - val_level1_output_loss: 2.2905 - val_level2_output_accuracy: 0.2982 - val_level2_output_loss: 3.1442 - val_loss: 124.8017\n",
            "Epoch 10/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - level1_output_accuracy: 0.3337 - level1_output_loss: 2.2444 - level2_output_accuracy: 0.2888 - level2_output_loss: 3.0494 - loss: 124.0675 - val_level1_output_accuracy: 0.2982 - val_level1_output_loss: 2.1945 - val_level2_output_accuracy: 0.2982 - val_level2_output_loss: 2.9936 - val_loss: 121.9165\n",
            "Epoch 11/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - level1_output_accuracy: 0.3428 - level1_output_loss: 2.1889 - level2_output_accuracy: 0.2993 - level2_output_loss: 2.9264 - loss: 121.2320 - val_level1_output_accuracy: 0.2456 - val_level1_output_loss: 2.1596 - val_level2_output_accuracy: 0.2982 - val_level2_output_loss: 2.8851 - val_loss: 119.1382\n",
            "Epoch 12/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - level1_output_accuracy: 0.3032 - level1_output_loss: 2.2766 - level2_output_accuracy: 0.2950 - level2_output_loss: 2.8806 - loss: 118.6611 - val_level1_output_accuracy: 0.2456 - val_level1_output_loss: 2.1676 - val_level2_output_accuracy: 0.3333 - val_level2_output_loss: 2.7639 - val_loss: 116.4334\n",
            "Epoch 13/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - level1_output_accuracy: 0.3570 - level1_output_loss: 2.1039 - level2_output_accuracy: 0.3273 - level2_output_loss: 2.6884 - loss: 115.7247 - val_level1_output_accuracy: 0.2456 - val_level1_output_loss: 2.1671 - val_level2_output_accuracy: 0.2982 - val_level2_output_loss: 2.7521 - val_loss: 113.8847\n",
            "Epoch 14/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - level1_output_accuracy: 0.3222 - level1_output_loss: 2.2095 - level2_output_accuracy: 0.3592 - level2_output_loss: 2.5609 - loss: 113.1761 - val_level1_output_accuracy: 0.2456 - val_level1_output_loss: 2.1724 - val_level2_output_accuracy: 0.2807 - val_level2_output_loss: 2.7651 - val_loss: 111.4003\n",
            "Epoch 15/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - level1_output_accuracy: 0.3274 - level1_output_loss: 2.0967 - level2_output_accuracy: 0.3894 - level2_output_loss: 2.4042 - loss: 110.4266 - val_level1_output_accuracy: 0.2456 - val_level1_output_loss: 2.2569 - val_level2_output_accuracy: 0.2982 - val_level2_output_loss: 2.5055 - val_loss: 108.7871\n",
            "Epoch 16/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - level1_output_accuracy: 0.3548 - level1_output_loss: 2.0894 - level2_output_accuracy: 0.3809 - level2_output_loss: 2.4966 - loss: 108.0780 - val_level1_output_accuracy: 0.2456 - val_level1_output_loss: 2.1658 - val_level2_output_accuracy: 0.3158 - val_level2_output_loss: 2.4230 - val_loss: 106.2200\n",
            "Epoch 17/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - level1_output_accuracy: 0.3567 - level1_output_loss: 2.0186 - level2_output_accuracy: 0.3813 - level2_output_loss: 2.3678 - loss: 105.4967 - val_level1_output_accuracy: 0.2456 - val_level1_output_loss: 2.1640 - val_level2_output_accuracy: 0.2982 - val_level2_output_loss: 2.4932 - val_loss: 103.9426\n",
            "Epoch 18/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - level1_output_accuracy: 0.3357 - level1_output_loss: 1.9942 - level2_output_accuracy: 0.4116 - level2_output_loss: 2.2134 - loss: 102.9918 - val_level1_output_accuracy: 0.2456 - val_level1_output_loss: 2.1783 - val_level2_output_accuracy: 0.3684 - val_level2_output_loss: 2.3014 - val_loss: 101.4716\n",
            "Epoch 19/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - level1_output_accuracy: 0.3163 - level1_output_loss: 2.0962 - level2_output_accuracy: 0.3553 - level2_output_loss: 2.3178 - loss: 100.9151 - val_level1_output_accuracy: 0.2456 - val_level1_output_loss: 2.1710 - val_level2_output_accuracy: 0.4035 - val_level2_output_loss: 2.2115 - val_loss: 99.1325\n",
            "Epoch 20/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - level1_output_accuracy: 0.3613 - level1_output_loss: 2.0148 - level2_output_accuracy: 0.4511 - level2_output_loss: 2.0496 - loss: 98.3349 - val_level1_output_accuracy: 0.2807 - val_level1_output_loss: 2.1740 - val_level2_output_accuracy: 0.4211 - val_level2_output_loss: 2.1823 - val_loss: 96.9138\n",
            "Epoch 21/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - level1_output_accuracy: 0.3779 - level1_output_loss: 1.9300 - level2_output_accuracy: 0.4579 - level2_output_loss: 1.9204 - loss: 95.9341 - val_level1_output_accuracy: 0.2281 - val_level1_output_loss: 2.1193 - val_level2_output_accuracy: 0.4386 - val_level2_output_loss: 2.1437 - val_loss: 94.6765\n",
            "Epoch 22/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - level1_output_accuracy: 0.3576 - level1_output_loss: 1.8772 - level2_output_accuracy: 0.4355 - level2_output_loss: 2.0385 - loss: 93.8598 - val_level1_output_accuracy: 0.2807 - val_level1_output_loss: 2.1819 - val_level2_output_accuracy: 0.4035 - val_level2_output_loss: 2.1547 - val_loss: 92.6434\n",
            "Epoch 23/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - level1_output_accuracy: 0.3990 - level1_output_loss: 1.8574 - level2_output_accuracy: 0.4430 - level2_output_loss: 1.9990 - loss: 91.7067 - val_level1_output_accuracy: 0.2807 - val_level1_output_loss: 2.1370 - val_level2_output_accuracy: 0.4211 - val_level2_output_loss: 2.0874 - val_loss: 90.4581\n",
            "Epoch 24/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - level1_output_accuracy: 0.3381 - level1_output_loss: 1.9988 - level2_output_accuracy: 0.4591 - level2_output_loss: 1.8658 - loss: 89.6590 - val_level1_output_accuracy: 0.2456 - val_level1_output_loss: 2.2094 - val_level2_output_accuracy: 0.3684 - val_level2_output_loss: 2.0722 - val_loss: 88.4979\n",
            "Epoch 25/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - level1_output_accuracy: 0.3810 - level1_output_loss: 1.9280 - level2_output_accuracy: 0.4780 - level2_output_loss: 1.7638 - loss: 87.4781 - val_level1_output_accuracy: 0.2632 - val_level1_output_loss: 2.1785 - val_level2_output_accuracy: 0.4561 - val_level2_output_loss: 2.0741 - val_loss: 86.4847\n",
            "Epoch 26/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - level1_output_accuracy: 0.3814 - level1_output_loss: 1.8945 - level2_output_accuracy: 0.4994 - level2_output_loss: 1.7455 - loss: 85.4569 - val_level1_output_accuracy: 0.2807 - val_level1_output_loss: 2.1667 - val_level2_output_accuracy: 0.3684 - val_level2_output_loss: 2.0766 - val_loss: 84.5464\n",
            "Epoch 27/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - level1_output_accuracy: 0.3550 - level1_output_loss: 1.9170 - level2_output_accuracy: 0.5001 - level2_output_loss: 1.6279 - loss: 83.4341 - val_level1_output_accuracy: 0.2807 - val_level1_output_loss: 2.1310 - val_level2_output_accuracy: 0.4211 - val_level2_output_loss: 1.9518 - val_loss: 82.4847\n",
            "Epoch 28/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - level1_output_accuracy: 0.3872 - level1_output_loss: 1.8230 - level2_output_accuracy: 0.5151 - level2_output_loss: 1.5440 - loss: 81.3661 - val_level1_output_accuracy: 0.2456 - val_level1_output_loss: 2.1403 - val_level2_output_accuracy: 0.4737 - val_level2_output_loss: 1.9659 - val_loss: 80.6450\n",
            "Epoch 29/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - level1_output_accuracy: 0.3669 - level1_output_loss: 1.8739 - level2_output_accuracy: 0.4557 - level2_output_loss: 1.7472 - loss: 79.7707 - val_level1_output_accuracy: 0.2807 - val_level1_output_loss: 2.1641 - val_level2_output_accuracy: 0.4386 - val_level2_output_loss: 1.9935 - val_loss: 78.8802\n",
            "Epoch 30/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - level1_output_accuracy: 0.4061 - level1_output_loss: 1.8231 - level2_output_accuracy: 0.5100 - level2_output_loss: 1.5984 - loss: 77.7614 - val_level1_output_accuracy: 0.2281 - val_level1_output_loss: 2.1586 - val_level2_output_accuracy: 0.4386 - val_level2_output_loss: 1.8984 - val_loss: 76.9957\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - level1_output_accuracy: 0.3953 - level1_output_loss: 1.6702 - level2_output_accuracy: 0.4161 - level2_output_loss: 1.7786 - loss: 76.4562\n",
            "Test Accuracy (Level 1): 0.4211\n",
            "Test Accuracy (Level 2): 0.4211\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a DataFrame with just numeric values\n",
        "sample_data_numeric = {\n",
        "\n",
        "    \"True Values\": [\n",
        "        f\"{y_test_true_classes[i]}, {y_test_true_classes_level1[i]}, {y_test_true_classes_level2[i]}\"\n",
        "        for i in range(10)\n",
        "    ],\n",
        "    \"Predicted Values\": [\n",
        "        f\"{y_test_pred_classes[i]}, {y_test_pred_classes_level1[i]}, {y_test_pred_classes_level2[i]}\"\n",
        "        for i in range(10)\n",
        "    ],\n",
        "}\n",
        "\n",
        "# Convert to a pandas DataFrame\n",
        "df_samples_numeric = pd.DataFrame(sample_data_numeric)\n",
        "\n",
        "df_samples_numeric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "F0bqZtyGPnaN",
        "outputId": "b25618be-8488-45ce-95aa-74c0c75e2e7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  True Values Predicted Values\n",
              "0     1, 1, 1          2, 1, 1\n",
              "1   0, 13, 27        0, 13, 27\n",
              "2    0, 0, 28         0, 11, 0\n",
              "3   2, 10, 21          2, 6, 3\n",
              "4   0, 13, 27        0, 13, 35\n",
              "5   0, 13, 27        0, 13, 53\n",
              "6   2, 10, 41        2, 10, 49\n",
              "7   2, 10, 41        2, 10, 57\n",
              "8   0, 11, 50          0, 0, 3\n",
              "9   0, 18, 40        0, 18, 39"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-78383a45-1b54-493d-876d-3ec2692933f9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>True Values</th>\n",
              "      <th>Predicted Values</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1, 1, 1</td>\n",
              "      <td>2, 1, 1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0, 13, 27</td>\n",
              "      <td>0, 13, 27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0, 0, 28</td>\n",
              "      <td>0, 11, 0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2, 10, 21</td>\n",
              "      <td>2, 6, 3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0, 13, 27</td>\n",
              "      <td>0, 13, 35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0, 13, 27</td>\n",
              "      <td>0, 13, 53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2, 10, 41</td>\n",
              "      <td>2, 10, 49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2, 10, 41</td>\n",
              "      <td>2, 10, 57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0, 11, 50</td>\n",
              "      <td>0, 0, 3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0, 18, 40</td>\n",
              "      <td>0, 18, 39</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-78383a45-1b54-493d-876d-3ec2692933f9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-78383a45-1b54-493d-876d-3ec2692933f9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-78383a45-1b54-493d-876d-3ec2692933f9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-093c358a-61ed-4656-a355-73bbd0ac38d2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-093c358a-61ed-4656-a355-73bbd0ac38d2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-093c358a-61ed-4656-a355-73bbd0ac38d2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_6f950b1b-22d1-4341-bc59-6932f53b6bba\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_samples_numeric')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_6f950b1b-22d1-4341-bc59-6932f53b6bba button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_samples_numeric');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_samples_numeric",
              "summary": "{\n  \"name\": \"df_samples_numeric\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"True Values\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"1, 1, 1\",\n          \"0, 13, 27\",\n          \"0, 11, 50\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Predicted Values\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"0, 0, 3\",\n          \"0, 13, 27\",\n          \"0, 13, 53\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    }
  ]
}